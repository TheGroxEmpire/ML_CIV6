{"custom_metrics": {}, "episode_media": {}, "num_recreated_workers": 0, "info": {"learner": {"attacker": {"learner_stats": {"cur_lr": 0.0005000000237487257, "mean_q": 0.27229219675064087, "min_q": -0.29965126514434814, "max_q": 0.910771369934082, "mean_td_error": 0.42142462730407715, "model": {}}, "td_error": [0.027449965476989746, -0.29485079646110535, 1.081540584564209, 0.25019654631614685, 0.6416902542114258, 0.23732426762580872, 1.4175914525985718, -0.2279016375541687, 1.5151176452636719, -0.5944885611534119, 0.9001834392547607, 0.08377960324287415, -0.15331363677978516, 0.5744611024856567, 1.7551729679107666, -0.471159428358078], "custom_metrics": {}, "num_agent_steps_trained": 16.0}, "defender": {"learner_stats": {"cur_lr": 0.0005000000237487257, "mean_q": -0.7157714366912842, "min_q": -1.5197783708572388, "max_q": 0.2254151701927185, "mean_td_error": -0.2706145644187927, "model": {}}, "td_error": [0.17652881145477295, -1.1483170986175537, -0.3926423192024231, -0.33451759815216064, -0.7731677293777466, -0.6225899457931519, 0.24058878421783447, -1.8352718353271484, 0.0020779073238372803, -1.4895555973052979, 0.5548447370529175, -0.24789538979530334, 0.20303919911384583, -0.11978161334991455, 0.7371619939804077, 0.7196645140647888], "custom_metrics": {}, "num_agent_steps_trained": 16.0}}, "num_env_steps_sampled": 1008, "num_env_steps_trained": 32, "num_agent_steps_sampled": 1006, "num_agent_steps_trained": 32, "last_target_update_ts": 1008, "num_target_updates": 1}, "sampler_results": {"episode_reward_max": -153.0333333333333, "episode_reward_min": -188.7999999999999, "episode_reward_mean": -170.9166666666666, "episode_len_mean": 322.0, "episode_media": {}, "episodes_this_iter": 2, "policy_reward_min": {"attacker": -179.69999999999987, "defender": -9.100000000000001}, "policy_reward_max": {"attacker": -144.53333333333322, "defender": -8.5}, "policy_reward_mean": {"attacker": -162.11666666666656, "defender": -8.8}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-188.7999999999999, -153.0333333333333], "episode_lengths": [309, 335], "policy_attacker_reward": [-179.69999999999987, -144.53333333333322], "policy_defender_reward": [-9.100000000000001, -8.5]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.3638582342810022, "mean_inference_ms": 0.9263548723667948, "mean_action_processing_ms": 0.06621244753149921, "mean_env_wait_ms": 0.5063522463382528, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0}, "episode_reward_max": -153.0333333333333, "episode_reward_min": -188.7999999999999, "episode_reward_mean": -170.9166666666666, "episode_len_mean": 322.0, "episodes_this_iter": 2, "policy_reward_min": {"attacker": -179.69999999999987, "defender": -9.100000000000001}, "policy_reward_max": {"attacker": -144.53333333333322, "defender": -8.5}, "policy_reward_mean": {"attacker": -162.11666666666656, "defender": -8.8}, "hist_stats": {"episode_reward": [-188.7999999999999, -153.0333333333333], "episode_lengths": [309, 335], "policy_attacker_reward": [-179.69999999999987, -144.53333333333322], "policy_defender_reward": [-9.100000000000001, -8.5]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.3638582342810022, "mean_inference_ms": 0.9263548723667948, "mean_action_processing_ms": 0.06621244753149921, "mean_env_wait_ms": 0.5063522463382528, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "num_healthy_workers": 3, "num_agent_steps_sampled": 1006, "num_agent_steps_trained": 32, "num_env_steps_sampled": 1008, "num_env_steps_trained": 32, "num_env_steps_sampled_this_iter": 1008, "num_env_steps_trained_this_iter": 32, "timesteps_total": 1008, "num_steps_trained_this_iter": 32, "agent_timesteps_total": 1006, "timers": {"training_iteration_time_ms": 49.6, "load_time_ms": 0.0, "load_throughput": 0.0, "learn_time_ms": 248.107, "learn_throughput": 128.977, "synch_weights_time_ms": 4.0}, "counters": {"num_env_steps_sampled": 1008, "num_env_steps_trained": 32, "num_agent_steps_sampled": 1006, "num_agent_steps_trained": 32, "last_target_update_ts": 1008, "num_target_updates": 1}, "done": false, "episodes_total": 2, "training_iteration": 1, "trial_id": "0ed51_00000", "experiment_id": "d8668fa6b1054a0c9b69c0d1b9ec4fc1", "date": "2022-09-11_15-52-43", "timestamp": 1662886363, "time_this_iter_s": 1.388399600982666, "time_total_s": 1.388399600982666, "pid": 5160, "hostname": "XorgWorkstation", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "my_env", "env_config": {}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "num_workers": 3, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "ignore_worker_failures": false, "recreate_failed_workers": false, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 0.0005, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "my_env", "env_config": {}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "num_workers": 3, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "ignore_worker_failures": false, "recreate_failed_workers": false, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 0.0005, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": {"explore": false}, "off_policy_estimation_methods": {}, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": 1, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 1000, "logger_creator": null, "logger_config": null, "log_level": "INFO", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": -1, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": null, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "min_time_s_per_reporting": -1, "min_train_timesteps_per_reporting": -1, "min_sample_timesteps_per_reporting": -1, "input_evaluation": -1, "target_network_update_freq": 500, "replay_buffer_config": {"type": "<class 'ray.rllib.utils.replay_buffers.multi_agent_prioritized_replay_buffer.MultiAgentPrioritizedReplayBuffer'>", "prioritized_replay": -1, "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "worker_side_prioritization": false, "replay_mode": "independent"}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "input": "sampler", "multiagent": {"policies": {"attacker": "<ray.rllib.policy.policy.PolicySpec object at 0x000002391529BAF0>", "defender": "<ray.rllib.policy.policy.PolicySpec object at 0x00000239152687F0>"}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x00000239152188B0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "tf", "num_cpus_for_driver": 1}, "off_policy_estimation_methods": {}, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": 1, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 1000, "logger_creator": null, "logger_config": null, "log_level": "INFO", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": -1, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": null, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "min_time_s_per_reporting": -1, "min_train_timesteps_per_reporting": -1, "min_sample_timesteps_per_reporting": -1, "input_evaluation": -1, "target_network_update_freq": 500, "replay_buffer_config": {"type": "<class 'ray.rllib.utils.replay_buffers.multi_agent_prioritized_replay_buffer.MultiAgentPrioritizedReplayBuffer'>", "prioritized_replay": -1, "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "worker_side_prioritization": false, "replay_mode": "independent"}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "input": "sampler", "multiagent": {"policies": {"attacker": "<ray.rllib.policy.policy.PolicySpec object at 0x0000023915268700>", "defender": "<ray.rllib.policy.policy.PolicySpec object at 0x0000023915224640>"}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x00000239152188B0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "tf", "num_cpus_for_driver": 1}, "time_since_restore": 1.388399600982666, "timesteps_since_restore": 0, "iterations_since_restore": 1, "warmup_time": 10.173219442367554, "perf": {"cpu_util_percent": 6.449999999999999, "ram_util_percent": 50.5}}
{"custom_metrics": {}, "episode_media": {}, "num_recreated_workers": 0, "info": {"learner": {"attacker": {"learner_stats": {"cur_lr": 0.0005000000237487257, "mean_q": -1.7036335468292236, "min_q": -2.5997822284698486, "max_q": -0.5316320061683655, "mean_td_error": -0.38016828894615173, "model": {}}, "td_error": [-0.23056018352508545, 0.345949649810791, 0.5125994682312012, -0.9471123218536377, -1.3379170894622803, -0.17649328708648682, -0.421414852142334, 0.2987505793571472, -1.0790001153945923, 0.23574864864349365, -0.6966888904571533, -0.6551437377929688, -0.531048059463501, -0.8032495975494385, -0.11271786689758301, -0.48439502716064453], "custom_metrics": {}, "num_agent_steps_trained": 16.0}, "defender": {"learner_stats": {"cur_lr": 0.0005000000237487257, "mean_q": -0.6059238910675049, "min_q": -1.0689895153045654, "max_q": -0.1305912733078003, "mean_td_error": -0.4076606035232544, "model": {}}, "td_error": [-0.5116075873374939, -1.2464393377304077, -0.10825590044260025, -0.6593655347824097, -0.2349751591682434, -0.3530797064304352, 0.030555829405784607, -0.8046577572822571, 0.12479600310325623, 0.05312886834144592, -0.14398783445358276, -0.7876107096672058, 0.2438957691192627, -0.8504810929298401, -0.5116075873374939, -0.7628777027130127], "custom_metrics": {}, "num_agent_steps_trained": 16.0}}, "num_env_steps_sampled": 2016, "num_env_steps_trained": 2720, "num_agent_steps_sampled": 2013, "num_agent_steps_trained": 2720, "last_target_update_ts": 2016, "num_target_updates": 3}, "sampler_results": {"episode_reward_max": -153.0333333333333, "episode_reward_min": -212.33333333333343, "episode_reward_mean": -178.96666666666667, "episode_len_mean": 318.8333333333333, "episode_media": {}, "episodes_this_iter": 4, "policy_reward_min": {"attacker": -196.13333333333338, "defender": -16.5}, "policy_reward_max": {"attacker": -144.53333333333322, "defender": -8.5}, "policy_reward_mean": {"attacker": -166.63333333333335, "defender": -12.333333333333334}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-188.7999999999999, -153.0333333333333, -212.33333333333343, -186.60000000000008, -155.5000000000001, -177.53333333333327], "episode_lengths": [309, 335, 320, 313, 367, 269], "policy_attacker_reward": [-179.69999999999987, -144.53333333333322, -196.13333333333338, -170.10000000000008, -146.3000000000001, -163.03333333333327], "policy_defender_reward": [-9.100000000000001, -8.5, -16.200000000000003, -16.5, -9.2, -14.5]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.33547535433310127, "mean_inference_ms": 0.8052076292077418, "mean_action_processing_ms": 0.06127112863162638, "mean_env_wait_ms": 0.4704831324039059, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0}, "episode_reward_max": -153.0333333333333, "episode_reward_min": -212.33333333333343, "episode_reward_mean": -178.96666666666667, "episode_len_mean": 318.8333333333333, "episodes_this_iter": 4, "policy_reward_min": {"attacker": -196.13333333333338, "defender": -16.5}, "policy_reward_max": {"attacker": -144.53333333333322, "defender": -8.5}, "policy_reward_mean": {"attacker": -166.63333333333335, "defender": -12.333333333333334}, "hist_stats": {"episode_reward": [-188.7999999999999, -153.0333333333333, -212.33333333333343, -186.60000000000008, -155.5000000000001, -177.53333333333327], "episode_lengths": [309, 335, 320, 313, 367, 269], "policy_attacker_reward": [-179.69999999999987, -144.53333333333322, -196.13333333333338, -170.10000000000008, -146.3000000000001, -163.03333333333327], "policy_defender_reward": [-9.100000000000001, -8.5, -16.200000000000003, -16.5, -9.2, -14.5]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.33547535433310127, "mean_inference_ms": 0.8052076292077418, "mean_action_processing_ms": 0.06127112863162638, "mean_env_wait_ms": 0.4704831324039059, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "num_healthy_workers": 3, "num_agent_steps_sampled": 2013, "num_agent_steps_trained": 2720, "num_env_steps_sampled": 2016, "num_env_steps_trained": 2720, "num_env_steps_sampled_this_iter": 1008, "num_env_steps_trained_this_iter": 2688, "timesteps_total": 2016, "num_steps_trained_this_iter": 2688, "agent_timesteps_total": 2013, "timers": {"training_iteration_time_ms": 25.918, "load_time_ms": 0.0, "load_throughput": 0.0, "learn_time_ms": 3.23, "learn_throughput": 9906.025, "synch_weights_time_ms": 2.264}, "counters": {"num_env_steps_sampled": 2016, "num_env_steps_trained": 2720, "num_agent_steps_sampled": 2013, "num_agent_steps_trained": 2720, "last_target_update_ts": 2016, "num_target_updates": 3}, "done": false, "episodes_total": 6, "training_iteration": 2, "trial_id": "0ed51_00000", "experiment_id": "d8668fa6b1054a0c9b69c0d1b9ec4fc1", "date": "2022-09-11_15-52-45", "timestamp": 1662886365, "time_this_iter_s": 2.31219482421875, "time_total_s": 3.700594425201416, "pid": 5160, "hostname": "XorgWorkstation", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "my_env", "env_config": {}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "num_workers": 3, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "ignore_worker_failures": false, "recreate_failed_workers": false, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 0.0005, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "my_env", "env_config": {}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "num_workers": 3, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "ignore_worker_failures": false, "recreate_failed_workers": false, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 0.0005, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": {"explore": false}, "off_policy_estimation_methods": {}, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": 1, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 1000, "logger_creator": null, "logger_config": null, "log_level": "INFO", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": -1, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": null, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "min_time_s_per_reporting": -1, "min_train_timesteps_per_reporting": -1, "min_sample_timesteps_per_reporting": -1, "input_evaluation": -1, "target_network_update_freq": 500, "replay_buffer_config": {"type": "<class 'ray.rllib.utils.replay_buffers.multi_agent_prioritized_replay_buffer.MultiAgentPrioritizedReplayBuffer'>", "prioritized_replay": -1, "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "worker_side_prioritization": false, "replay_mode": "independent"}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "input": "sampler", "multiagent": {"policies": {"attacker": "<ray.rllib.policy.policy.PolicySpec object at 0x00000239152A4460>", "defender": "<ray.rllib.policy.policy.PolicySpec object at 0x00000239152241F0>"}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x00000239151A5EE0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "tf", "num_cpus_for_driver": 1}, "off_policy_estimation_methods": {}, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": 1, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 1000, "logger_creator": null, "logger_config": null, "log_level": "INFO", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": -1, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": null, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "min_time_s_per_reporting": -1, "min_train_timesteps_per_reporting": -1, "min_sample_timesteps_per_reporting": -1, "input_evaluation": -1, "target_network_update_freq": 500, "replay_buffer_config": {"type": "<class 'ray.rllib.utils.replay_buffers.multi_agent_prioritized_replay_buffer.MultiAgentPrioritizedReplayBuffer'>", "prioritized_replay": -1, "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "worker_side_prioritization": false, "replay_mode": "independent"}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "input": "sampler", "multiagent": {"policies": {"attacker": "<ray.rllib.policy.policy.PolicySpec object at 0x00000239152240D0>", "defender": "<ray.rllib.policy.policy.PolicySpec object at 0x00000239151FC6A0>"}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x00000239151A5EE0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "tf", "num_cpus_for_driver": 1}, "time_since_restore": 3.700594425201416, "timesteps_since_restore": 0, "iterations_since_restore": 2, "warmup_time": 10.173219442367554, "perf": {"cpu_util_percent": 6.875, "ram_util_percent": 50.95}}
