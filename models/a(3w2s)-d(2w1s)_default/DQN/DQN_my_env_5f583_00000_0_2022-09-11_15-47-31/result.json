{"custom_metrics": {}, "episode_media": {}, "num_recreated_workers": 0, "info": {"learner": {"attacker": {"learner_stats": {"cur_lr": 0.0005000000237487257, "mean_q": 0.44909167289733887, "min_q": -0.08013948798179626, "max_q": 0.8695144653320312, "mean_td_error": 1.7275772094726562, "model": {}}, "td_error": [1.2284936904907227, 2.2670953273773193, 1.6108683347702026, 0.5605696439743042, 2.249356746673584, 2.4483251571655273, 1.5120798349380493, 0.4151151776313782, 1.0053235292434692, 1.8813647031784058, 1.6192972660064697, 2.4790964126586914, 1.611106276512146, 1.3127479553222656, 2.1252198219299316, 3.315174102783203], "custom_metrics": {}, "num_agent_steps_trained": 16.0}, "defender": {"learner_stats": {"cur_lr": 0.0005000000237487257, "mean_q": 0.0700332373380661, "min_q": -1.1464853286743164, "max_q": 0.48381489515304565, "mean_td_error": 0.6023043394088745, "model": {}}, "td_error": [0.42954790592193604, 0.6222816705703735, 1.4056657552719116, 1.924276351928711, 1.0488357543945312, 0.8422557711601257, 0.5336731672286987, 1.9544106721878052, 1.115217685699463, 1.297369122505188, 0.01142151653766632, 0.12042795866727829, -1.39909029006958, 0.13338947296142578, 0.047172144055366516, -0.44998490810394287], "custom_metrics": {}, "num_agent_steps_trained": 16.0}}, "num_env_steps_sampled": 1008, "num_env_steps_trained": 32, "num_agent_steps_sampled": 1005, "num_agent_steps_trained": 32, "last_target_update_ts": 1008, "num_target_updates": 1}, "sampler_results": {"episode_reward_max": -126.73333333333342, "episode_reward_min": -201.73333333333355, "episode_reward_mean": -171.7777777777779, "episode_len_mean": 300.3333333333333, "episode_media": {}, "episodes_this_iter": 3, "policy_reward_min": {"attacker": -185.36666666666673, "defender": -17.1}, "policy_reward_max": {"attacker": -124.43333333333341, "defender": -1.4999999999999998}, "policy_reward_mean": {"attacker": -164.81111111111122, "defender": -6.966666666666668}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-186.86666666666676, -201.73333333333355, -126.73333333333342], "episode_lengths": [283, 303, 315], "policy_attacker_reward": [-185.36666666666673, -184.63333333333352, -124.43333333333341], "policy_defender_reward": [-1.4999999999999998, -17.1, -2.3]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.3022725457135813, "mean_inference_ms": 0.7704518786995393, "mean_action_processing_ms": 0.058105980017536585, "mean_env_wait_ms": 0.5470449445745239, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0}, "episode_reward_max": -126.73333333333342, "episode_reward_min": -201.73333333333355, "episode_reward_mean": -171.7777777777779, "episode_len_mean": 300.3333333333333, "episodes_this_iter": 3, "policy_reward_min": {"attacker": -185.36666666666673, "defender": -17.1}, "policy_reward_max": {"attacker": -124.43333333333341, "defender": -1.4999999999999998}, "policy_reward_mean": {"attacker": -164.81111111111122, "defender": -6.966666666666668}, "hist_stats": {"episode_reward": [-186.86666666666676, -201.73333333333355, -126.73333333333342], "episode_lengths": [283, 303, 315], "policy_attacker_reward": [-185.36666666666673, -184.63333333333352, -124.43333333333341], "policy_defender_reward": [-1.4999999999999998, -17.1, -2.3]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.3022725457135813, "mean_inference_ms": 0.7704518786995393, "mean_action_processing_ms": 0.058105980017536585, "mean_env_wait_ms": 0.5470449445745239, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "num_healthy_workers": 3, "num_agent_steps_sampled": 1005, "num_agent_steps_trained": 32, "num_env_steps_sampled": 1008, "num_env_steps_trained": 32, "num_env_steps_sampled_this_iter": 1008, "num_env_steps_trained_this_iter": 32, "timesteps_total": 1008, "num_steps_trained_this_iter": 32, "agent_timesteps_total": 1005, "timers": {"training_iteration_time_ms": 43.497, "load_time_ms": 0.0, "load_throughput": 0.0, "learn_time_ms": 253.583, "learn_throughput": 126.191, "synch_weights_time_ms": 3.0}, "counters": {"num_env_steps_sampled": 1008, "num_env_steps_trained": 32, "num_agent_steps_sampled": 1005, "num_agent_steps_trained": 32, "last_target_update_ts": 1008, "num_target_updates": 1}, "done": false, "episodes_total": 3, "training_iteration": 1, "trial_id": "5f583_00000", "experiment_id": "d83cb2d89bc543feb18deca748a0082f", "date": "2022-09-11_15-47-47", "timestamp": 1662886067, "time_this_iter_s": 1.316469669342041, "time_total_s": 1.316469669342041, "pid": 14740, "hostname": "XorgWorkstation", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "my_env", "env_config": {}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "num_workers": 3, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "ignore_worker_failures": false, "recreate_failed_workers": false, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 0.0005, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "my_env", "env_config": {}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "num_workers": 3, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "ignore_worker_failures": false, "recreate_failed_workers": false, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 0.0005, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": {"explore": false}, "off_policy_estimation_methods": {}, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": 1, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 1000, "logger_creator": null, "logger_config": null, "log_level": "INFO", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": -1, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": null, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "min_time_s_per_reporting": -1, "min_train_timesteps_per_reporting": -1, "min_sample_timesteps_per_reporting": -1, "input_evaluation": -1, "target_network_update_freq": 500, "replay_buffer_config": {"type": "<class 'ray.rllib.utils.replay_buffers.multi_agent_prioritized_replay_buffer.MultiAgentPrioritizedReplayBuffer'>", "prioritized_replay": -1, "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "worker_side_prioritization": false, "replay_mode": "independent"}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "input": "sampler", "multiagent": {"policies": {"attacker": "<ray.rllib.policy.policy.PolicySpec object at 0x000002958037DAF0>", "defender": "<ray.rllib.policy.policy.PolicySpec object at 0x00000295803483A0>"}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x00000295802F79D0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "tf", "num_cpus_for_driver": 1}, "off_policy_estimation_methods": {}, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": 1, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 1000, "logger_creator": null, "logger_config": null, "log_level": "INFO", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": -1, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": null, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "min_time_s_per_reporting": -1, "min_train_timesteps_per_reporting": -1, "min_sample_timesteps_per_reporting": -1, "input_evaluation": -1, "target_network_update_freq": 500, "replay_buffer_config": {"type": "<class 'ray.rllib.utils.replay_buffers.multi_agent_prioritized_replay_buffer.MultiAgentPrioritizedReplayBuffer'>", "prioritized_replay": -1, "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "worker_side_prioritization": false, "replay_mode": "independent"}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "input": "sampler", "multiagent": {"policies": {"attacker": "<ray.rllib.policy.policy.PolicySpec object at 0x00000295803482B0>", "defender": "<ray.rllib.policy.policy.PolicySpec object at 0x0000029580306640>"}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x00000295802F79D0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "tf", "num_cpus_for_driver": 1}, "time_since_restore": 1.316469669342041, "timesteps_since_restore": 0, "iterations_since_restore": 1, "warmup_time": 9.31046748161316, "perf": {"cpu_util_percent": 5.15, "ram_util_percent": 50.1}}
{"custom_metrics": {}, "episode_media": {}, "num_recreated_workers": 0, "info": {"learner": {"attacker": {"learner_stats": {"cur_lr": 0.0005000000237487257, "mean_q": -1.9469465017318726, "min_q": -2.5161521434783936, "max_q": -0.9229151606559753, "mean_td_error": -0.0006304457783699036, "model": {}}, "td_error": [0.1647546887397766, 0.7591981887817383, -0.10566186904907227, -0.1851179599761963, 0.23706555366516113, -0.6427563428878784, -0.16267967224121094, -0.801032304763794, 0.320587158203125, -0.31389427185058594, 1.6720421314239502, -0.5338892936706543, -0.6582597494125366, 0.24032342433929443, 0.12145841121673584, -0.12222516536712646], "custom_metrics": {}, "num_agent_steps_trained": 16.0}, "defender": {"learner_stats": {"cur_lr": 0.0005000000237487257, "mean_q": -1.3098580837249756, "min_q": -1.842764973640442, "max_q": -0.8553005456924438, "mean_td_error": -0.16809356212615967, "model": {}}, "td_error": [-0.036649465560913086, 0.030219554901123047, -0.24790918827056885, -0.25692129135131836, -0.5102376937866211, 0.04925966262817383, -0.6743541955947876, -0.453110933303833, 1.0678956508636475, -0.2500550150871277, -0.4800484776496887, -0.6757398843765259, -0.12766385078430176, 0.13846611976623535, -0.6874460577964783, 0.42479801177978516], "custom_metrics": {}, "num_agent_steps_trained": 16.0}}, "num_env_steps_sampled": 2016, "num_env_steps_trained": 2720, "num_agent_steps_sampled": 2013, "num_agent_steps_trained": 2720, "last_target_update_ts": 2016, "num_target_updates": 3}, "sampler_results": {"episode_reward_max": -126.73333333333342, "episode_reward_min": -201.73333333333355, "episode_reward_mean": -181.0466666666667, "episode_len_mean": 305.8, "episode_media": {}, "episodes_this_iter": 2, "policy_reward_min": {"attacker": -191.56666666666655, "defender": -17.1}, "policy_reward_max": {"attacker": -124.43333333333341, "defender": -1.4999999999999998}, "policy_reward_mean": {"attacker": -173.2066666666667, "defender": -7.840000000000001}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-186.86666666666676, -201.73333333333355, -126.73333333333342, -190.63333333333333, -199.26666666666654], "episode_lengths": [283, 303, 315, 300, 328], "policy_attacker_reward": [-185.36666666666673, -184.63333333333352, -124.43333333333341, -180.03333333333336, -191.56666666666655], "policy_defender_reward": [-1.4999999999999998, -17.1, -2.3, -10.600000000000001, -7.699999999999999]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.3068316412296033, "mean_inference_ms": 0.7140963408291668, "mean_action_processing_ms": 0.06045762763276784, "mean_env_wait_ms": 0.5383804387608662, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0}, "episode_reward_max": -126.73333333333342, "episode_reward_min": -201.73333333333355, "episode_reward_mean": -181.0466666666667, "episode_len_mean": 305.8, "episodes_this_iter": 2, "policy_reward_min": {"attacker": -191.56666666666655, "defender": -17.1}, "policy_reward_max": {"attacker": -124.43333333333341, "defender": -1.4999999999999998}, "policy_reward_mean": {"attacker": -173.2066666666667, "defender": -7.840000000000001}, "hist_stats": {"episode_reward": [-186.86666666666676, -201.73333333333355, -126.73333333333342, -190.63333333333333, -199.26666666666654], "episode_lengths": [283, 303, 315, 300, 328], "policy_attacker_reward": [-185.36666666666673, -184.63333333333352, -124.43333333333341, -180.03333333333336, -191.56666666666655], "policy_defender_reward": [-1.4999999999999998, -17.1, -2.3, -10.600000000000001, -7.699999999999999]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.3068316412296033, "mean_inference_ms": 0.7140963408291668, "mean_action_processing_ms": 0.06045762763276784, "mean_env_wait_ms": 0.5383804387608662, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "num_healthy_workers": 3, "num_agent_steps_sampled": 2013, "num_agent_steps_trained": 2720, "num_env_steps_sampled": 2016, "num_env_steps_trained": 2720, "num_env_steps_sampled_this_iter": 1008, "num_env_steps_trained_this_iter": 2688, "timesteps_total": 2016, "num_steps_trained_this_iter": 2688, "agent_timesteps_total": 2013, "timers": {"training_iteration_time_ms": 24.521, "load_time_ms": 0.1, "load_throughput": 319870.658, "learn_time_ms": 3.248, "learn_throughput": 9851.927, "synch_weights_time_ms": 2.361}, "counters": {"num_env_steps_sampled": 2016, "num_env_steps_trained": 2720, "num_agent_steps_sampled": 2013, "num_agent_steps_trained": 2720, "last_target_update_ts": 2016, "num_target_updates": 3}, "done": false, "episodes_total": 5, "training_iteration": 2, "trial_id": "5f583_00000", "experiment_id": "d83cb2d89bc543feb18deca748a0082f", "date": "2022-09-11_15-47-49", "timestamp": 1662886069, "time_this_iter_s": 2.2401323318481445, "time_total_s": 3.5566020011901855, "pid": 14740, "hostname": "XorgWorkstation", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "my_env", "env_config": {}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "num_workers": 3, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "ignore_worker_failures": false, "recreate_failed_workers": false, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 0.0005, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "my_env", "env_config": {}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "num_workers": 3, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "ignore_worker_failures": false, "recreate_failed_workers": false, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 0.0005, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": {"explore": false}, "off_policy_estimation_methods": {}, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": 1, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 1000, "logger_creator": null, "logger_config": null, "log_level": "INFO", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": -1, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": null, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "min_time_s_per_reporting": -1, "min_train_timesteps_per_reporting": -1, "min_sample_timesteps_per_reporting": -1, "input_evaluation": -1, "target_network_update_freq": 500, "replay_buffer_config": {"type": "<class 'ray.rllib.utils.replay_buffers.multi_agent_prioritized_replay_buffer.MultiAgentPrioritizedReplayBuffer'>", "prioritized_replay": -1, "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "worker_side_prioritization": false, "replay_mode": "independent"}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "input": "sampler", "multiagent": {"policies": {"attacker": "<ray.rllib.policy.policy.PolicySpec object at 0x00000295803824C0>", "defender": "<ray.rllib.policy.policy.PolicySpec object at 0x00000295803061F0>"}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x00000295802F7EE0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "tf", "num_cpus_for_driver": 1}, "off_policy_estimation_methods": {}, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": 1, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 1000, "logger_creator": null, "logger_config": null, "log_level": "INFO", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": -1, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": null, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "min_time_s_per_reporting": -1, "min_train_timesteps_per_reporting": -1, "min_sample_timesteps_per_reporting": -1, "input_evaluation": -1, "target_network_update_freq": 500, "replay_buffer_config": {"type": "<class 'ray.rllib.utils.replay_buffers.multi_agent_prioritized_replay_buffer.MultiAgentPrioritizedReplayBuffer'>", "prioritized_replay": -1, "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "worker_side_prioritization": false, "replay_mode": "independent"}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "input": "sampler", "multiagent": {"policies": {"attacker": "<ray.rllib.policy.policy.PolicySpec object at 0x00000295803060D0>", "defender": "<ray.rllib.policy.policy.PolicySpec object at 0x00000295802DD670>"}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x00000295802F7EE0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "tf", "num_cpus_for_driver": 1}, "time_since_restore": 3.5566020011901855, "timesteps_since_restore": 0, "iterations_since_restore": 2, "warmup_time": 9.31046748161316, "perf": {"cpu_util_percent": 4.066666666666667, "ram_util_percent": 50.26666666666667}}
{"custom_metrics": {}, "episode_media": {}, "num_recreated_workers": 0, "info": {"learner": {"attacker": {"learner_stats": {"cur_lr": 0.0005000000237487257, "mean_q": -2.4258837699890137, "min_q": -4.521066188812256, "max_q": -1.1029967069625854, "mean_td_error": -0.06507973372936249, "model": {}}, "td_error": [0.21274590492248535, 0.8020243644714355, -0.012330055236816406, -0.05688011646270752, -0.5859415531158447, 0.055187225341796875, 0.3642120361328125, -0.41079264879226685, 0.5681381225585938, 0.05145835876464844, 1.1112685203552246, -0.5227102041244507, -0.46027278900146484, -0.31398797035217285, -1.9702279567718506, 0.1268329620361328], "custom_metrics": {}, "num_agent_steps_trained": 16.0}, "defender": {"learner_stats": {"cur_lr": 0.0005000000237487257, "mean_q": -1.2907174825668335, "min_q": -1.7336435317993164, "max_q": -0.5336799621582031, "mean_td_error": -0.02455076202750206, "model": {}}, "td_error": [-0.12260687351226807, -0.3100130558013916, 0.2615605592727661, -0.2140224575996399, 0.7269456386566162, -0.11283838748931885, -0.25394999980926514, -0.1566981077194214, 0.029308795928955078, -0.2701512575149536, -0.09181547164916992, 0.5153956413269043, -0.9169138669967651, 0.7833216190338135, -0.5336799621582031, 0.2733449935913086], "custom_metrics": {}, "num_agent_steps_trained": 16.0}}, "num_env_steps_sampled": 3024, "num_env_steps_trained": 5408, "num_agent_steps_sampled": 3021, "num_agent_steps_trained": 5408, "last_target_update_ts": 3024, "num_target_updates": 5}, "sampler_results": {"episode_reward_max": -126.73333333333342, "episode_reward_min": -201.73333333333355, "episode_reward_mean": -175.6111111111112, "episode_len_mean": 315.22222222222223, "episode_media": {}, "episodes_this_iter": 4, "policy_reward_min": {"attacker": -192.93333333333337, "defender": -17.1}, "policy_reward_max": {"attacker": -124.43333333333341, "defender": -1.4999999999999998}, "policy_reward_mean": {"attacker": -168.04444444444454, "defender": -7.566666666666667}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-186.86666666666676, -201.73333333333355, -126.73333333333342, -190.63333333333333, -199.26666666666654, -154.26666666666696, -168.16666666666674, -152.5000000000002, -200.3333333333335], "episode_lengths": [283, 303, 315, 300, 328, 333, 292, 369, 314], "policy_attacker_reward": [-185.36666666666673, -184.63333333333352, -124.43333333333341, -180.03333333333336, -191.56666666666655, -143.86666666666696, -163.36666666666673, -146.2000000000002, -192.93333333333337], "policy_defender_reward": [-1.4999999999999998, -17.1, -2.3, -10.600000000000001, -7.699999999999999, -10.400000000000002, -4.800000000000001, -6.299999999999999, -7.400000000000009]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.29574283415087815, "mean_inference_ms": 0.6594932486227864, "mean_action_processing_ms": 0.05862735024756191, "mean_env_wait_ms": 0.5242324414785685, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0}, "episode_reward_max": -126.73333333333342, "episode_reward_min": -201.73333333333355, "episode_reward_mean": -175.6111111111112, "episode_len_mean": 315.22222222222223, "episodes_this_iter": 4, "policy_reward_min": {"attacker": -192.93333333333337, "defender": -17.1}, "policy_reward_max": {"attacker": -124.43333333333341, "defender": -1.4999999999999998}, "policy_reward_mean": {"attacker": -168.04444444444454, "defender": -7.566666666666667}, "hist_stats": {"episode_reward": [-186.86666666666676, -201.73333333333355, -126.73333333333342, -190.63333333333333, -199.26666666666654, -154.26666666666696, -168.16666666666674, -152.5000000000002, -200.3333333333335], "episode_lengths": [283, 303, 315, 300, 328, 333, 292, 369, 314], "policy_attacker_reward": [-185.36666666666673, -184.63333333333352, -124.43333333333341, -180.03333333333336, -191.56666666666655, -143.86666666666696, -163.36666666666673, -146.2000000000002, -192.93333333333337], "policy_defender_reward": [-1.4999999999999998, -17.1, -2.3, -10.600000000000001, -7.699999999999999, -10.400000000000002, -4.800000000000001, -6.299999999999999, -7.400000000000009]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.29574283415087815, "mean_inference_ms": 0.6594932486227864, "mean_action_processing_ms": 0.05862735024756191, "mean_env_wait_ms": 0.5242324414785685, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "num_healthy_workers": 3, "num_agent_steps_sampled": 3021, "num_agent_steps_trained": 5408, "num_env_steps_sampled": 3024, "num_env_steps_trained": 5408, "num_env_steps_sampled_this_iter": 1008, "num_env_steps_trained_this_iter": 2688, "timesteps_total": 3024, "num_steps_trained_this_iter": 2688, "agent_timesteps_total": 3021, "timers": {"training_iteration_time_ms": 24.215, "load_time_ms": 0.201, "load_throughput": 159479.24, "learn_time_ms": 3.264, "learn_throughput": 9802.567, "synch_weights_time_ms": 2.642}, "counters": {"num_env_steps_sampled": 3024, "num_env_steps_trained": 5408, "num_agent_steps_sampled": 3021, "num_agent_steps_trained": 5408, "last_target_update_ts": 3024, "num_target_updates": 5}, "done": false, "episodes_total": 9, "training_iteration": 3, "trial_id": "5f583_00000", "experiment_id": "d83cb2d89bc543feb18deca748a0082f", "date": "2022-09-11_15-47-51", "timestamp": 1662886071, "time_this_iter_s": 2.077894687652588, "time_total_s": 5.634496688842773, "pid": 14740, "hostname": "XorgWorkstation", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "my_env", "env_config": {}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "num_workers": 3, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "ignore_worker_failures": false, "recreate_failed_workers": false, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 0.0005, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "my_env", "env_config": {}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "num_workers": 3, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "ignore_worker_failures": false, "recreate_failed_workers": false, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 0.0005, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": {"explore": false}, "off_policy_estimation_methods": {}, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": 1, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 1000, "logger_creator": null, "logger_config": null, "log_level": "INFO", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": -1, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": null, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "min_time_s_per_reporting": -1, "min_train_timesteps_per_reporting": -1, "min_sample_timesteps_per_reporting": -1, "input_evaluation": -1, "target_network_update_freq": 500, "replay_buffer_config": {"type": "<class 'ray.rllib.utils.replay_buffers.multi_agent_prioritized_replay_buffer.MultiAgentPrioritizedReplayBuffer'>", "prioritized_replay": -1, "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "worker_side_prioritization": false, "replay_mode": "independent"}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "input": "sampler", "multiagent": {"policies": {"attacker": "<ray.rllib.policy.policy.PolicySpec object at 0x00000295802FFE20>", "defender": "<ray.rllib.policy.policy.PolicySpec object at 0x0000029580382D90>"}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x00000295B548DCA0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "tf", "num_cpus_for_driver": 1}, "off_policy_estimation_methods": {}, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": 1, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 1000, "logger_creator": null, "logger_config": null, "log_level": "INFO", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": -1, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": null, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "min_time_s_per_reporting": -1, "min_train_timesteps_per_reporting": -1, "min_sample_timesteps_per_reporting": -1, "input_evaluation": -1, "target_network_update_freq": 500, "replay_buffer_config": {"type": "<class 'ray.rllib.utils.replay_buffers.multi_agent_prioritized_replay_buffer.MultiAgentPrioritizedReplayBuffer'>", "prioritized_replay": -1, "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "worker_side_prioritization": false, "replay_mode": "independent"}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "input": "sampler", "multiagent": {"policies": {"attacker": "<ray.rllib.policy.policy.PolicySpec object at 0x00000295803820D0>", "defender": "<ray.rllib.policy.policy.PolicySpec object at 0x0000029580326490>"}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x00000295B548DCA0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "tf", "num_cpus_for_driver": 1}, "time_since_restore": 5.634496688842773, "timesteps_since_restore": 0, "iterations_since_restore": 3, "warmup_time": 9.31046748161316, "perf": {"cpu_util_percent": 4.766666666666667, "ram_util_percent": 50.300000000000004}}
{"custom_metrics": {}, "episode_media": {}, "num_recreated_workers": 0, "info": {"learner": {"attacker": {"learner_stats": {"cur_lr": 0.0005000000237487257, "mean_q": -3.405423164367676, "min_q": -5.227869033813477, "max_q": -1.276560664176941, "mean_td_error": -0.0429963618516922, "model": {}}, "td_error": [0.7549171447753906, -0.4747490882873535, 0.4743039608001709, 0.5635166168212891, 1.4887323379516602, -0.7445824146270752, -0.5469570159912109, -0.7054941654205322, 0.22715353965759277, -0.14450597763061523, 0.21116101741790771, -2.1283295154571533, 0.3501896858215332, -0.08889007568359375, -0.2096848487854004, 0.2852768898010254], "custom_metrics": {}, "num_agent_steps_trained": 16.0}, "defender": {"learner_stats": {"cur_lr": 0.0005000000237487257, "mean_q": -0.9004761576652527, "min_q": -1.3561279773712158, "max_q": -0.1373724788427353, "mean_td_error": -0.08810348808765411, "model": {}}, "td_error": [-0.28357088565826416, -0.06784850358963013, 0.21556103229522705, 0.17572712898254395, -0.2934228777885437, -0.3887665867805481, -0.07635432481765747, 0.11826002597808838, -0.07369637489318848, 0.3176000714302063, -0.14400064945220947, -0.3297075629234314, 0.06596946716308594, -0.13645756244659424, -0.39996564388275146, -0.1089826226234436], "custom_metrics": {}, "num_agent_steps_trained": 16.0}}, "num_env_steps_sampled": 4032, "num_env_steps_trained": 8096, "num_agent_steps_sampled": 4029, "num_agent_steps_trained": 8096, "last_target_update_ts": 4032, "num_target_updates": 7}, "sampler_results": {"episode_reward_max": -119.16666666666663, "episode_reward_min": -201.73333333333355, "episode_reward_mean": -167.46944444444452, "episode_len_mean": 302.9166666666667, "episode_media": {}, "episodes_this_iter": 3, "policy_reward_min": {"attacker": -192.93333333333337, "defender": -17.1}, "policy_reward_max": {"attacker": -120.76666666666664, "defender": 1.6000000000000005}, "policy_reward_mean": {"attacker": -161.42777777777786, "defender": -6.041666666666668}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-186.86666666666676, -201.73333333333355, -126.73333333333342, -190.63333333333333, -199.26666666666654, -154.26666666666696, -168.16666666666674, -152.5000000000002, -200.3333333333335, -164.50000000000006, -145.46666666666667, -119.16666666666663], "episode_lengths": [283, 303, 315, 300, 328, 333, 292, 369, 314, 288, 273, 237], "policy_attacker_reward": [-185.36666666666673, -184.63333333333352, -124.43333333333341, -180.03333333333336, -191.56666666666655, -143.86666666666696, -163.36666666666673, -146.2000000000002, -192.93333333333337, -160.60000000000002, -143.36666666666667, -120.76666666666664], "policy_defender_reward": [-1.4999999999999998, -17.1, -2.3, -10.600000000000001, -7.699999999999999, -10.400000000000002, -4.800000000000001, -6.299999999999999, -7.400000000000009, -3.8999999999999995, -2.0999999999999996, 1.6000000000000005]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2933988036274861, "mean_inference_ms": 0.6391339458789832, "mean_action_processing_ms": 0.058552718863412456, "mean_env_wait_ms": 0.5130501143319804, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0}, "episode_reward_max": -119.16666666666663, "episode_reward_min": -201.73333333333355, "episode_reward_mean": -167.46944444444452, "episode_len_mean": 302.9166666666667, "episodes_this_iter": 3, "policy_reward_min": {"attacker": -192.93333333333337, "defender": -17.1}, "policy_reward_max": {"attacker": -120.76666666666664, "defender": 1.6000000000000005}, "policy_reward_mean": {"attacker": -161.42777777777786, "defender": -6.041666666666668}, "hist_stats": {"episode_reward": [-186.86666666666676, -201.73333333333355, -126.73333333333342, -190.63333333333333, -199.26666666666654, -154.26666666666696, -168.16666666666674, -152.5000000000002, -200.3333333333335, -164.50000000000006, -145.46666666666667, -119.16666666666663], "episode_lengths": [283, 303, 315, 300, 328, 333, 292, 369, 314, 288, 273, 237], "policy_attacker_reward": [-185.36666666666673, -184.63333333333352, -124.43333333333341, -180.03333333333336, -191.56666666666655, -143.86666666666696, -163.36666666666673, -146.2000000000002, -192.93333333333337, -160.60000000000002, -143.36666666666667, -120.76666666666664], "policy_defender_reward": [-1.4999999999999998, -17.1, -2.3, -10.600000000000001, -7.699999999999999, -10.400000000000002, -4.800000000000001, -6.299999999999999, -7.400000000000009, -3.8999999999999995, -2.0999999999999996, 1.6000000000000005]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2933988036274861, "mean_inference_ms": 0.6391339458789832, "mean_action_processing_ms": 0.058552718863412456, "mean_env_wait_ms": 0.5130501143319804, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "num_healthy_workers": 3, "num_agent_steps_sampled": 4029, "num_agent_steps_trained": 8096, "num_env_steps_sampled": 4032, "num_env_steps_trained": 8096, "num_env_steps_sampled_this_iter": 1008, "num_env_steps_trained_this_iter": 2688, "timesteps_total": 4032, "num_steps_trained_this_iter": 2688, "agent_timesteps_total": 4029, "timers": {"training_iteration_time_ms": 26.621, "load_time_ms": 0.1, "load_throughput": 319946.908, "learn_time_ms": 3.223, "learn_throughput": 9928.962, "synch_weights_time_ms": 2.383}, "counters": {"num_env_steps_sampled": 4032, "num_env_steps_trained": 8096, "num_agent_steps_sampled": 4029, "num_agent_steps_trained": 8096, "last_target_update_ts": 4032, "num_target_updates": 7}, "done": false, "episodes_total": 12, "training_iteration": 4, "trial_id": "5f583_00000", "experiment_id": "d83cb2d89bc543feb18deca748a0082f", "date": "2022-09-11_15-47-53", "timestamp": 1662886073, "time_this_iter_s": 2.092118501663208, "time_total_s": 7.7266151905059814, "pid": 14740, "hostname": "XorgWorkstation", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "my_env", "env_config": {}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "num_workers": 3, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "ignore_worker_failures": false, "recreate_failed_workers": false, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 0.0005, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "my_env", "env_config": {}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "num_workers": 3, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "ignore_worker_failures": false, "recreate_failed_workers": false, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 0.0005, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": {"explore": false}, "off_policy_estimation_methods": {}, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": 1, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 1000, "logger_creator": null, "logger_config": null, "log_level": "INFO", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": -1, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": null, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "min_time_s_per_reporting": -1, "min_train_timesteps_per_reporting": -1, "min_sample_timesteps_per_reporting": -1, "input_evaluation": -1, "target_network_update_freq": 500, "replay_buffer_config": {"type": "<class 'ray.rllib.utils.replay_buffers.multi_agent_prioritized_replay_buffer.MultiAgentPrioritizedReplayBuffer'>", "prioritized_replay": -1, "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "worker_side_prioritization": false, "replay_mode": "independent"}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "input": "sampler", "multiagent": {"policies": {"attacker": "<ray.rllib.policy.policy.PolicySpec object at 0x00000295803482B0>", "defender": "<ray.rllib.policy.policy.PolicySpec object at 0x00000295802FF8E0>"}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x000002958029D280>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "tf", "num_cpus_for_driver": 1}, "off_policy_estimation_methods": {}, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": 1, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 1000, "logger_creator": null, "logger_config": null, "log_level": "INFO", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": -1, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": null, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "min_time_s_per_reporting": -1, "min_train_timesteps_per_reporting": -1, "min_sample_timesteps_per_reporting": -1, "input_evaluation": -1, "target_network_update_freq": 500, "replay_buffer_config": {"type": "<class 'ray.rllib.utils.replay_buffers.multi_agent_prioritized_replay_buffer.MultiAgentPrioritizedReplayBuffer'>", "prioritized_replay": -1, "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "worker_side_prioritization": false, "replay_mode": "independent"}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "input": "sampler", "multiagent": {"policies": {"attacker": "<ray.rllib.policy.policy.PolicySpec object at 0x0000029580326400>", "defender": "<ray.rllib.policy.policy.PolicySpec object at 0x0000029580326850>"}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x000002958029D280>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "tf", "num_cpus_for_driver": 1}, "time_since_restore": 7.7266151905059814, "timesteps_since_restore": 0, "iterations_since_restore": 4, "warmup_time": 9.31046748161316, "perf": {"cpu_util_percent": 4.55, "ram_util_percent": 50.45}}
{"custom_metrics": {}, "episode_media": {}, "num_recreated_workers": 0, "info": {"learner": {"attacker": {"learner_stats": {"cur_lr": 0.0005000000237487257, "mean_q": -4.3894877433776855, "min_q": -5.490403652191162, "max_q": -2.024899959564209, "mean_td_error": 0.09762702882289886, "model": {}}, "td_error": [-0.30857229232788086, -0.6091427803039551, -0.22362136840820312, -0.48754453659057617, -0.05933713912963867, 0.37993907928466797, -0.13823151588439941, 0.6842451095581055, 0.17512893676757812, 0.038608551025390625, 0.31206607818603516, 0.9677386283874512, 0.3167235851287842, 0.19493460655212402, -0.5051488876342773, 0.8242464065551758], "custom_metrics": {}, "num_agent_steps_trained": 16.0}, "defender": {"learner_stats": {"cur_lr": 0.0005000000237487257, "mean_q": -0.7229646444320679, "min_q": -1.2942286729812622, "max_q": 0.05552887171506882, "mean_td_error": 0.045979276299476624, "model": {}}, "td_error": [0.04835021495819092, 0.34460464119911194, 0.08943329751491547, 0.0765923261642456, 0.049614787101745605, 0.38780808448791504, -0.20803296566009521, -0.3445311188697815, 0.24463921785354614, 0.17657601833343506, -0.3233620524406433, 0.06553542613983154, 0.018077731132507324, -0.10699605941772461, 0.5979483127593994, -0.38058942556381226], "custom_metrics": {}, "num_agent_steps_trained": 16.0}}, "num_env_steps_sampled": 5040, "num_env_steps_trained": 10784, "num_agent_steps_sampled": 5037, "num_agent_steps_trained": 10784, "last_target_update_ts": 5040, "num_target_updates": 9}, "sampler_results": {"episode_reward_max": -93.13333333333337, "episode_reward_min": -204.33333333333317, "episode_reward_mean": -165.63750000000005, "episode_len_mean": 301.125, "episode_media": {}, "episodes_this_iter": 4, "policy_reward_min": {"attacker": -194.86666666666667, "defender": -17.1}, "policy_reward_max": {"attacker": -86.43333333333337, "defender": 1.6000000000000005}, "policy_reward_mean": {"attacker": -159.20625000000004, "defender": -6.43125}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-186.86666666666676, -201.73333333333355, -126.73333333333342, -190.63333333333333, -199.26666666666654, -154.26666666666696, -168.16666666666674, -152.5000000000002, -200.3333333333335, -164.50000000000006, -145.46666666666667, -119.16666666666663, -93.13333333333337, -141.8333333333334, -201.2666666666667, -204.33333333333317], "episode_lengths": [283, 303, 315, 300, 328, 333, 292, 369, 314, 288, 273, 237, 151, 286, 351, 395], "policy_attacker_reward": [-185.36666666666673, -184.63333333333352, -124.43333333333341, -180.03333333333336, -191.56666666666655, -143.86666666666696, -163.36666666666673, -146.2000000000002, -192.93333333333337, -160.60000000000002, -143.36666666666667, -120.76666666666664, -86.43333333333337, -137.03333333333333, -194.86666666666667, -191.83333333333312], "policy_defender_reward": [-1.4999999999999998, -17.1, -2.3, -10.600000000000001, -7.699999999999999, -10.400000000000002, -4.800000000000001, -6.299999999999999, -7.400000000000009, -3.8999999999999995, -2.0999999999999996, 1.6000000000000005, -6.7, -4.800000000000001, -6.4, -12.5]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.29267413571513623, "mean_inference_ms": 0.6221441208325795, "mean_action_processing_ms": 0.058561520748264595, "mean_env_wait_ms": 0.5074245590040816, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0}, "episode_reward_max": -93.13333333333337, "episode_reward_min": -204.33333333333317, "episode_reward_mean": -165.63750000000005, "episode_len_mean": 301.125, "episodes_this_iter": 4, "policy_reward_min": {"attacker": -194.86666666666667, "defender": -17.1}, "policy_reward_max": {"attacker": -86.43333333333337, "defender": 1.6000000000000005}, "policy_reward_mean": {"attacker": -159.20625000000004, "defender": -6.43125}, "hist_stats": {"episode_reward": [-186.86666666666676, -201.73333333333355, -126.73333333333342, -190.63333333333333, -199.26666666666654, -154.26666666666696, -168.16666666666674, -152.5000000000002, -200.3333333333335, -164.50000000000006, -145.46666666666667, -119.16666666666663, -93.13333333333337, -141.8333333333334, -201.2666666666667, -204.33333333333317], "episode_lengths": [283, 303, 315, 300, 328, 333, 292, 369, 314, 288, 273, 237, 151, 286, 351, 395], "policy_attacker_reward": [-185.36666666666673, -184.63333333333352, -124.43333333333341, -180.03333333333336, -191.56666666666655, -143.86666666666696, -163.36666666666673, -146.2000000000002, -192.93333333333337, -160.60000000000002, -143.36666666666667, -120.76666666666664, -86.43333333333337, -137.03333333333333, -194.86666666666667, -191.83333333333312], "policy_defender_reward": [-1.4999999999999998, -17.1, -2.3, -10.600000000000001, -7.699999999999999, -10.400000000000002, -4.800000000000001, -6.299999999999999, -7.400000000000009, -3.8999999999999995, -2.0999999999999996, 1.6000000000000005, -6.7, -4.800000000000001, -6.4, -12.5]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.29267413571513623, "mean_inference_ms": 0.6221441208325795, "mean_action_processing_ms": 0.058561520748264595, "mean_env_wait_ms": 0.5074245590040816, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "num_healthy_workers": 3, "num_agent_steps_sampled": 5037, "num_agent_steps_trained": 10784, "num_env_steps_sampled": 5040, "num_env_steps_trained": 10784, "num_env_steps_sampled_this_iter": 1008, "num_env_steps_trained_this_iter": 2688, "timesteps_total": 5040, "num_steps_trained_this_iter": 2688, "agent_timesteps_total": 5037, "timers": {"training_iteration_time_ms": 29.246, "load_time_ms": 0.301, "load_throughput": 106479.752, "learn_time_ms": 3.621, "learn_throughput": 8837.556, "synch_weights_time_ms": 2.612}, "counters": {"num_env_steps_sampled": 5040, "num_env_steps_trained": 10784, "num_agent_steps_sampled": 5037, "num_agent_steps_trained": 10784, "last_target_update_ts": 5040, "num_target_updates": 9}, "done": false, "episodes_total": 16, "training_iteration": 5, "trial_id": "5f583_00000", "experiment_id": "d83cb2d89bc543feb18deca748a0082f", "date": "2022-09-11_15-47-56", "timestamp": 1662886076, "time_this_iter_s": 2.1958301067352295, "time_total_s": 9.922445297241211, "pid": 14740, "hostname": "XorgWorkstation", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "my_env", "env_config": {}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "num_workers": 3, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "ignore_worker_failures": false, "recreate_failed_workers": false, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 0.0005, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "my_env", "env_config": {}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "num_workers": 3, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "ignore_worker_failures": false, "recreate_failed_workers": false, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 0.0005, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": {"explore": false}, "off_policy_estimation_methods": {}, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": 1, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 1000, "logger_creator": null, "logger_config": null, "log_level": "INFO", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": -1, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": null, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "min_time_s_per_reporting": -1, "min_train_timesteps_per_reporting": -1, "min_sample_timesteps_per_reporting": -1, "input_evaluation": -1, "target_network_update_freq": 500, "replay_buffer_config": {"type": "<class 'ray.rllib.utils.replay_buffers.multi_agent_prioritized_replay_buffer.MultiAgentPrioritizedReplayBuffer'>", "prioritized_replay": -1, "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "worker_side_prioritization": false, "replay_mode": "independent"}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "input": "sampler", "multiagent": {"policies": {"attacker": "<ray.rllib.policy.policy.PolicySpec object at 0x0000029580382E80>", "defender": "<ray.rllib.policy.policy.PolicySpec object at 0x0000029580306190>"}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x00000295803AAB80>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "tf", "num_cpus_for_driver": 1}, "off_policy_estimation_methods": {}, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": 1, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 1000, "logger_creator": null, "logger_config": null, "log_level": "INFO", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": -1, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": null, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "min_time_s_per_reporting": -1, "min_train_timesteps_per_reporting": -1, "min_sample_timesteps_per_reporting": -1, "input_evaluation": -1, "target_network_update_freq": 500, "replay_buffer_config": {"type": "<class 'ray.rllib.utils.replay_buffers.multi_agent_prioritized_replay_buffer.MultiAgentPrioritizedReplayBuffer'>", "prioritized_replay": -1, "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "worker_side_prioritization": false, "replay_mode": "independent"}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "input": "sampler", "multiagent": {"policies": {"attacker": "<ray.rllib.policy.policy.PolicySpec object at 0x0000029580306670>", "defender": "<ray.rllib.policy.policy.PolicySpec object at 0x0000029580306AF0>"}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x00000295803AAB80>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "tf", "num_cpus_for_driver": 1}, "time_since_restore": 9.922445297241211, "timesteps_since_restore": 0, "iterations_since_restore": 5, "warmup_time": 9.31046748161316, "perf": {"cpu_util_percent": 5.866666666666667, "ram_util_percent": 50.46666666666667}}
{"custom_metrics": {}, "episode_media": {}, "num_recreated_workers": 0, "info": {"learner": {"attacker": {"learner_stats": {"cur_lr": 0.0005000000237487257, "mean_q": -6.085966110229492, "min_q": -8.944404602050781, "max_q": -4.105854511260986, "mean_td_error": -0.10898290574550629, "model": {}}, "td_error": [0.5362768173217773, -4.064404487609863, 0.08875513076782227, 0.4499049186706543, 1.3893914222717285, 0.002017498016357422, -0.29562878608703613, 1.8518157005310059, -0.2982645034790039, -0.08864688873291016, 0.16408920288085938, 0.08533430099487305, -0.8930974006652832, -0.6107873916625977, 0.06952810287475586, -0.13001012802124023], "custom_metrics": {}, "num_agent_steps_trained": 16.0}, "defender": {"learner_stats": {"cur_lr": 0.0005000000237487257, "mean_q": -0.39957576990127563, "min_q": -1.0211687088012695, "max_q": 0.14337538182735443, "mean_td_error": 0.21461689472198486, "model": {}}, "td_error": [0.37419670820236206, 0.6700702905654907, 0.08995610475540161, 0.01780158281326294, 0.29444026947021484, -0.2912829518318176, 0.5425631999969482, 0.22356611490249634, 0.8631527423858643, -0.143706277012825, 0.1585233211517334, 1.0541503429412842, -0.0969519317150116, -0.08260371536016464, -0.3792029023170471, 0.13919728994369507], "custom_metrics": {}, "num_agent_steps_trained": 16.0}}, "num_env_steps_sampled": 6048, "num_env_steps_trained": 13472, "num_agent_steps_sampled": 6045, "num_agent_steps_trained": 13472, "last_target_update_ts": 6048, "num_target_updates": 11}, "sampler_results": {"episode_reward_max": -93.13333333333337, "episode_reward_min": -228.7333333333334, "episode_reward_mean": -168.7333333333334, "episode_len_mean": 303.4736842105263, "episode_media": {}, "episodes_this_iter": 3, "policy_reward_min": {"attacker": -217.63333333333333, "defender": -17.1}, "policy_reward_max": {"attacker": -86.43333333333337, "defender": 1.6000000000000005}, "policy_reward_mean": {"attacker": -161.44912280701757, "defender": -7.28421052631579}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-186.86666666666676, -201.73333333333355, -126.73333333333342, -190.63333333333333, -199.26666666666654, -154.26666666666696, -168.16666666666674, -152.5000000000002, -200.3333333333335, -164.50000000000006, -145.46666666666667, -119.16666666666663, -93.13333333333337, -141.8333333333334, -201.2666666666667, -204.33333333333317, -151.23333333333335, -175.76666666666677, -228.7333333333334], "episode_lengths": [283, 303, 315, 300, 328, 333, 292, 369, 314, 288, 273, 237, 151, 286, 351, 395, 286, 310, 352], "policy_attacker_reward": [-185.36666666666673, -184.63333333333352, -124.43333333333341, -180.03333333333336, -191.56666666666655, -143.86666666666696, -163.36666666666673, -146.2000000000002, -192.93333333333337, -160.60000000000002, -143.36666666666667, -120.76666666666664, -86.43333333333337, -137.03333333333333, -194.86666666666667, -191.83333333333312, -134.5333333333334, -168.06666666666678, -217.63333333333333], "policy_defender_reward": [-1.4999999999999998, -17.1, -2.3, -10.600000000000001, -7.699999999999999, -10.400000000000002, -4.800000000000001, -6.299999999999999, -7.400000000000009, -3.8999999999999995, -2.0999999999999996, 1.6000000000000005, -6.7, -4.800000000000001, -6.4, -12.5, -16.700000000000003, -7.7, -11.100000000000003]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2916728338738463, "mean_inference_ms": 0.6136270910769356, "mean_action_processing_ms": 0.05848896934455201, "mean_env_wait_ms": 0.5032585075395842, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0}, "episode_reward_max": -93.13333333333337, "episode_reward_min": -228.7333333333334, "episode_reward_mean": -168.7333333333334, "episode_len_mean": 303.4736842105263, "episodes_this_iter": 3, "policy_reward_min": {"attacker": -217.63333333333333, "defender": -17.1}, "policy_reward_max": {"attacker": -86.43333333333337, "defender": 1.6000000000000005}, "policy_reward_mean": {"attacker": -161.44912280701757, "defender": -7.28421052631579}, "hist_stats": {"episode_reward": [-186.86666666666676, -201.73333333333355, -126.73333333333342, -190.63333333333333, -199.26666666666654, -154.26666666666696, -168.16666666666674, -152.5000000000002, -200.3333333333335, -164.50000000000006, -145.46666666666667, -119.16666666666663, -93.13333333333337, -141.8333333333334, -201.2666666666667, -204.33333333333317, -151.23333333333335, -175.76666666666677, -228.7333333333334], "episode_lengths": [283, 303, 315, 300, 328, 333, 292, 369, 314, 288, 273, 237, 151, 286, 351, 395, 286, 310, 352], "policy_attacker_reward": [-185.36666666666673, -184.63333333333352, -124.43333333333341, -180.03333333333336, -191.56666666666655, -143.86666666666696, -163.36666666666673, -146.2000000000002, -192.93333333333337, -160.60000000000002, -143.36666666666667, -120.76666666666664, -86.43333333333337, -137.03333333333333, -194.86666666666667, -191.83333333333312, -134.5333333333334, -168.06666666666678, -217.63333333333333], "policy_defender_reward": [-1.4999999999999998, -17.1, -2.3, -10.600000000000001, -7.699999999999999, -10.400000000000002, -4.800000000000001, -6.299999999999999, -7.400000000000009, -3.8999999999999995, -2.0999999999999996, 1.6000000000000005, -6.7, -4.800000000000001, -6.4, -12.5, -16.700000000000003, -7.7, -11.100000000000003]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2916728338738463, "mean_inference_ms": 0.6136270910769356, "mean_action_processing_ms": 0.05848896934455201, "mean_env_wait_ms": 0.5032585075395842, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "num_healthy_workers": 3, "num_agent_steps_sampled": 6045, "num_agent_steps_trained": 13472, "num_env_steps_sampled": 6048, "num_env_steps_trained": 13472, "num_env_steps_sampled_this_iter": 1008, "num_env_steps_trained_this_iter": 2688, "timesteps_total": 6048, "num_steps_trained_this_iter": 2688, "agent_timesteps_total": 6045, "timers": {"training_iteration_time_ms": 25.075, "load_time_ms": 0.15, "load_throughput": 212773.824, "learn_time_ms": 3.36, "learn_throughput": 9525.135, "synch_weights_time_ms": 2.377}, "counters": {"num_env_steps_sampled": 6048, "num_env_steps_trained": 13472, "num_agent_steps_sampled": 6045, "num_agent_steps_trained": 13472, "last_target_update_ts": 6048, "num_target_updates": 11}, "done": false, "episodes_total": 19, "training_iteration": 6, "trial_id": "5f583_00000", "experiment_id": "d83cb2d89bc543feb18deca748a0082f", "date": "2022-09-11_15-47-58", "timestamp": 1662886078, "time_this_iter_s": 2.072903871536255, "time_total_s": 11.995349168777466, "pid": 14740, "hostname": "XorgWorkstation", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "my_env", "env_config": {}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "num_workers": 3, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "ignore_worker_failures": false, "recreate_failed_workers": false, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 0.0005, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "my_env", "env_config": {}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "num_workers": 3, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "ignore_worker_failures": false, "recreate_failed_workers": false, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 0.0005, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": {"explore": false}, "off_policy_estimation_methods": {}, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": 1, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 1000, "logger_creator": null, "logger_config": null, "log_level": "INFO", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": -1, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": null, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "min_time_s_per_reporting": -1, "min_train_timesteps_per_reporting": -1, "min_sample_timesteps_per_reporting": -1, "input_evaluation": -1, "target_network_update_freq": 500, "replay_buffer_config": {"type": "<class 'ray.rllib.utils.replay_buffers.multi_agent_prioritized_replay_buffer.MultiAgentPrioritizedReplayBuffer'>", "prioritized_replay": -1, "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "worker_side_prioritization": false, "replay_mode": "independent"}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "input": "sampler", "multiagent": {"policies": {"attacker": "<ray.rllib.policy.policy.PolicySpec object at 0x0000029580326430>", "defender": "<ray.rllib.policy.policy.PolicySpec object at 0x0000029580326D90>"}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x00000295802F7F70>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "tf", "num_cpus_for_driver": 1}, "off_policy_estimation_methods": {}, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": 1, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 1000, "logger_creator": null, "logger_config": null, "log_level": "INFO", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": -1, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": null, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "min_time_s_per_reporting": -1, "min_train_timesteps_per_reporting": -1, "min_sample_timesteps_per_reporting": -1, "input_evaluation": -1, "target_network_update_freq": 500, "replay_buffer_config": {"type": "<class 'ray.rllib.utils.replay_buffers.multi_agent_prioritized_replay_buffer.MultiAgentPrioritizedReplayBuffer'>", "prioritized_replay": -1, "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "worker_side_prioritization": false, "replay_mode": "independent"}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "input": "sampler", "multiagent": {"policies": {"attacker": "<ray.rllib.policy.policy.PolicySpec object at 0x0000029580326CA0>", "defender": "<ray.rllib.policy.policy.PolicySpec object at 0x00000295803B1040>"}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x00000295802F7F70>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "tf", "num_cpus_for_driver": 1}, "time_since_restore": 11.995349168777466, "timesteps_since_restore": 0, "iterations_since_restore": 6, "warmup_time": 9.31046748161316, "perf": {"cpu_util_percent": 5.333333333333333, "ram_util_percent": 50.6}}
{"custom_metrics": {}, "episode_media": {}, "num_recreated_workers": 0, "info": {"learner": {"attacker": {"learner_stats": {"cur_lr": 0.0005000000237487257, "mean_q": -6.959433555603027, "min_q": -10.178674697875977, "max_q": -3.6004421710968018, "mean_td_error": -0.5771715641021729, "model": {}}, "td_error": [0.24224185943603516, -4.0952348709106445, -0.5579423904418945, -0.4151163101196289, 0.41956520080566406, -0.06738471984863281, 0.06612062454223633, 0.8745613098144531, -7.294571876525879, 0.579554557800293, -0.2681612968444824, -0.6651368141174316, 1.5054354667663574, 0.4523453712463379, 0.6806788444519043, -0.6916995048522949], "custom_metrics": {}, "num_agent_steps_trained": 16.0}, "defender": {"learner_stats": {"cur_lr": 0.0005000000237487257, "mean_q": -0.44236594438552856, "min_q": -0.8777965307235718, "max_q": 0.32295745611190796, "mean_td_error": 0.042504437267780304, "model": {}}, "td_error": [0.6308625936508179, -0.06892508268356323, 0.06955623626708984, -0.024523615837097168, -0.35218971967697144, -0.0824727714061737, -0.5641165971755981, 0.1672254204750061, 0.02490168809890747, 0.5972689390182495, -0.08547025918960571, 0.1551491916179657, 0.09714663028717041, 0.36350542306900024, -0.010154902935028076, -0.23769217729568481], "custom_metrics": {}, "num_agent_steps_trained": 16.0}}, "num_env_steps_sampled": 7056, "num_env_steps_trained": 16160, "num_agent_steps_sampled": 7053, "num_agent_steps_trained": 16160, "last_target_update_ts": 7056, "num_target_updates": 13}, "sampler_results": {"episode_reward_max": -93.13333333333337, "episode_reward_min": -228.7333333333334, "episode_reward_mean": -175.05000000000007, "episode_len_mean": 309.1818181818182, "episode_media": {}, "episodes_this_iter": 3, "policy_reward_min": {"attacker": -217.63333333333333, "defender": -17.1}, "policy_reward_max": {"attacker": -86.43333333333337, "defender": 1.6000000000000005}, "policy_reward_mean": {"attacker": -167.5090909090909, "defender": -7.540909090909091}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-186.86666666666676, -201.73333333333355, -126.73333333333342, -190.63333333333333, -199.26666666666654, -154.26666666666696, -168.16666666666674, -152.5000000000002, -200.3333333333335, -164.50000000000006, -145.46666666666667, -119.16666666666663, -93.13333333333337, -141.8333333333334, -201.2666666666667, -204.33333333333317, -151.23333333333335, -175.76666666666677, -228.7333333333334, -199.20000000000005, -219.76666666666682, -226.19999999999976], "episode_lengths": [283, 303, 315, 300, 328, 333, 292, 369, 314, 288, 273, 237, 151, 286, 351, 395, 286, 310, 352, 378, 304, 354], "policy_attacker_reward": [-185.36666666666673, -184.63333333333352, -124.43333333333341, -180.03333333333336, -191.56666666666655, -143.86666666666696, -163.36666666666673, -146.2000000000002, -192.93333333333337, -160.60000000000002, -143.36666666666667, -120.76666666666664, -86.43333333333337, -137.03333333333333, -194.86666666666667, -191.83333333333312, -134.5333333333334, -168.06666666666678, -217.63333333333333, -195.7, -206.06666666666678, -215.8999999999997], "policy_defender_reward": [-1.4999999999999998, -17.1, -2.3, -10.600000000000001, -7.699999999999999, -10.400000000000002, -4.800000000000001, -6.299999999999999, -7.400000000000009, -3.8999999999999995, -2.0999999999999996, 1.6000000000000005, -6.7, -4.800000000000001, -6.4, -12.5, -16.700000000000003, -7.7, -11.100000000000003, -3.5, -13.7, -10.300000000000002]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.29084741331398867, "mean_inference_ms": 0.6068508076800916, "mean_action_processing_ms": 0.05850180295199287, "mean_env_wait_ms": 0.499696817266372, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0}, "episode_reward_max": -93.13333333333337, "episode_reward_min": -228.7333333333334, "episode_reward_mean": -175.05000000000007, "episode_len_mean": 309.1818181818182, "episodes_this_iter": 3, "policy_reward_min": {"attacker": -217.63333333333333, "defender": -17.1}, "policy_reward_max": {"attacker": -86.43333333333337, "defender": 1.6000000000000005}, "policy_reward_mean": {"attacker": -167.5090909090909, "defender": -7.540909090909091}, "hist_stats": {"episode_reward": [-186.86666666666676, -201.73333333333355, -126.73333333333342, -190.63333333333333, -199.26666666666654, -154.26666666666696, -168.16666666666674, -152.5000000000002, -200.3333333333335, -164.50000000000006, -145.46666666666667, -119.16666666666663, -93.13333333333337, -141.8333333333334, -201.2666666666667, -204.33333333333317, -151.23333333333335, -175.76666666666677, -228.7333333333334, -199.20000000000005, -219.76666666666682, -226.19999999999976], "episode_lengths": [283, 303, 315, 300, 328, 333, 292, 369, 314, 288, 273, 237, 151, 286, 351, 395, 286, 310, 352, 378, 304, 354], "policy_attacker_reward": [-185.36666666666673, -184.63333333333352, -124.43333333333341, -180.03333333333336, -191.56666666666655, -143.86666666666696, -163.36666666666673, -146.2000000000002, -192.93333333333337, -160.60000000000002, -143.36666666666667, -120.76666666666664, -86.43333333333337, -137.03333333333333, -194.86666666666667, -191.83333333333312, -134.5333333333334, -168.06666666666678, -217.63333333333333, -195.7, -206.06666666666678, -215.8999999999997], "policy_defender_reward": [-1.4999999999999998, -17.1, -2.3, -10.600000000000001, -7.699999999999999, -10.400000000000002, -4.800000000000001, -6.299999999999999, -7.400000000000009, -3.8999999999999995, -2.0999999999999996, 1.6000000000000005, -6.7, -4.800000000000001, -6.4, -12.5, -16.700000000000003, -7.7, -11.100000000000003, -3.5, -13.7, -10.300000000000002]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.29084741331398867, "mean_inference_ms": 0.6068508076800916, "mean_action_processing_ms": 0.05850180295199287, "mean_env_wait_ms": 0.499696817266372, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "num_healthy_workers": 3, "num_agent_steps_sampled": 7053, "num_agent_steps_trained": 16160, "num_env_steps_sampled": 7056, "num_env_steps_trained": 16160, "num_env_steps_sampled_this_iter": 1008, "num_env_steps_trained_this_iter": 2688, "timesteps_total": 7056, "num_steps_trained_this_iter": 2688, "agent_timesteps_total": 7053, "timers": {"training_iteration_time_ms": 24.554, "load_time_ms": 0.1, "load_throughput": 319186.036, "learn_time_ms": 3.386, "learn_throughput": 9450.555, "synch_weights_time_ms": 2.408}, "counters": {"num_env_steps_sampled": 7056, "num_env_steps_trained": 16160, "num_agent_steps_sampled": 7053, "num_agent_steps_trained": 16160, "last_target_update_ts": 7056, "num_target_updates": 13}, "done": false, "episodes_total": 22, "training_iteration": 7, "trial_id": "5f583_00000", "experiment_id": "d83cb2d89bc543feb18deca748a0082f", "date": "2022-09-11_15-48-00", "timestamp": 1662886080, "time_this_iter_s": 2.0759949684143066, "time_total_s": 14.071344137191772, "pid": 14740, "hostname": "XorgWorkstation", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "my_env", "env_config": {}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "num_workers": 3, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "ignore_worker_failures": false, "recreate_failed_workers": false, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 0.0005, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "my_env", "env_config": {}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "num_workers": 3, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "ignore_worker_failures": false, "recreate_failed_workers": false, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 0.0005, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": {"explore": false}, "off_policy_estimation_methods": {}, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": 1, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 1000, "logger_creator": null, "logger_config": null, "log_level": "INFO", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": -1, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": null, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "min_time_s_per_reporting": -1, "min_train_timesteps_per_reporting": -1, "min_sample_timesteps_per_reporting": -1, "input_evaluation": -1, "target_network_update_freq": 500, "replay_buffer_config": {"type": "<class 'ray.rllib.utils.replay_buffers.multi_agent_prioritized_replay_buffer.MultiAgentPrioritizedReplayBuffer'>", "prioritized_replay": -1, "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "worker_side_prioritization": false, "replay_mode": "independent"}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "input": "sampler", "multiagent": {"policies": {"attacker": "<ray.rllib.policy.policy.PolicySpec object at 0x00000295803829D0>", "defender": "<ray.rllib.policy.policy.PolicySpec object at 0x00000295803B1760>"}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x00000295803AA8B0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "tf", "num_cpus_for_driver": 1}, "off_policy_estimation_methods": {}, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": 1, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 1000, "logger_creator": null, "logger_config": null, "log_level": "INFO", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": -1, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": null, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "min_time_s_per_reporting": -1, "min_train_timesteps_per_reporting": -1, "min_sample_timesteps_per_reporting": -1, "input_evaluation": -1, "target_network_update_freq": 500, "replay_buffer_config": {"type": "<class 'ray.rllib.utils.replay_buffers.multi_agent_prioritized_replay_buffer.MultiAgentPrioritizedReplayBuffer'>", "prioritized_replay": -1, "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "worker_side_prioritization": false, "replay_mode": "independent"}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "input": "sampler", "multiagent": {"policies": {"attacker": "<ray.rllib.policy.policy.PolicySpec object at 0x00000295803B1910>", "defender": "<ray.rllib.policy.policy.PolicySpec object at 0x00000295803B1B80>"}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x00000295803AA8B0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "tf", "num_cpus_for_driver": 1}, "time_since_restore": 14.071344137191772, "timesteps_since_restore": 0, "iterations_since_restore": 7, "warmup_time": 9.31046748161316, "perf": {"cpu_util_percent": 6.233333333333333, "ram_util_percent": 50.56666666666666}}
{"custom_metrics": {}, "episode_media": {}, "num_recreated_workers": 0, "info": {"learner": {"attacker": {"learner_stats": {"cur_lr": 0.0005000000237487257, "mean_q": -8.753271102905273, "min_q": -11.048087120056152, "max_q": -3.6810951232910156, "mean_td_error": -0.25584906339645386, "model": {}}, "td_error": [0.40520668029785156, -0.31641292572021484, 0.3009824752807617, -1.2849950790405273, -0.10494136810302734, 0.014109611511230469, -0.6436195373535156, -1.6537508964538574, 1.6023006439208984, -0.5346570014953613, -0.879206657409668, -0.10836553573608398, -1.3352422714233398, 2.5489463806152344, -0.20925021171569824, -1.8946890830993652], "custom_metrics": {}, "num_agent_steps_trained": 16.0}, "defender": {"learner_stats": {"cur_lr": 0.0005000000237487257, "mean_q": -0.36699753999710083, "min_q": -0.805659294128418, "max_q": 0.2855945825576782, "mean_td_error": 0.06705805659294128, "model": {}}, "td_error": [0.14354577660560608, 0.0026864707469940186, 0.19315141439437866, 0.13074615597724915, -0.28863781690597534, 0.06789226830005646, 0.07720541954040527, 0.21139580011367798, -0.19252480566501617, 0.024318933486938477, 0.2271651029586792, -0.06609940528869629, -0.07184535264968872, 0.34029054641723633, 0.325158953666687, -0.051520466804504395], "custom_metrics": {}, "num_agent_steps_trained": 16.0}}, "num_env_steps_sampled": 8064, "num_env_steps_trained": 18848, "num_agent_steps_sampled": 8061, "num_agent_steps_trained": 18848, "last_target_update_ts": 8064, "num_target_updates": 15}, "sampler_results": {"episode_reward_max": -93.13333333333337, "episode_reward_min": -317.6333333333334, "episode_reward_mean": -179.3638888888889, "episode_len_mean": 314.2916666666667, "episode_media": {}, "episodes_this_iter": 2, "policy_reward_min": {"attacker": -315.3333333333334, "defender": -17.1}, "policy_reward_max": {"attacker": -86.43333333333337, "defender": 1.6000000000000005}, "policy_reward_mean": {"attacker": -171.6930555555556, "defender": -7.670833333333334}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-186.86666666666676, -201.73333333333355, -126.73333333333342, -190.63333333333333, -199.26666666666654, -154.26666666666696, -168.16666666666674, -152.5000000000002, -200.3333333333335, -164.50000000000006, -145.46666666666667, -119.16666666666663, -93.13333333333337, -141.8333333333334, -201.2666666666667, -204.33333333333317, -151.23333333333335, -175.76666666666677, -228.7333333333334, -199.20000000000005, -219.76666666666682, -226.19999999999976, -136.00000000000009, -317.6333333333334], "episode_lengths": [283, 303, 315, 300, 328, 333, 292, 369, 314, 288, 273, 237, 151, 286, 351, 395, 286, 310, 352, 378, 304, 354, 300, 441], "policy_attacker_reward": [-185.36666666666673, -184.63333333333352, -124.43333333333341, -180.03333333333336, -191.56666666666655, -143.86666666666696, -163.36666666666673, -146.2000000000002, -192.93333333333337, -160.60000000000002, -143.36666666666667, -120.76666666666664, -86.43333333333337, -137.03333333333333, -194.86666666666667, -191.83333333333312, -134.5333333333334, -168.06666666666678, -217.63333333333333, -195.7, -206.06666666666678, -215.8999999999997, -120.10000000000001, -315.3333333333334], "policy_defender_reward": [-1.4999999999999998, -17.1, -2.3, -10.600000000000001, -7.699999999999999, -10.400000000000002, -4.800000000000001, -6.299999999999999, -7.400000000000009, -3.8999999999999995, -2.0999999999999996, 1.6000000000000005, -6.7, -4.800000000000001, -6.4, -12.5, -16.700000000000003, -7.7, -11.100000000000003, -3.5, -13.7, -10.300000000000002, -15.899999999999995, -2.2999999999999994]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.29043360000078405, "mean_inference_ms": 0.6026102050840128, "mean_action_processing_ms": 0.05866681023737614, "mean_env_wait_ms": 0.4975176510121407, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0}, "episode_reward_max": -93.13333333333337, "episode_reward_min": -317.6333333333334, "episode_reward_mean": -179.3638888888889, "episode_len_mean": 314.2916666666667, "episodes_this_iter": 2, "policy_reward_min": {"attacker": -315.3333333333334, "defender": -17.1}, "policy_reward_max": {"attacker": -86.43333333333337, "defender": 1.6000000000000005}, "policy_reward_mean": {"attacker": -171.6930555555556, "defender": -7.670833333333334}, "hist_stats": {"episode_reward": [-186.86666666666676, -201.73333333333355, -126.73333333333342, -190.63333333333333, -199.26666666666654, -154.26666666666696, -168.16666666666674, -152.5000000000002, -200.3333333333335, -164.50000000000006, -145.46666666666667, -119.16666666666663, -93.13333333333337, -141.8333333333334, -201.2666666666667, -204.33333333333317, -151.23333333333335, -175.76666666666677, -228.7333333333334, -199.20000000000005, -219.76666666666682, -226.19999999999976, -136.00000000000009, -317.6333333333334], "episode_lengths": [283, 303, 315, 300, 328, 333, 292, 369, 314, 288, 273, 237, 151, 286, 351, 395, 286, 310, 352, 378, 304, 354, 300, 441], "policy_attacker_reward": [-185.36666666666673, -184.63333333333352, -124.43333333333341, -180.03333333333336, -191.56666666666655, -143.86666666666696, -163.36666666666673, -146.2000000000002, -192.93333333333337, -160.60000000000002, -143.36666666666667, -120.76666666666664, -86.43333333333337, -137.03333333333333, -194.86666666666667, -191.83333333333312, -134.5333333333334, -168.06666666666678, -217.63333333333333, -195.7, -206.06666666666678, -215.8999999999997, -120.10000000000001, -315.3333333333334], "policy_defender_reward": [-1.4999999999999998, -17.1, -2.3, -10.600000000000001, -7.699999999999999, -10.400000000000002, -4.800000000000001, -6.299999999999999, -7.400000000000009, -3.8999999999999995, -2.0999999999999996, 1.6000000000000005, -6.7, -4.800000000000001, -6.4, -12.5, -16.700000000000003, -7.7, -11.100000000000003, -3.5, -13.7, -10.300000000000002, -15.899999999999995, -2.2999999999999994]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.29043360000078405, "mean_inference_ms": 0.6026102050840128, "mean_action_processing_ms": 0.05866681023737614, "mean_env_wait_ms": 0.4975176510121407, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "num_healthy_workers": 3, "num_agent_steps_sampled": 8061, "num_agent_steps_trained": 18848, "num_env_steps_sampled": 8064, "num_env_steps_trained": 18848, "num_env_steps_sampled_this_iter": 1008, "num_env_steps_trained_this_iter": 2688, "timesteps_total": 8064, "num_steps_trained_this_iter": 2688, "agent_timesteps_total": 8061, "timers": {"training_iteration_time_ms": 23.991, "load_time_ms": 0.1, "load_throughput": 320941.483, "learn_time_ms": 3.481, "learn_throughput": 9192.428, "synch_weights_time_ms": 2.29}, "counters": {"num_env_steps_sampled": 8064, "num_env_steps_trained": 18848, "num_agent_steps_sampled": 8061, "num_agent_steps_trained": 18848, "last_target_update_ts": 8064, "num_target_updates": 15}, "done": false, "episodes_total": 24, "training_iteration": 8, "trial_id": "5f583_00000", "experiment_id": "d83cb2d89bc543feb18deca748a0082f", "date": "2022-09-11_15-48-02", "timestamp": 1662886082, "time_this_iter_s": 2.057856321334839, "time_total_s": 16.12920045852661, "pid": 14740, "hostname": "XorgWorkstation", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "my_env", "env_config": {}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "num_workers": 3, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "ignore_worker_failures": false, "recreate_failed_workers": false, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 0.0005, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "my_env", "env_config": {}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "num_workers": 3, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "ignore_worker_failures": false, "recreate_failed_workers": false, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 0.0005, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": {"explore": false}, "off_policy_estimation_methods": {}, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": 1, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 1000, "logger_creator": null, "logger_config": null, "log_level": "INFO", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": -1, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": null, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "min_time_s_per_reporting": -1, "min_train_timesteps_per_reporting": -1, "min_sample_timesteps_per_reporting": -1, "input_evaluation": -1, "target_network_update_freq": 500, "replay_buffer_config": {"type": "<class 'ray.rllib.utils.replay_buffers.multi_agent_prioritized_replay_buffer.MultiAgentPrioritizedReplayBuffer'>", "prioritized_replay": -1, "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "worker_side_prioritization": false, "replay_mode": "independent"}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "input": "sampler", "multiagent": {"policies": {"attacker": "<ray.rllib.policy.policy.PolicySpec object at 0x000002958037DCA0>", "defender": "<ray.rllib.policy.policy.PolicySpec object at 0x00000295803B2640>"}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x00000295802F7790>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "tf", "num_cpus_for_driver": 1}, "off_policy_estimation_methods": {}, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": 1, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 1000, "logger_creator": null, "logger_config": null, "log_level": "INFO", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": -1, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": null, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "min_time_s_per_reporting": -1, "min_train_timesteps_per_reporting": -1, "min_sample_timesteps_per_reporting": -1, "input_evaluation": -1, "target_network_update_freq": 500, "replay_buffer_config": {"type": "<class 'ray.rllib.utils.replay_buffers.multi_agent_prioritized_replay_buffer.MultiAgentPrioritizedReplayBuffer'>", "prioritized_replay": -1, "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "worker_side_prioritization": false, "replay_mode": "independent"}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "input": "sampler", "multiagent": {"policies": {"attacker": "<ray.rllib.policy.policy.PolicySpec object at 0x00000295803B2670>", "defender": "<ray.rllib.policy.policy.PolicySpec object at 0x00000295803B2A30>"}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x00000295802F7790>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "tf", "num_cpus_for_driver": 1}, "time_since_restore": 16.12920045852661, "timesteps_since_restore": 0, "iterations_since_restore": 8, "warmup_time": 9.31046748161316, "perf": {"cpu_util_percent": 5.3, "ram_util_percent": 50.63333333333333}}
{"custom_metrics": {}, "episode_media": {}, "num_recreated_workers": 0, "info": {"learner": {"attacker": {"learner_stats": {"cur_lr": 0.0005000000237487257, "mean_q": -9.91971206665039, "min_q": -11.436649322509766, "max_q": -5.1616926193237305, "mean_td_error": -0.7635084986686707, "model": {}}, "td_error": [-9.127744674682617, 0.2202472686767578, -4.19502592086792, 1.3571081161499023, 1.6763763427734375, 0.3361959457397461, -0.5670576095581055, -1.3313140869140625, 0.06351184844970703, 0.36789894104003906, -0.8300724029541016, -0.3525505065917969, -0.4297294616699219, 0.7763299942016602, -0.040909767150878906, -0.13940048217773438], "custom_metrics": {}, "num_agent_steps_trained": 16.0}, "defender": {"learner_stats": {"cur_lr": 0.0005000000237487257, "mean_q": -0.015439771115779877, "min_q": -1.016070008277893, "max_q": 1.7754589319229126, "mean_td_error": -0.11067986488342285, "model": {}}, "td_error": [0.3888667821884155, 0.07942286133766174, 0.03977744281291962, -0.045571088790893555, 0.2210935354232788, 0.12837427854537964, -0.12080863118171692, -0.01700732856988907, -0.16420221328735352, 0.0049693286418914795, -0.05211065709590912, 0.13899585604667664, -1.8589524030685425, -0.2402307391166687, 0.03691953420639038, -0.3104144334793091], "custom_metrics": {}, "num_agent_steps_trained": 16.0}}, "num_env_steps_sampled": 9072, "num_env_steps_trained": 21536, "num_agent_steps_sampled": 9070, "num_agent_steps_trained": 21536, "last_target_update_ts": 9072, "num_target_updates": 17}, "sampler_results": {"episode_reward_max": -9.899999999999999, "episode_reward_min": -317.6333333333334, "episode_reward_mean": -172.71428571428572, "episode_len_mean": 309.0, "episode_media": {}, "episodes_this_iter": 4, "policy_reward_min": {"attacker": -315.3333333333334, "defender": -17.1}, "policy_reward_max": {"attacker": -10.299999999999997, "defender": 2.1}, "policy_reward_mean": {"attacker": -165.86785714285722, "defender": -6.846428571428572}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-186.86666666666676, -201.73333333333355, -126.73333333333342, -190.63333333333333, -199.26666666666654, -154.26666666666696, -168.16666666666674, -152.5000000000002, -200.3333333333335, -164.50000000000006, -145.46666666666667, -119.16666666666663, -93.13333333333337, -141.8333333333334, -201.2666666666667, -204.33333333333317, -151.23333333333335, -175.76666666666677, -228.7333333333334, -199.20000000000005, -219.76666666666682, -226.19999999999976, -136.00000000000009, -317.6333333333334, -100.99999999999987, -9.899999999999999, -234.0, -186.36666666666693], "episode_lengths": [283, 303, 315, 300, 328, 333, 292, 369, 314, 288, 273, 237, 151, 286, 351, 395, 286, 310, 352, 378, 304, 354, 300, 441, 337, 69, 339, 364], "policy_attacker_reward": [-185.36666666666673, -184.63333333333352, -124.43333333333341, -180.03333333333336, -191.56666666666655, -143.86666666666696, -163.36666666666673, -146.2000000000002, -192.93333333333337, -160.60000000000002, -143.36666666666667, -120.76666666666664, -86.43333333333337, -137.03333333333333, -194.86666666666667, -191.83333333333312, -134.5333333333334, -168.06666666666678, -217.63333333333333, -195.7, -206.06666666666678, -215.8999999999997, -120.10000000000001, -315.3333333333334, -98.59999999999994, -10.299999999999997, -226.29999999999998, -188.46666666666678], "policy_defender_reward": [-1.4999999999999998, -17.1, -2.3, -10.600000000000001, -7.699999999999999, -10.400000000000002, -4.800000000000001, -6.299999999999999, -7.400000000000009, -3.8999999999999995, -2.0999999999999996, 1.6000000000000005, -6.7, -4.800000000000001, -6.4, -12.5, -16.700000000000003, -7.7, -11.100000000000003, -3.5, -13.7, -10.300000000000002, -15.899999999999995, -2.2999999999999994, -2.3999999999999986, 0.4, -7.699999999999999, 2.1]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2894857400474306, "mean_inference_ms": 0.5938510561978882, "mean_action_processing_ms": 0.05884745696643729, "mean_env_wait_ms": 0.4961399763826945, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0}, "episode_reward_max": -9.899999999999999, "episode_reward_min": -317.6333333333334, "episode_reward_mean": -172.71428571428572, "episode_len_mean": 309.0, "episodes_this_iter": 4, "policy_reward_min": {"attacker": -315.3333333333334, "defender": -17.1}, "policy_reward_max": {"attacker": -10.299999999999997, "defender": 2.1}, "policy_reward_mean": {"attacker": -165.86785714285722, "defender": -6.846428571428572}, "hist_stats": {"episode_reward": [-186.86666666666676, -201.73333333333355, -126.73333333333342, -190.63333333333333, -199.26666666666654, -154.26666666666696, -168.16666666666674, -152.5000000000002, -200.3333333333335, -164.50000000000006, -145.46666666666667, -119.16666666666663, -93.13333333333337, -141.8333333333334, -201.2666666666667, -204.33333333333317, -151.23333333333335, -175.76666666666677, -228.7333333333334, -199.20000000000005, -219.76666666666682, -226.19999999999976, -136.00000000000009, -317.6333333333334, -100.99999999999987, -9.899999999999999, -234.0, -186.36666666666693], "episode_lengths": [283, 303, 315, 300, 328, 333, 292, 369, 314, 288, 273, 237, 151, 286, 351, 395, 286, 310, 352, 378, 304, 354, 300, 441, 337, 69, 339, 364], "policy_attacker_reward": [-185.36666666666673, -184.63333333333352, -124.43333333333341, -180.03333333333336, -191.56666666666655, -143.86666666666696, -163.36666666666673, -146.2000000000002, -192.93333333333337, -160.60000000000002, -143.36666666666667, -120.76666666666664, -86.43333333333337, -137.03333333333333, -194.86666666666667, -191.83333333333312, -134.5333333333334, -168.06666666666678, -217.63333333333333, -195.7, -206.06666666666678, -215.8999999999997, -120.10000000000001, -315.3333333333334, -98.59999999999994, -10.299999999999997, -226.29999999999998, -188.46666666666678], "policy_defender_reward": [-1.4999999999999998, -17.1, -2.3, -10.600000000000001, -7.699999999999999, -10.400000000000002, -4.800000000000001, -6.299999999999999, -7.400000000000009, -3.8999999999999995, -2.0999999999999996, 1.6000000000000005, -6.7, -4.800000000000001, -6.4, -12.5, -16.700000000000003, -7.7, -11.100000000000003, -3.5, -13.7, -10.300000000000002, -15.899999999999995, -2.2999999999999994, -2.3999999999999986, 0.4, -7.699999999999999, 2.1]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2894857400474306, "mean_inference_ms": 0.5938510561978882, "mean_action_processing_ms": 0.05884745696643729, "mean_env_wait_ms": 0.4961399763826945, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "num_healthy_workers": 3, "num_agent_steps_sampled": 9070, "num_agent_steps_trained": 21536, "num_env_steps_sampled": 9072, "num_env_steps_trained": 21536, "num_env_steps_sampled_this_iter": 1008, "num_env_steps_trained_this_iter": 2688, "timesteps_total": 9072, "num_steps_trained_this_iter": 2688, "agent_timesteps_total": 9070, "timers": {"training_iteration_time_ms": 24.12, "load_time_ms": 0.0, "load_throughput": 0.0, "learn_time_ms": 3.447, "learn_throughput": 9283.67, "synch_weights_time_ms": 2.206}, "counters": {"num_env_steps_sampled": 9072, "num_env_steps_trained": 21536, "num_agent_steps_sampled": 9070, "num_agent_steps_trained": 21536, "last_target_update_ts": 9072, "num_target_updates": 17}, "done": false, "episodes_total": 28, "training_iteration": 9, "trial_id": "5f583_00000", "experiment_id": "d83cb2d89bc543feb18deca748a0082f", "date": "2022-09-11_15-48-04", "timestamp": 1662886084, "time_this_iter_s": 2.072977304458618, "time_total_s": 18.20217776298523, "pid": 14740, "hostname": "XorgWorkstation", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "my_env", "env_config": {}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "num_workers": 3, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "ignore_worker_failures": false, "recreate_failed_workers": false, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 0.0005, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "my_env", "env_config": {}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "num_workers": 3, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "ignore_worker_failures": false, "recreate_failed_workers": false, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 0.0005, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": {"explore": false}, "off_policy_estimation_methods": {}, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": 1, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 1000, "logger_creator": null, "logger_config": null, "log_level": "INFO", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": -1, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": null, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "min_time_s_per_reporting": -1, "min_train_timesteps_per_reporting": -1, "min_sample_timesteps_per_reporting": -1, "input_evaluation": -1, "target_network_update_freq": 500, "replay_buffer_config": {"type": "<class 'ray.rllib.utils.replay_buffers.multi_agent_prioritized_replay_buffer.MultiAgentPrioritizedReplayBuffer'>", "prioritized_replay": -1, "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "worker_side_prioritization": false, "replay_mode": "independent"}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "input": "sampler", "multiagent": {"policies": {"attacker": "<ray.rllib.policy.policy.PolicySpec object at 0x00000295803B2E20>", "defender": "<ray.rllib.policy.policy.PolicySpec object at 0x00000295802FEFD0>"}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x00000295B548DCA0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "tf", "num_cpus_for_driver": 1}, "off_policy_estimation_methods": {}, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": 1, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 1000, "logger_creator": null, "logger_config": null, "log_level": "INFO", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": -1, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": null, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "min_time_s_per_reporting": -1, "min_train_timesteps_per_reporting": -1, "min_sample_timesteps_per_reporting": -1, "input_evaluation": -1, "target_network_update_freq": 500, "replay_buffer_config": {"type": "<class 'ray.rllib.utils.replay_buffers.multi_agent_prioritized_replay_buffer.MultiAgentPrioritizedReplayBuffer'>", "prioritized_replay": -1, "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "worker_side_prioritization": false, "replay_mode": "independent"}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "input": "sampler", "multiagent": {"policies": {"attacker": "<ray.rllib.policy.policy.PolicySpec object at 0x000002958037D190>", "defender": "<ray.rllib.policy.policy.PolicySpec object at 0x0000029580382F40>"}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x00000295B548DCA0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "tf", "num_cpus_for_driver": 1}, "time_since_restore": 18.20217776298523, "timesteps_since_restore": 0, "iterations_since_restore": 9, "warmup_time": 9.31046748161316, "perf": {"cpu_util_percent": 4.533333333333334, "ram_util_percent": 50.63333333333333}}
{"custom_metrics": {}, "episode_media": {}, "num_recreated_workers": 0, "info": {"learner": {"attacker": {"learner_stats": {"cur_lr": 0.0005000000237487257, "mean_q": -10.335810661315918, "min_q": -12.927748680114746, "max_q": -7.94058895111084, "mean_td_error": -0.43504685163497925, "model": {}}, "td_error": [0.23734378814697266, 0.328857421875, 0.11252403259277344, -0.56072998046875, -0.6681394577026367, 0.6618881225585938, 0.3366870880126953, 1.2716245651245117, 1.0151567459106445, -1.828725814819336, -0.5661239624023438, -7.381181716918945, -0.0639801025390625, -0.00179290771484375, -0.13342571258544922, 0.2792682647705078], "custom_metrics": {}, "num_agent_steps_trained": 16.0}, "defender": {"learner_stats": {"cur_lr": 0.0005000000237487257, "mean_q": 0.06228061020374298, "min_q": -0.684728741645813, "max_q": 4.151224613189697, "mean_td_error": -0.177946537733078, "model": {}}, "td_error": [0.3057510256767273, -0.11165773868560791, -0.12024229764938354, 0.21698912978172302, -0.8978499174118042, -0.43493491411209106, -0.5205718874931335, 0.14825193583965302, -0.14654454588890076, 0.6233481764793396, -0.3315822184085846, 0.34859585762023926, -1.597592830657959, -0.3575788736343384, -0.33435457944869995, 0.3628289997577667], "custom_metrics": {}, "num_agent_steps_trained": 16.0}}, "num_env_steps_sampled": 10080, "num_env_steps_trained": 24224, "num_agent_steps_sampled": 10077, "num_agent_steps_trained": 24224, "last_target_update_ts": 10080, "num_target_updates": 19}, "sampler_results": {"episode_reward_max": -9.899999999999999, "episode_reward_min": -317.6333333333334, "episode_reward_mean": -171.8483870967742, "episode_len_mean": 309.51612903225805, "episode_media": {}, "episodes_this_iter": 3, "policy_reward_min": {"attacker": -315.3333333333334, "defender": -17.1}, "policy_reward_max": {"attacker": -10.299999999999997, "defender": 3.6000000000000005}, "policy_reward_mean": {"attacker": -165.6516129032259, "defender": -6.1967741935483875}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-186.86666666666676, -201.73333333333355, -126.73333333333342, -190.63333333333333, -199.26666666666654, -154.26666666666696, -168.16666666666674, -152.5000000000002, -200.3333333333335, -164.50000000000006, -145.46666666666667, -119.16666666666663, -93.13333333333337, -141.8333333333334, -201.2666666666667, -204.33333333333317, -151.23333333333335, -175.76666666666677, -228.7333333333334, -199.20000000000005, -219.76666666666682, -226.19999999999976, -136.00000000000009, -317.6333333333334, -100.99999999999987, -9.899999999999999, -234.0, -186.36666666666693, -159.66666666666677, -178.23333333333355, -153.4], "episode_lengths": [283, 303, 315, 300, 328, 333, 292, 369, 314, 288, 273, 237, 151, 286, 351, 395, 286, 310, 352, 378, 304, 354, 300, 441, 337, 69, 339, 364, 288, 298, 357], "policy_attacker_reward": [-185.36666666666673, -184.63333333333352, -124.43333333333341, -180.03333333333336, -191.56666666666655, -143.86666666666696, -163.36666666666673, -146.2000000000002, -192.93333333333337, -160.60000000000002, -143.36666666666667, -120.76666666666664, -86.43333333333337, -137.03333333333333, -194.86666666666667, -191.83333333333312, -134.5333333333334, -168.06666666666678, -217.63333333333333, -195.7, -206.06666666666678, -215.8999999999997, -120.10000000000001, -315.3333333333334, -98.59999999999994, -10.299999999999997, -226.29999999999998, -188.46666666666678, -156.36666666666667, -177.5333333333335, -157.0], "policy_defender_reward": [-1.4999999999999998, -17.1, -2.3, -10.600000000000001, -7.699999999999999, -10.400000000000002, -4.800000000000001, -6.299999999999999, -7.400000000000009, -3.8999999999999995, -2.0999999999999996, 1.6000000000000005, -6.7, -4.800000000000001, -6.4, -12.5, -16.700000000000003, -7.7, -11.100000000000003, -3.5, -13.7, -10.300000000000002, -15.899999999999995, -2.2999999999999994, -2.3999999999999986, 0.4, -7.699999999999999, 2.1, -3.3000000000000016, -0.7000000000000001, 3.6000000000000005]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.28869227112711565, "mean_inference_ms": 0.5881954841924644, "mean_action_processing_ms": 0.05899991011434037, "mean_env_wait_ms": 0.49480719130478235, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0}, "episode_reward_max": -9.899999999999999, "episode_reward_min": -317.6333333333334, "episode_reward_mean": -171.8483870967742, "episode_len_mean": 309.51612903225805, "episodes_this_iter": 3, "policy_reward_min": {"attacker": -315.3333333333334, "defender": -17.1}, "policy_reward_max": {"attacker": -10.299999999999997, "defender": 3.6000000000000005}, "policy_reward_mean": {"attacker": -165.6516129032259, "defender": -6.1967741935483875}, "hist_stats": {"episode_reward": [-186.86666666666676, -201.73333333333355, -126.73333333333342, -190.63333333333333, -199.26666666666654, -154.26666666666696, -168.16666666666674, -152.5000000000002, -200.3333333333335, -164.50000000000006, -145.46666666666667, -119.16666666666663, -93.13333333333337, -141.8333333333334, -201.2666666666667, -204.33333333333317, -151.23333333333335, -175.76666666666677, -228.7333333333334, -199.20000000000005, -219.76666666666682, -226.19999999999976, -136.00000000000009, -317.6333333333334, -100.99999999999987, -9.899999999999999, -234.0, -186.36666666666693, -159.66666666666677, -178.23333333333355, -153.4], "episode_lengths": [283, 303, 315, 300, 328, 333, 292, 369, 314, 288, 273, 237, 151, 286, 351, 395, 286, 310, 352, 378, 304, 354, 300, 441, 337, 69, 339, 364, 288, 298, 357], "policy_attacker_reward": [-185.36666666666673, -184.63333333333352, -124.43333333333341, -180.03333333333336, -191.56666666666655, -143.86666666666696, -163.36666666666673, -146.2000000000002, -192.93333333333337, -160.60000000000002, -143.36666666666667, -120.76666666666664, -86.43333333333337, -137.03333333333333, -194.86666666666667, -191.83333333333312, -134.5333333333334, -168.06666666666678, -217.63333333333333, -195.7, -206.06666666666678, -215.8999999999997, -120.10000000000001, -315.3333333333334, -98.59999999999994, -10.299999999999997, -226.29999999999998, -188.46666666666678, -156.36666666666667, -177.5333333333335, -157.0], "policy_defender_reward": [-1.4999999999999998, -17.1, -2.3, -10.600000000000001, -7.699999999999999, -10.400000000000002, -4.800000000000001, -6.299999999999999, -7.400000000000009, -3.8999999999999995, -2.0999999999999996, 1.6000000000000005, -6.7, -4.800000000000001, -6.4, -12.5, -16.700000000000003, -7.7, -11.100000000000003, -3.5, -13.7, -10.300000000000002, -15.899999999999995, -2.2999999999999994, -2.3999999999999986, 0.4, -7.699999999999999, 2.1, -3.3000000000000016, -0.7000000000000001, 3.6000000000000005]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.28869227112711565, "mean_inference_ms": 0.5881954841924644, "mean_action_processing_ms": 0.05899991011434037, "mean_env_wait_ms": 0.49480719130478235, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "num_healthy_workers": 3, "num_agent_steps_sampled": 10077, "num_agent_steps_trained": 24224, "num_env_steps_sampled": 10080, "num_env_steps_trained": 24224, "num_env_steps_sampled_this_iter": 1008, "num_env_steps_trained_this_iter": 2688, "timesteps_total": 10080, "num_steps_trained_this_iter": 2688, "agent_timesteps_total": 10077, "timers": {"training_iteration_time_ms": 23.436, "load_time_ms": 0.1, "load_throughput": 320481.681, "learn_time_ms": 3.211, "learn_throughput": 9967.23, "synch_weights_time_ms": 2.486}, "counters": {"num_env_steps_sampled": 10080, "num_env_steps_trained": 24224, "num_agent_steps_sampled": 10077, "num_agent_steps_trained": 24224, "last_target_update_ts": 10080, "num_target_updates": 19}, "done": false, "episodes_total": 31, "training_iteration": 10, "trial_id": "5f583_00000", "experiment_id": "d83cb2d89bc543feb18deca748a0082f", "date": "2022-09-11_15-48-06", "timestamp": 1662886086, "time_this_iter_s": 2.0442960262298584, "time_total_s": 20.246473789215088, "pid": 14740, "hostname": "XorgWorkstation", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "my_env", "env_config": {}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "num_workers": 3, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "ignore_worker_failures": false, "recreate_failed_workers": false, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 0.0005, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "my_env", "env_config": {}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "num_workers": 3, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "ignore_worker_failures": false, "recreate_failed_workers": false, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 0.0005, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": {"explore": false}, "off_policy_estimation_methods": {}, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": 1, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 1000, "logger_creator": null, "logger_config": null, "log_level": "INFO", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": -1, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": null, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "min_time_s_per_reporting": -1, "min_train_timesteps_per_reporting": -1, "min_sample_timesteps_per_reporting": -1, "input_evaluation": -1, "target_network_update_freq": 500, "replay_buffer_config": {"type": "<class 'ray.rllib.utils.replay_buffers.multi_agent_prioritized_replay_buffer.MultiAgentPrioritizedReplayBuffer'>", "prioritized_replay": -1, "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "worker_side_prioritization": false, "replay_mode": "independent"}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "input": "sampler", "multiagent": {"policies": {"attacker": "<ray.rllib.policy.policy.PolicySpec object at 0x00000295803B26D0>", "defender": "<ray.rllib.policy.policy.PolicySpec object at 0x00000295803B2FD0>"}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x00000295803AA3A0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "tf", "num_cpus_for_driver": 1}, "off_policy_estimation_methods": {}, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": 1, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 1000, "logger_creator": null, "logger_config": null, "log_level": "INFO", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": -1, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": null, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "min_time_s_per_reporting": -1, "min_train_timesteps_per_reporting": -1, "min_sample_timesteps_per_reporting": -1, "input_evaluation": -1, "target_network_update_freq": 500, "replay_buffer_config": {"type": "<class 'ray.rllib.utils.replay_buffers.multi_agent_prioritized_replay_buffer.MultiAgentPrioritizedReplayBuffer'>", "prioritized_replay": -1, "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "worker_side_prioritization": false, "replay_mode": "independent"}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "input": "sampler", "multiagent": {"policies": {"attacker": "<ray.rllib.policy.policy.PolicySpec object at 0x00000295803B2F10>", "defender": "<ray.rllib.policy.policy.PolicySpec object at 0x0000029580306A90>"}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x00000295803AA3A0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "tf", "num_cpus_for_driver": 1}, "time_since_restore": 20.246473789215088, "timesteps_since_restore": 0, "iterations_since_restore": 10, "warmup_time": 9.31046748161316, "perf": {"cpu_util_percent": 4.766666666666667, "ram_util_percent": 50.666666666666664}}
{"custom_metrics": {}, "episode_media": {}, "num_recreated_workers": 0, "info": {"learner": {"attacker": {"learner_stats": {"cur_lr": 0.0005000000237487257, "mean_q": -10.204216003417969, "min_q": -13.997390747070312, "max_q": -5.446904182434082, "mean_td_error": 0.31094592809677124, "model": {}}, "td_error": [2.0010290145874023, 0.7357645034790039, 0.009351730346679688, -0.018978118896484375, 0.11834049224853516, -1.1923646926879883, -0.041710853576660156, 0.23918437957763672, -1.2065372467041016, 1.8238639831542969, 0.26839160919189453, 0.012759208679199219, -0.02002716064453125, 0.8648672103881836, 0.7064275741577148, 0.6747732162475586], "custom_metrics": {}, "num_agent_steps_trained": 16.0}, "defender": {"learner_stats": {"cur_lr": 0.0005000000237487257, "mean_q": 0.16423317790031433, "min_q": -1.0929057598114014, "max_q": 2.150592565536499, "mean_td_error": -0.1528761386871338, "model": {}}, "td_error": [-0.17128154635429382, -0.10894972085952759, -0.27306467294692993, -0.0406651496887207, 0.108186274766922, -0.07017719745635986, -0.14819321036338806, -0.3064879775047302, 0.2590335011482239, -0.055374372750520706, -0.6241669654846191, -0.42277055978775024, -0.33794474601745605, 0.1277531385421753, -0.06938067078590393, -0.3125344514846802], "custom_metrics": {}, "num_agent_steps_trained": 16.0}}, "num_env_steps_sampled": 11088, "num_env_steps_trained": 26912, "num_agent_steps_sampled": 11085, "num_agent_steps_trained": 26912, "last_target_update_ts": 11088, "num_target_updates": 21}, "sampler_results": {"episode_reward_max": -9.899999999999999, "episode_reward_min": -317.6333333333334, "episode_reward_mean": -171.8483870967742, "episode_len_mean": 309.51612903225805, "episode_media": {}, "episodes_this_iter": 0, "policy_reward_min": {"attacker": -315.3333333333334, "defender": -17.1}, "policy_reward_max": {"attacker": -10.299999999999997, "defender": 3.6000000000000005}, "policy_reward_mean": {"attacker": -165.6516129032259, "defender": -6.1967741935483875}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-186.86666666666676, -201.73333333333355, -126.73333333333342, -190.63333333333333, -199.26666666666654, -154.26666666666696, -168.16666666666674, -152.5000000000002, -200.3333333333335, -164.50000000000006, -145.46666666666667, -119.16666666666663, -93.13333333333337, -141.8333333333334, -201.2666666666667, -204.33333333333317, -151.23333333333335, -175.76666666666677, -228.7333333333334, -199.20000000000005, -219.76666666666682, -226.19999999999976, -136.00000000000009, -317.6333333333334, -100.99999999999987, -9.899999999999999, -234.0, -186.36666666666693, -159.66666666666677, -178.23333333333355, -153.4], "episode_lengths": [283, 303, 315, 300, 328, 333, 292, 369, 314, 288, 273, 237, 151, 286, 351, 395, 286, 310, 352, 378, 304, 354, 300, 441, 337, 69, 339, 364, 288, 298, 357], "policy_attacker_reward": [-185.36666666666673, -184.63333333333352, -124.43333333333341, -180.03333333333336, -191.56666666666655, -143.86666666666696, -163.36666666666673, -146.2000000000002, -192.93333333333337, -160.60000000000002, -143.36666666666667, -120.76666666666664, -86.43333333333337, -137.03333333333333, -194.86666666666667, -191.83333333333312, -134.5333333333334, -168.06666666666678, -217.63333333333333, -195.7, -206.06666666666678, -215.8999999999997, -120.10000000000001, -315.3333333333334, -98.59999999999994, -10.299999999999997, -226.29999999999998, -188.46666666666678, -156.36666666666667, -177.5333333333335, -157.0], "policy_defender_reward": [-1.4999999999999998, -17.1, -2.3, -10.600000000000001, -7.699999999999999, -10.400000000000002, -4.800000000000001, -6.299999999999999, -7.400000000000009, -3.8999999999999995, -2.0999999999999996, 1.6000000000000005, -6.7, -4.800000000000001, -6.4, -12.5, -16.700000000000003, -7.7, -11.100000000000003, -3.5, -13.7, -10.300000000000002, -15.899999999999995, -2.2999999999999994, -2.3999999999999986, 0.4, -7.699999999999999, 2.1, -3.3000000000000016, -0.7000000000000001, 3.6000000000000005]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.28869227112711565, "mean_inference_ms": 0.5881954841924644, "mean_action_processing_ms": 0.05899991011434037, "mean_env_wait_ms": 0.49480719130478235, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0}, "episode_reward_max": -9.899999999999999, "episode_reward_min": -317.6333333333334, "episode_reward_mean": -171.8483870967742, "episode_len_mean": 309.51612903225805, "episodes_this_iter": 0, "policy_reward_min": {"attacker": -315.3333333333334, "defender": -17.1}, "policy_reward_max": {"attacker": -10.299999999999997, "defender": 3.6000000000000005}, "policy_reward_mean": {"attacker": -165.6516129032259, "defender": -6.1967741935483875}, "hist_stats": {"episode_reward": [-186.86666666666676, -201.73333333333355, -126.73333333333342, -190.63333333333333, -199.26666666666654, -154.26666666666696, -168.16666666666674, -152.5000000000002, -200.3333333333335, -164.50000000000006, -145.46666666666667, -119.16666666666663, -93.13333333333337, -141.8333333333334, -201.2666666666667, -204.33333333333317, -151.23333333333335, -175.76666666666677, -228.7333333333334, -199.20000000000005, -219.76666666666682, -226.19999999999976, -136.00000000000009, -317.6333333333334, -100.99999999999987, -9.899999999999999, -234.0, -186.36666666666693, -159.66666666666677, -178.23333333333355, -153.4], "episode_lengths": [283, 303, 315, 300, 328, 333, 292, 369, 314, 288, 273, 237, 151, 286, 351, 395, 286, 310, 352, 378, 304, 354, 300, 441, 337, 69, 339, 364, 288, 298, 357], "policy_attacker_reward": [-185.36666666666673, -184.63333333333352, -124.43333333333341, -180.03333333333336, -191.56666666666655, -143.86666666666696, -163.36666666666673, -146.2000000000002, -192.93333333333337, -160.60000000000002, -143.36666666666667, -120.76666666666664, -86.43333333333337, -137.03333333333333, -194.86666666666667, -191.83333333333312, -134.5333333333334, -168.06666666666678, -217.63333333333333, -195.7, -206.06666666666678, -215.8999999999997, -120.10000000000001, -315.3333333333334, -98.59999999999994, -10.299999999999997, -226.29999999999998, -188.46666666666678, -156.36666666666667, -177.5333333333335, -157.0], "policy_defender_reward": [-1.4999999999999998, -17.1, -2.3, -10.600000000000001, -7.699999999999999, -10.400000000000002, -4.800000000000001, -6.299999999999999, -7.400000000000009, -3.8999999999999995, -2.0999999999999996, 1.6000000000000005, -6.7, -4.800000000000001, -6.4, -12.5, -16.700000000000003, -7.7, -11.100000000000003, -3.5, -13.7, -10.300000000000002, -15.899999999999995, -2.2999999999999994, -2.3999999999999986, 0.4, -7.699999999999999, 2.1, -3.3000000000000016, -0.7000000000000001, 3.6000000000000005]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.28869227112711565, "mean_inference_ms": 0.5881954841924644, "mean_action_processing_ms": 0.05899991011434037, "mean_env_wait_ms": 0.49480719130478235, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "num_healthy_workers": 3, "num_agent_steps_sampled": 11085, "num_agent_steps_trained": 26912, "num_env_steps_sampled": 11088, "num_env_steps_trained": 26912, "num_env_steps_sampled_this_iter": 1008, "num_env_steps_trained_this_iter": 2688, "timesteps_total": 11088, "num_steps_trained_this_iter": 2688, "agent_timesteps_total": 11085, "timers": {"training_iteration_time_ms": 27.551, "load_time_ms": 0.1, "load_throughput": 319870.658, "learn_time_ms": 3.245, "learn_throughput": 9861.41, "synch_weights_time_ms": 2.463}, "counters": {"num_env_steps_sampled": 11088, "num_env_steps_trained": 26912, "num_agent_steps_sampled": 11085, "num_agent_steps_trained": 26912, "last_target_update_ts": 11088, "num_target_updates": 21}, "done": false, "episodes_total": 31, "training_iteration": 11, "trial_id": "5f583_00000", "experiment_id": "d83cb2d89bc543feb18deca748a0082f", "date": "2022-09-11_15-48-08", "timestamp": 1662886088, "time_this_iter_s": 2.0960898399353027, "time_total_s": 22.34256362915039, "pid": 14740, "hostname": "XorgWorkstation", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "my_env", "env_config": {}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "num_workers": 3, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "ignore_worker_failures": false, "recreate_failed_workers": false, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 0.0005, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "my_env", "env_config": {}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "num_workers": 3, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "ignore_worker_failures": false, "recreate_failed_workers": false, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 0.0005, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": {"explore": false}, "off_policy_estimation_methods": {}, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": 1, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 1000, "logger_creator": null, "logger_config": null, "log_level": "INFO", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": -1, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": null, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "min_time_s_per_reporting": -1, "min_train_timesteps_per_reporting": -1, "min_sample_timesteps_per_reporting": -1, "input_evaluation": -1, "target_network_update_freq": 500, "replay_buffer_config": {"type": "<class 'ray.rllib.utils.replay_buffers.multi_agent_prioritized_replay_buffer.MultiAgentPrioritizedReplayBuffer'>", "prioritized_replay": -1, "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "worker_side_prioritization": false, "replay_mode": "independent"}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "input": "sampler", "multiagent": {"policies": {"attacker": "<ray.rllib.policy.policy.PolicySpec object at 0x00000295803B1D30>", "defender": "<ray.rllib.policy.policy.PolicySpec object at 0x00000295802DD7C0>"}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x00000295802F7F70>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "tf", "num_cpus_for_driver": 1}, "off_policy_estimation_methods": {}, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": 1, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 1000, "logger_creator": null, "logger_config": null, "log_level": "INFO", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": -1, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": null, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "min_time_s_per_reporting": -1, "min_train_timesteps_per_reporting": -1, "min_sample_timesteps_per_reporting": -1, "input_evaluation": -1, "target_network_update_freq": 500, "replay_buffer_config": {"type": "<class 'ray.rllib.utils.replay_buffers.multi_agent_prioritized_replay_buffer.MultiAgentPrioritizedReplayBuffer'>", "prioritized_replay": -1, "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "worker_side_prioritization": false, "replay_mode": "independent"}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "input": "sampler", "multiagent": {"policies": {"attacker": "<ray.rllib.policy.policy.PolicySpec object at 0x000002958037DE80>", "defender": "<ray.rllib.policy.policy.PolicySpec object at 0x000002958037DF10>"}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x00000295802F7F70>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "tf", "num_cpus_for_driver": 1}, "time_since_restore": 22.34256362915039, "timesteps_since_restore": 0, "iterations_since_restore": 11, "warmup_time": 9.31046748161316, "perf": {"cpu_util_percent": 5.633333333333333, "ram_util_percent": 50.633333333333326}}
{"custom_metrics": {}, "episode_media": {}, "num_recreated_workers": 0, "info": {"learner": {"attacker": {"learner_stats": {"cur_lr": 0.0005000000237487257, "mean_q": -12.79948616027832, "min_q": -16.05324935913086, "max_q": -7.4304938316345215, "mean_td_error": -0.18836447596549988, "model": {}}, "td_error": [-1.8186101913452148, -0.5649938583374023, 0.17596435546875, 2.0715980529785156, 0.5886306762695312, 1.7945661544799805, -3.694031238555908, -0.35921669006347656, -0.26177978515625, 0.3618803024291992, 3.200993537902832, 0.4066810607910156, 1.9724321365356445, -0.03420257568359375, -6.463827133178711, -0.38991641998291016], "custom_metrics": {}, "num_agent_steps_trained": 16.0}, "defender": {"learner_stats": {"cur_lr": 0.0005000000237487257, "mean_q": -0.14236564934253693, "min_q": -0.6974600553512573, "max_q": 2.2846012115478516, "mean_td_error": 0.16961023211479187, "model": {}}, "td_error": [0.8639942407608032, 0.1702280044555664, 0.1282007098197937, 0.1068386435508728, -0.1287311613559723, 0.12552565336227417, 0.07913351058959961, -0.09613564610481262, 0.47347012162208557, 0.3571373224258423, -0.17986240983009338, 0.0889551043510437, 0.0744771957397461, 0.25492843985557556, 0.46801358461380005, -0.07240945100784302], "custom_metrics": {}, "num_agent_steps_trained": 16.0}}, "num_env_steps_sampled": 12096, "num_env_steps_trained": 29600, "num_agent_steps_sampled": 12093, "num_agent_steps_trained": 29600, "last_target_update_ts": 12096, "num_target_updates": 23}, "sampler_results": {"episode_reward_max": -9.899999999999999, "episode_reward_min": -317.6333333333334, "episode_reward_mean": -175.6572916666667, "episode_len_mean": 316.59375, "episode_media": {}, "episodes_this_iter": 1, "policy_reward_min": {"attacker": -315.3333333333334, "defender": -19.299999999999997}, "policy_reward_max": {"attacker": -10.299999999999997, "defender": 3.6000000000000005}, "policy_reward_mean": {"attacker": -169.05104166666672, "defender": -6.60625}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-186.86666666666676, -201.73333333333355, -126.73333333333342, -190.63333333333333, -199.26666666666654, -154.26666666666696, -168.16666666666674, -152.5000000000002, -200.3333333333335, -164.50000000000006, -145.46666666666667, -119.16666666666663, -93.13333333333337, -141.8333333333334, -201.2666666666667, -204.33333333333317, -151.23333333333335, -175.76666666666677, -228.7333333333334, -199.20000000000005, -219.76666666666682, -226.19999999999976, -136.00000000000009, -317.6333333333334, -100.99999999999987, -9.899999999999999, -234.0, -186.36666666666693, -159.66666666666677, -178.23333333333355, -153.4, -293.73333333333323], "episode_lengths": [283, 303, 315, 300, 328, 333, 292, 369, 314, 288, 273, 237, 151, 286, 351, 395, 286, 310, 352, 378, 304, 354, 300, 441, 337, 69, 339, 364, 288, 298, 357, 536], "policy_attacker_reward": [-185.36666666666673, -184.63333333333352, -124.43333333333341, -180.03333333333336, -191.56666666666655, -143.86666666666696, -163.36666666666673, -146.2000000000002, -192.93333333333337, -160.60000000000002, -143.36666666666667, -120.76666666666664, -86.43333333333337, -137.03333333333333, -194.86666666666667, -191.83333333333312, -134.5333333333334, -168.06666666666678, -217.63333333333333, -195.7, -206.06666666666678, -215.8999999999997, -120.10000000000001, -315.3333333333334, -98.59999999999994, -10.299999999999997, -226.29999999999998, -188.46666666666678, -156.36666666666667, -177.5333333333335, -157.0, -274.43333333333317], "policy_defender_reward": [-1.4999999999999998, -17.1, -2.3, -10.600000000000001, -7.699999999999999, -10.400000000000002, -4.800000000000001, -6.299999999999999, -7.400000000000009, -3.8999999999999995, -2.0999999999999996, 1.6000000000000005, -6.7, -4.800000000000001, -6.4, -12.5, -16.700000000000003, -7.7, -11.100000000000003, -3.5, -13.7, -10.300000000000002, -15.899999999999995, -2.2999999999999994, -2.3999999999999986, 0.4, -7.699999999999999, 2.1, -3.3000000000000016, -0.7000000000000001, 3.6000000000000005, -19.299999999999997]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.28813350885132355, "mean_inference_ms": 0.5867498683039691, "mean_action_processing_ms": 0.059100644377800084, "mean_env_wait_ms": 0.4940352841908403, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0}, "episode_reward_max": -9.899999999999999, "episode_reward_min": -317.6333333333334, "episode_reward_mean": -175.6572916666667, "episode_len_mean": 316.59375, "episodes_this_iter": 1, "policy_reward_min": {"attacker": -315.3333333333334, "defender": -19.299999999999997}, "policy_reward_max": {"attacker": -10.299999999999997, "defender": 3.6000000000000005}, "policy_reward_mean": {"attacker": -169.05104166666672, "defender": -6.60625}, "hist_stats": {"episode_reward": [-186.86666666666676, -201.73333333333355, -126.73333333333342, -190.63333333333333, -199.26666666666654, -154.26666666666696, -168.16666666666674, -152.5000000000002, -200.3333333333335, -164.50000000000006, -145.46666666666667, -119.16666666666663, -93.13333333333337, -141.8333333333334, -201.2666666666667, -204.33333333333317, -151.23333333333335, -175.76666666666677, -228.7333333333334, -199.20000000000005, -219.76666666666682, -226.19999999999976, -136.00000000000009, -317.6333333333334, -100.99999999999987, -9.899999999999999, -234.0, -186.36666666666693, -159.66666666666677, -178.23333333333355, -153.4, -293.73333333333323], "episode_lengths": [283, 303, 315, 300, 328, 333, 292, 369, 314, 288, 273, 237, 151, 286, 351, 395, 286, 310, 352, 378, 304, 354, 300, 441, 337, 69, 339, 364, 288, 298, 357, 536], "policy_attacker_reward": [-185.36666666666673, -184.63333333333352, -124.43333333333341, -180.03333333333336, -191.56666666666655, -143.86666666666696, -163.36666666666673, -146.2000000000002, -192.93333333333337, -160.60000000000002, -143.36666666666667, -120.76666666666664, -86.43333333333337, -137.03333333333333, -194.86666666666667, -191.83333333333312, -134.5333333333334, -168.06666666666678, -217.63333333333333, -195.7, -206.06666666666678, -215.8999999999997, -120.10000000000001, -315.3333333333334, -98.59999999999994, -10.299999999999997, -226.29999999999998, -188.46666666666678, -156.36666666666667, -177.5333333333335, -157.0, -274.43333333333317], "policy_defender_reward": [-1.4999999999999998, -17.1, -2.3, -10.600000000000001, -7.699999999999999, -10.400000000000002, -4.800000000000001, -6.299999999999999, -7.400000000000009, -3.8999999999999995, -2.0999999999999996, 1.6000000000000005, -6.7, -4.800000000000001, -6.4, -12.5, -16.700000000000003, -7.7, -11.100000000000003, -3.5, -13.7, -10.300000000000002, -15.899999999999995, -2.2999999999999994, -2.3999999999999986, 0.4, -7.699999999999999, 2.1, -3.3000000000000016, -0.7000000000000001, 3.6000000000000005, -19.299999999999997]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.28813350885132355, "mean_inference_ms": 0.5867498683039691, "mean_action_processing_ms": 0.059100644377800084, "mean_env_wait_ms": 0.4940352841908403, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "num_healthy_workers": 3, "num_agent_steps_sampled": 12093, "num_agent_steps_trained": 29600, "num_env_steps_sampled": 12096, "num_env_steps_trained": 29600, "num_env_steps_sampled_this_iter": 1008, "num_env_steps_trained_this_iter": 2688, "timesteps_total": 12096, "num_steps_trained_this_iter": 2688, "agent_timesteps_total": 12093, "timers": {"training_iteration_time_ms": 24.184, "load_time_ms": 0.1, "load_throughput": 320405.175, "learn_time_ms": 3.401, "learn_throughput": 9409.675, "synch_weights_time_ms": 2.431}, "counters": {"num_env_steps_sampled": 12096, "num_env_steps_trained": 29600, "num_agent_steps_sampled": 12093, "num_agent_steps_trained": 29600, "last_target_update_ts": 12096, "num_target_updates": 23}, "done": false, "episodes_total": 32, "training_iteration": 12, "trial_id": "5f583_00000", "experiment_id": "d83cb2d89bc543feb18deca748a0082f", "date": "2022-09-11_15-48-10", "timestamp": 1662886090, "time_this_iter_s": 2.05277156829834, "time_total_s": 24.39533519744873, "pid": 14740, "hostname": "XorgWorkstation", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "my_env", "env_config": {}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "num_workers": 3, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "ignore_worker_failures": false, "recreate_failed_workers": false, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 0.0005, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "my_env", "env_config": {}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "num_workers": 3, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "ignore_worker_failures": false, "recreate_failed_workers": false, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 0.0005, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": {"explore": false}, "off_policy_estimation_methods": {}, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": 1, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 1000, "logger_creator": null, "logger_config": null, "log_level": "INFO", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": -1, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": null, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "min_time_s_per_reporting": -1, "min_train_timesteps_per_reporting": -1, "min_sample_timesteps_per_reporting": -1, "input_evaluation": -1, "target_network_update_freq": 500, "replay_buffer_config": {"type": "<class 'ray.rllib.utils.replay_buffers.multi_agent_prioritized_replay_buffer.MultiAgentPrioritizedReplayBuffer'>", "prioritized_replay": -1, "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "worker_side_prioritization": false, "replay_mode": "independent"}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "input": "sampler", "multiagent": {"policies": {"attacker": "<ray.rllib.policy.policy.PolicySpec object at 0x00000295803B2460>", "defender": "<ray.rllib.policy.policy.PolicySpec object at 0x000002958037C820>"}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x00000295803AA280>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "tf", "num_cpus_for_driver": 1}, "off_policy_estimation_methods": {}, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": 1, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 1000, "logger_creator": null, "logger_config": null, "log_level": "INFO", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": -1, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": null, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "min_time_s_per_reporting": -1, "min_train_timesteps_per_reporting": -1, "min_sample_timesteps_per_reporting": -1, "input_evaluation": -1, "target_network_update_freq": 500, "replay_buffer_config": {"type": "<class 'ray.rllib.utils.replay_buffers.multi_agent_prioritized_replay_buffer.MultiAgentPrioritizedReplayBuffer'>", "prioritized_replay": -1, "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "worker_side_prioritization": false, "replay_mode": "independent"}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "input": "sampler", "multiagent": {"policies": {"attacker": "<ray.rllib.policy.policy.PolicySpec object at 0x000002958037C520>", "defender": "<ray.rllib.policy.policy.PolicySpec object at 0x0000029580306460>"}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x00000295803AA280>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "tf", "num_cpus_for_driver": 1}, "time_since_restore": 24.39533519744873, "timesteps_since_restore": 0, "iterations_since_restore": 12, "warmup_time": 9.31046748161316, "perf": {"cpu_util_percent": 5.766666666666667, "ram_util_percent": 50.63333333333333}}
{"custom_metrics": {}, "episode_media": {}, "num_recreated_workers": 0, "info": {"learner": {"attacker": {"learner_stats": {"cur_lr": 0.0005000000237487257, "mean_q": -14.504861831665039, "min_q": -17.3070011138916, "max_q": -9.233382225036621, "mean_td_error": -0.9919171929359436, "model": {}}, "td_error": [-0.5527353286743164, -0.5666370391845703, -0.24053955078125, 0.4242076873779297, -0.11154937744140625, -0.20175838470458984, -0.07672786712646484, 0.4417552947998047, -0.20175838470458984, 0.14642906188964844, -15.227801322937012, 1.0177249908447266, 0.29563236236572266, 0.030084609985351562, -0.8504543304443359, -0.1965465545654297], "custom_metrics": {}, "num_agent_steps_trained": 16.0}, "defender": {"learner_stats": {"cur_lr": 0.0005000000237487257, "mean_q": -0.04192186892032623, "min_q": -1.1062650680541992, "max_q": 0.9519822001457214, "mean_td_error": -0.19327199459075928, "model": {}}, "td_error": [0.42765921354293823, 0.16637639701366425, -0.5155910849571228, -0.48854872584342957, -0.11963766813278198, -0.34316903352737427, -0.4470251202583313, -0.3622886538505554, -0.021072447299957275, -0.31205612421035767, -0.21066613495349884, 0.4621856212615967, -0.42573484778404236, -0.23048895597457886, -0.240126371383667, -0.4321679174900055], "custom_metrics": {}, "num_agent_steps_trained": 16.0}}, "num_env_steps_sampled": 13104, "num_env_steps_trained": 32288, "num_agent_steps_sampled": 13101, "num_agent_steps_trained": 32288, "last_target_update_ts": 13104, "num_target_updates": 25}, "sampler_results": {"episode_reward_max": -9.899999999999999, "episode_reward_min": -383.5000000000007, "episode_reward_mean": -181.95555555555563, "episode_len_mean": 332.030303030303, "episode_media": {}, "episodes_this_iter": 1, "policy_reward_min": {"attacker": -376.60000000000076, "defender": -19.299999999999997}, "policy_reward_max": {"attacker": -10.299999999999997, "defender": 3.6000000000000005}, "policy_reward_mean": {"attacker": -175.3404040404041, "defender": -6.615151515151515}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-186.86666666666676, -201.73333333333355, -126.73333333333342, -190.63333333333333, -199.26666666666654, -154.26666666666696, -168.16666666666674, -152.5000000000002, -200.3333333333335, -164.50000000000006, -145.46666666666667, -119.16666666666663, -93.13333333333337, -141.8333333333334, -201.2666666666667, -204.33333333333317, -151.23333333333335, -175.76666666666677, -228.7333333333334, -199.20000000000005, -219.76666666666682, -226.19999999999976, -136.00000000000009, -317.6333333333334, -100.99999999999987, -9.899999999999999, -234.0, -186.36666666666693, -159.66666666666677, -178.23333333333355, -153.4, -293.73333333333323, -383.5000000000007], "episode_lengths": [283, 303, 315, 300, 328, 333, 292, 369, 314, 288, 273, 237, 151, 286, 351, 395, 286, 310, 352, 378, 304, 354, 300, 441, 337, 69, 339, 364, 288, 298, 357, 536, 826], "policy_attacker_reward": [-185.36666666666673, -184.63333333333352, -124.43333333333341, -180.03333333333336, -191.56666666666655, -143.86666666666696, -163.36666666666673, -146.2000000000002, -192.93333333333337, -160.60000000000002, -143.36666666666667, -120.76666666666664, -86.43333333333337, -137.03333333333333, -194.86666666666667, -191.83333333333312, -134.5333333333334, -168.06666666666678, -217.63333333333333, -195.7, -206.06666666666678, -215.8999999999997, -120.10000000000001, -315.3333333333334, -98.59999999999994, -10.299999999999997, -226.29999999999998, -188.46666666666678, -156.36666666666667, -177.5333333333335, -157.0, -274.43333333333317, -376.60000000000076], "policy_defender_reward": [-1.4999999999999998, -17.1, -2.3, -10.600000000000001, -7.699999999999999, -10.400000000000002, -4.800000000000001, -6.299999999999999, -7.400000000000009, -3.8999999999999995, -2.0999999999999996, 1.6000000000000005, -6.7, -4.800000000000001, -6.4, -12.5, -16.700000000000003, -7.7, -11.100000000000003, -3.5, -13.7, -10.300000000000002, -15.899999999999995, -2.2999999999999994, -2.3999999999999986, 0.4, -7.699999999999999, 2.1, -3.3000000000000016, -0.7000000000000001, 3.6000000000000005, -19.299999999999997, -6.900000000000001]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2880115407395912, "mean_inference_ms": 0.5854773269280859, "mean_action_processing_ms": 0.05908353695802915, "mean_env_wait_ms": 0.4934995717596469, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0}, "episode_reward_max": -9.899999999999999, "episode_reward_min": -383.5000000000007, "episode_reward_mean": -181.95555555555563, "episode_len_mean": 332.030303030303, "episodes_this_iter": 1, "policy_reward_min": {"attacker": -376.60000000000076, "defender": -19.299999999999997}, "policy_reward_max": {"attacker": -10.299999999999997, "defender": 3.6000000000000005}, "policy_reward_mean": {"attacker": -175.3404040404041, "defender": -6.615151515151515}, "hist_stats": {"episode_reward": [-186.86666666666676, -201.73333333333355, -126.73333333333342, -190.63333333333333, -199.26666666666654, -154.26666666666696, -168.16666666666674, -152.5000000000002, -200.3333333333335, -164.50000000000006, -145.46666666666667, -119.16666666666663, -93.13333333333337, -141.8333333333334, -201.2666666666667, -204.33333333333317, -151.23333333333335, -175.76666666666677, -228.7333333333334, -199.20000000000005, -219.76666666666682, -226.19999999999976, -136.00000000000009, -317.6333333333334, -100.99999999999987, -9.899999999999999, -234.0, -186.36666666666693, -159.66666666666677, -178.23333333333355, -153.4, -293.73333333333323, -383.5000000000007], "episode_lengths": [283, 303, 315, 300, 328, 333, 292, 369, 314, 288, 273, 237, 151, 286, 351, 395, 286, 310, 352, 378, 304, 354, 300, 441, 337, 69, 339, 364, 288, 298, 357, 536, 826], "policy_attacker_reward": [-185.36666666666673, -184.63333333333352, -124.43333333333341, -180.03333333333336, -191.56666666666655, -143.86666666666696, -163.36666666666673, -146.2000000000002, -192.93333333333337, -160.60000000000002, -143.36666666666667, -120.76666666666664, -86.43333333333337, -137.03333333333333, -194.86666666666667, -191.83333333333312, -134.5333333333334, -168.06666666666678, -217.63333333333333, -195.7, -206.06666666666678, -215.8999999999997, -120.10000000000001, -315.3333333333334, -98.59999999999994, -10.299999999999997, -226.29999999999998, -188.46666666666678, -156.36666666666667, -177.5333333333335, -157.0, -274.43333333333317, -376.60000000000076], "policy_defender_reward": [-1.4999999999999998, -17.1, -2.3, -10.600000000000001, -7.699999999999999, -10.400000000000002, -4.800000000000001, -6.299999999999999, -7.400000000000009, -3.8999999999999995, -2.0999999999999996, 1.6000000000000005, -6.7, -4.800000000000001, -6.4, -12.5, -16.700000000000003, -7.7, -11.100000000000003, -3.5, -13.7, -10.300000000000002, -15.899999999999995, -2.2999999999999994, -2.3999999999999986, 0.4, -7.699999999999999, 2.1, -3.3000000000000016, -0.7000000000000001, 3.6000000000000005, -19.299999999999997, -6.900000000000001]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2880115407395912, "mean_inference_ms": 0.5854773269280859, "mean_action_processing_ms": 0.05908353695802915, "mean_env_wait_ms": 0.4934995717596469, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "num_healthy_workers": 3, "num_agent_steps_sampled": 13101, "num_agent_steps_trained": 32288, "num_env_steps_sampled": 13104, "num_env_steps_trained": 32288, "num_env_steps_sampled_this_iter": 1008, "num_env_steps_trained_this_iter": 2688, "timesteps_total": 13104, "num_steps_trained_this_iter": 2688, "agent_timesteps_total": 13101, "timers": {"training_iteration_time_ms": 26.198, "load_time_ms": 0.251, "load_throughput": 127474.336, "learn_time_ms": 3.195, "learn_throughput": 10014.828, "synch_weights_time_ms": 2.381}, "counters": {"num_env_steps_sampled": 13104, "num_env_steps_trained": 32288, "num_agent_steps_sampled": 13101, "num_agent_steps_trained": 32288, "last_target_update_ts": 13104, "num_target_updates": 25}, "done": false, "episodes_total": 33, "training_iteration": 13, "trial_id": "5f583_00000", "experiment_id": "d83cb2d89bc543feb18deca748a0082f", "date": "2022-09-11_15-48-13", "timestamp": 1662886093, "time_this_iter_s": 2.06862735748291, "time_total_s": 26.46396255493164, "pid": 14740, "hostname": "XorgWorkstation", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "my_env", "env_config": {}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "num_workers": 3, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "ignore_worker_failures": false, "recreate_failed_workers": false, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 0.0005, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "my_env", "env_config": {}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "num_workers": 3, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "ignore_worker_failures": false, "recreate_failed_workers": false, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 0.0005, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": {"explore": false}, "off_policy_estimation_methods": {}, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": 1, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 1000, "logger_creator": null, "logger_config": null, "log_level": "INFO", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": -1, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": null, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "min_time_s_per_reporting": -1, "min_train_timesteps_per_reporting": -1, "min_sample_timesteps_per_reporting": -1, "input_evaluation": -1, "target_network_update_freq": 500, "replay_buffer_config": {"type": "<class 'ray.rllib.utils.replay_buffers.multi_agent_prioritized_replay_buffer.MultiAgentPrioritizedReplayBuffer'>", "prioritized_replay": -1, "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "worker_side_prioritization": false, "replay_mode": "independent"}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "input": "sampler", "multiagent": {"policies": {"attacker": "<ray.rllib.policy.policy.PolicySpec object at 0x00000295802DD3D0>", "defender": "<ray.rllib.policy.policy.PolicySpec object at 0x0000029580306FA0>"}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x0000029580408EE0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "tf", "num_cpus_for_driver": 1}, "off_policy_estimation_methods": {}, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": 1, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 1000, "logger_creator": null, "logger_config": null, "log_level": "INFO", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": -1, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": null, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "min_time_s_per_reporting": -1, "min_train_timesteps_per_reporting": -1, "min_sample_timesteps_per_reporting": -1, "input_evaluation": -1, "target_network_update_freq": 500, "replay_buffer_config": {"type": "<class 'ray.rllib.utils.replay_buffers.multi_agent_prioritized_replay_buffer.MultiAgentPrioritizedReplayBuffer'>", "prioritized_replay": -1, "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "worker_side_prioritization": false, "replay_mode": "independent"}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "input": "sampler", "multiagent": {"policies": {"attacker": "<ray.rllib.policy.policy.PolicySpec object at 0x0000029580306130>", "defender": "<ray.rllib.policy.policy.PolicySpec object at 0x0000029580306640>"}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x0000029580408EE0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "tf", "num_cpus_for_driver": 1}, "time_since_restore": 26.46396255493164, "timesteps_since_restore": 0, "iterations_since_restore": 13, "warmup_time": 9.31046748161316, "perf": {"cpu_util_percent": 4.466666666666667, "ram_util_percent": 50.73333333333333}}
{"custom_metrics": {}, "episode_media": {}, "num_recreated_workers": 0, "info": {"learner": {"attacker": {"learner_stats": {"cur_lr": 0.0005000000237487257, "mean_q": -13.186938285827637, "min_q": -17.933204650878906, "max_q": -10.315201759338379, "mean_td_error": 0.13878464698791504, "model": {}}, "td_error": [0.2204427719116211, 0.19173526763916016, 0.3280372619628906, -0.0952005386352539, -0.03484535217285156, -0.4803733825683594, 1.1375246047973633, 0.19173526763916016, -0.5876731872558594, -0.28296661376953125, 0.23055362701416016, -1.1093568801879883, 1.6396236419677734, 0.4351511001586914, -0.3516244888305664, 0.7877912521362305], "custom_metrics": {}, "num_agent_steps_trained": 16.0}, "defender": {"learner_stats": {"cur_lr": 0.0005000000237487257, "mean_q": 0.2943309545516968, "min_q": -0.17503045499324799, "max_q": 1.1570940017700195, "mean_td_error": 0.15104743838310242, "model": {}}, "td_error": [0.09478013217449188, 0.18799278140068054, 0.1396886557340622, 0.23027724027633667, 0.10568384826183319, 0.16123425960540771, -0.011284112930297852, 0.13756215572357178, 0.8888647556304932, -0.005854696035385132, 0.24617940187454224, -0.44646450877189636, 0.2658458948135376, 0.10568384826183319, 0.32785317301750183, -0.011284112930297852], "custom_metrics": {}, "num_agent_steps_trained": 16.0}}, "num_env_steps_sampled": 14112, "num_env_steps_trained": 34976, "num_agent_steps_sampled": 14109, "num_agent_steps_trained": 34976, "last_target_update_ts": 14112, "num_target_updates": 27}, "sampler_results": {"episode_reward_max": -9.899999999999999, "episode_reward_min": -673.2666666666697, "episode_reward_mean": -200.68761904761925, "episode_len_mean": 375.57142857142856, "episode_media": {}, "episodes_this_iter": 2, "policy_reward_min": {"attacker": -670.1666666666697, "defender": -19.299999999999997}, "policy_reward_max": {"attacker": -10.299999999999997, "defender": 3.6000000000000005}, "policy_reward_mean": {"attacker": -194.20190476190496, "defender": -6.485714285714286}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-186.86666666666676, -201.73333333333355, -126.73333333333342, -190.63333333333333, -199.26666666666654, -154.26666666666696, -168.16666666666674, -152.5000000000002, -200.3333333333335, -164.50000000000006, -145.46666666666667, -119.16666666666663, -93.13333333333337, -141.8333333333334, -201.2666666666667, -204.33333333333317, -151.23333333333335, -175.76666666666677, -228.7333333333334, -199.20000000000005, -219.76666666666682, -226.19999999999976, -136.00000000000009, -317.6333333333334, -100.99999999999987, -9.899999999999999, -234.0, -186.36666666666693, -159.66666666666677, -178.23333333333355, -153.4, -293.73333333333323, -383.5000000000007, -346.26666666666785, -673.2666666666697], "episode_lengths": [283, 303, 315, 300, 328, 333, 292, 369, 314, 288, 273, 237, 151, 286, 351, 395, 286, 310, 352, 378, 304, 354, 300, 441, 337, 69, 339, 364, 288, 298, 357, 536, 826, 841, 1347], "policy_attacker_reward": [-185.36666666666673, -184.63333333333352, -124.43333333333341, -180.03333333333336, -191.56666666666655, -143.86666666666696, -163.36666666666673, -146.2000000000002, -192.93333333333337, -160.60000000000002, -143.36666666666667, -120.76666666666664, -86.43333333333337, -137.03333333333333, -194.86666666666667, -191.83333333333312, -134.5333333333334, -168.06666666666678, -217.63333333333333, -195.7, -206.06666666666678, -215.8999999999997, -120.10000000000001, -315.3333333333334, -98.59999999999994, -10.299999999999997, -226.29999999999998, -188.46666666666678, -156.36666666666667, -177.5333333333335, -157.0, -274.43333333333317, -376.60000000000076, -340.66666666666777, -670.1666666666697], "policy_defender_reward": [-1.4999999999999998, -17.1, -2.3, -10.600000000000001, -7.699999999999999, -10.400000000000002, -4.800000000000001, -6.299999999999999, -7.400000000000009, -3.8999999999999995, -2.0999999999999996, 1.6000000000000005, -6.7, -4.800000000000001, -6.4, -12.5, -16.700000000000003, -7.7, -11.100000000000003, -3.5, -13.7, -10.300000000000002, -15.899999999999995, -2.2999999999999994, -2.3999999999999986, 0.4, -7.699999999999999, 2.1, -3.3000000000000016, -0.7000000000000001, 3.6000000000000005, -19.299999999999997, -6.900000000000001, -5.6000000000000005, -3.099999999999999]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2870773295465634, "mean_inference_ms": 0.5823878409881849, "mean_action_processing_ms": 0.05902327941063448, "mean_env_wait_ms": 0.4925479145159936, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0}, "episode_reward_max": -9.899999999999999, "episode_reward_min": -673.2666666666697, "episode_reward_mean": -200.68761904761925, "episode_len_mean": 375.57142857142856, "episodes_this_iter": 2, "policy_reward_min": {"attacker": -670.1666666666697, "defender": -19.299999999999997}, "policy_reward_max": {"attacker": -10.299999999999997, "defender": 3.6000000000000005}, "policy_reward_mean": {"attacker": -194.20190476190496, "defender": -6.485714285714286}, "hist_stats": {"episode_reward": [-186.86666666666676, -201.73333333333355, -126.73333333333342, -190.63333333333333, -199.26666666666654, -154.26666666666696, -168.16666666666674, -152.5000000000002, -200.3333333333335, -164.50000000000006, -145.46666666666667, -119.16666666666663, -93.13333333333337, -141.8333333333334, -201.2666666666667, -204.33333333333317, -151.23333333333335, -175.76666666666677, -228.7333333333334, -199.20000000000005, -219.76666666666682, -226.19999999999976, -136.00000000000009, -317.6333333333334, -100.99999999999987, -9.899999999999999, -234.0, -186.36666666666693, -159.66666666666677, -178.23333333333355, -153.4, -293.73333333333323, -383.5000000000007, -346.26666666666785, -673.2666666666697], "episode_lengths": [283, 303, 315, 300, 328, 333, 292, 369, 314, 288, 273, 237, 151, 286, 351, 395, 286, 310, 352, 378, 304, 354, 300, 441, 337, 69, 339, 364, 288, 298, 357, 536, 826, 841, 1347], "policy_attacker_reward": [-185.36666666666673, -184.63333333333352, -124.43333333333341, -180.03333333333336, -191.56666666666655, -143.86666666666696, -163.36666666666673, -146.2000000000002, -192.93333333333337, -160.60000000000002, -143.36666666666667, -120.76666666666664, -86.43333333333337, -137.03333333333333, -194.86666666666667, -191.83333333333312, -134.5333333333334, -168.06666666666678, -217.63333333333333, -195.7, -206.06666666666678, -215.8999999999997, -120.10000000000001, -315.3333333333334, -98.59999999999994, -10.299999999999997, -226.29999999999998, -188.46666666666678, -156.36666666666667, -177.5333333333335, -157.0, -274.43333333333317, -376.60000000000076, -340.66666666666777, -670.1666666666697], "policy_defender_reward": [-1.4999999999999998, -17.1, -2.3, -10.600000000000001, -7.699999999999999, -10.400000000000002, -4.800000000000001, -6.299999999999999, -7.400000000000009, -3.8999999999999995, -2.0999999999999996, 1.6000000000000005, -6.7, -4.800000000000001, -6.4, -12.5, -16.700000000000003, -7.7, -11.100000000000003, -3.5, -13.7, -10.300000000000002, -15.899999999999995, -2.2999999999999994, -2.3999999999999986, 0.4, -7.699999999999999, 2.1, -3.3000000000000016, -0.7000000000000001, 3.6000000000000005, -19.299999999999997, -6.900000000000001, -5.6000000000000005, -3.099999999999999]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2870773295465634, "mean_inference_ms": 0.5823878409881849, "mean_action_processing_ms": 0.05902327941063448, "mean_env_wait_ms": 0.4925479145159936, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "num_healthy_workers": 3, "num_agent_steps_sampled": 14109, "num_agent_steps_trained": 34976, "num_env_steps_sampled": 14112, "num_env_steps_trained": 34976, "num_env_steps_sampled_this_iter": 1008, "num_env_steps_trained_this_iter": 2688, "timesteps_total": 14112, "num_steps_trained_this_iter": 2688, "agent_timesteps_total": 14109, "timers": {"training_iteration_time_ms": 24.305, "load_time_ms": 0.0, "load_throughput": 0.0, "learn_time_ms": 3.169, "learn_throughput": 10098.316, "synch_weights_time_ms": 2.442}, "counters": {"num_env_steps_sampled": 14112, "num_env_steps_trained": 34976, "num_agent_steps_sampled": 14109, "num_agent_steps_trained": 34976, "last_target_update_ts": 14112, "num_target_updates": 27}, "done": false, "episodes_total": 35, "training_iteration": 14, "trial_id": "5f583_00000", "experiment_id": "d83cb2d89bc543feb18deca748a0082f", "date": "2022-09-11_15-48-15", "timestamp": 1662886095, "time_this_iter_s": 2.0359644889831543, "time_total_s": 28.499927043914795, "pid": 14740, "hostname": "XorgWorkstation", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "my_env", "env_config": {}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "num_workers": 3, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "ignore_worker_failures": false, "recreate_failed_workers": false, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 0.0005, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "my_env", "env_config": {}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "num_workers": 3, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "ignore_worker_failures": false, "recreate_failed_workers": false, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 0.0005, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": {"explore": false}, "off_policy_estimation_methods": {}, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": 1, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 1000, "logger_creator": null, "logger_config": null, "log_level": "INFO", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": -1, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": null, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "min_time_s_per_reporting": -1, "min_train_timesteps_per_reporting": -1, "min_sample_timesteps_per_reporting": -1, "input_evaluation": -1, "target_network_update_freq": 500, "replay_buffer_config": {"type": "<class 'ray.rllib.utils.replay_buffers.multi_agent_prioritized_replay_buffer.MultiAgentPrioritizedReplayBuffer'>", "prioritized_replay": -1, "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "worker_side_prioritization": false, "replay_mode": "independent"}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "input": "sampler", "multiagent": {"policies": {"attacker": "<ray.rllib.policy.policy.PolicySpec object at 0x000002958037DC70>", "defender": "<ray.rllib.policy.policy.PolicySpec object at 0x00000295803825B0>"}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x000002958029D280>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "tf", "num_cpus_for_driver": 1}, "off_policy_estimation_methods": {}, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": 1, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 1000, "logger_creator": null, "logger_config": null, "log_level": "INFO", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": -1, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": null, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "min_time_s_per_reporting": -1, "min_train_timesteps_per_reporting": -1, "min_sample_timesteps_per_reporting": -1, "input_evaluation": -1, "target_network_update_freq": 500, "replay_buffer_config": {"type": "<class 'ray.rllib.utils.replay_buffers.multi_agent_prioritized_replay_buffer.MultiAgentPrioritizedReplayBuffer'>", "prioritized_replay": -1, "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "worker_side_prioritization": false, "replay_mode": "independent"}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "input": "sampler", "multiagent": {"policies": {"attacker": "<ray.rllib.policy.policy.PolicySpec object at 0x0000029580382910>", "defender": "<ray.rllib.policy.policy.PolicySpec object at 0x0000029580348220>"}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x000002958029D280>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "tf", "num_cpus_for_driver": 1}, "time_since_restore": 28.499927043914795, "timesteps_since_restore": 0, "iterations_since_restore": 14, "warmup_time": 9.31046748161316, "perf": {"cpu_util_percent": 5.133333333333334, "ram_util_percent": 50.70000000000001}}
{"custom_metrics": {}, "episode_media": {}, "num_recreated_workers": 0, "info": {"learner": {"attacker": {"learner_stats": {"cur_lr": 0.0005000000237487257, "mean_q": -12.571617126464844, "min_q": -18.038570404052734, "max_q": -3.5542259216308594, "mean_td_error": -0.3392031788825989, "model": {}}, "td_error": [-0.07646560668945312, 0.42932558059692383, 0.4676361083984375, 0.1560230255126953, 0.1479778289794922, -0.2583942413330078, -0.10415363311767578, 0.7333850860595703, 0.09397220611572266, -0.8553118705749512, -2.254225969314575, -0.040851593017578125, 0.22145462036132812, -2.501262664794922, 0.8746967315673828, -2.461056709289551], "custom_metrics": {}, "num_agent_steps_trained": 16.0}, "defender": {"learner_stats": {"cur_lr": 0.0005000000237487257, "mean_q": 0.6296557784080505, "min_q": -0.18031007051467896, "max_q": 1.6610157489776611, "mean_td_error": 0.07226347923278809, "model": {}}, "td_error": [0.09708088636398315, 0.0817960798740387, -0.24828335642814636, 0.13024169206619263, 0.1929771900177002, 0.22658652067184448, -0.4221247732639313, -0.025159478187561035, 0.03297809883952141, 0.1548621654510498, -0.21168795228004456, 0.18427228927612305, -0.059239231050014496, -0.019339382648468018, 0.702231228351593, 0.3390235900878906], "custom_metrics": {}, "num_agent_steps_trained": 16.0}}, "num_env_steps_sampled": 15120, "num_env_steps_trained": 37664, "num_agent_steps_sampled": 15118, "num_agent_steps_trained": 37664, "last_target_update_ts": 15120, "num_target_updates": 29}, "sampler_results": {"episode_reward_max": -9.899999999999999, "episode_reward_min": -673.2666666666697, "episode_reward_mean": -204.40964912280728, "episode_len_mean": 386.1578947368421, "episode_media": {}, "episodes_this_iter": 3, "policy_reward_min": {"attacker": -670.1666666666697, "defender": -19.299999999999997}, "policy_reward_max": {"attacker": -10.299999999999997, "defender": 3.6000000000000005}, "policy_reward_mean": {"attacker": -198.38333333333355, "defender": -6.026315789473685}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-186.86666666666676, -201.73333333333355, -126.73333333333342, -190.63333333333333, -199.26666666666654, -154.26666666666696, -168.16666666666674, -152.5000000000002, -200.3333333333335, -164.50000000000006, -145.46666666666667, -119.16666666666663, -93.13333333333337, -141.8333333333334, -201.2666666666667, -204.33333333333317, -151.23333333333335, -175.76666666666677, -228.7333333333334, -199.20000000000005, -219.76666666666682, -226.19999999999976, -136.00000000000009, -317.6333333333334, -100.99999999999987, -9.899999999999999, -234.0, -186.36666666666693, -159.66666666666677, -178.23333333333355, -153.4, -293.73333333333323, -383.5000000000007, -346.26666666666785, -673.2666666666697, -234.000000000002, -200.10000000000014, -309.40000000000055], "episode_lengths": [283, 303, 315, 300, 328, 333, 292, 369, 314, 288, 273, 237, 151, 286, 351, 395, 286, 310, 352, 378, 304, 354, 300, 441, 337, 69, 339, 364, 288, 298, 357, 536, 826, 841, 1347, 705, 209, 615], "policy_attacker_reward": [-185.36666666666673, -184.63333333333352, -124.43333333333341, -180.03333333333336, -191.56666666666655, -143.86666666666696, -163.36666666666673, -146.2000000000002, -192.93333333333337, -160.60000000000002, -143.36666666666667, -120.76666666666664, -86.43333333333337, -137.03333333333333, -194.86666666666667, -191.83333333333312, -134.5333333333334, -168.06666666666678, -217.63333333333333, -195.7, -206.06666666666678, -215.8999999999997, -120.10000000000001, -315.3333333333334, -98.59999999999994, -10.299999999999997, -226.29999999999998, -188.46666666666678, -156.36666666666667, -177.5333333333335, -157.0, -274.43333333333317, -376.60000000000076, -340.66666666666777, -670.1666666666697, -233.200000000002, -201.2000000000001, -307.1000000000005], "policy_defender_reward": [-1.4999999999999998, -17.1, -2.3, -10.600000000000001, -7.699999999999999, -10.400000000000002, -4.800000000000001, -6.299999999999999, -7.400000000000009, -3.8999999999999995, -2.0999999999999996, 1.6000000000000005, -6.7, -4.800000000000001, -6.4, -12.5, -16.700000000000003, -7.7, -11.100000000000003, -3.5, -13.7, -10.300000000000002, -15.899999999999995, -2.2999999999999994, -2.3999999999999986, 0.4, -7.699999999999999, 2.1, -3.3000000000000016, -0.7000000000000001, 3.6000000000000005, -19.299999999999997, -6.900000000000001, -5.6000000000000005, -3.099999999999999, -0.7999999999999989, 1.0999999999999999, -2.3]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2865751244984955, "mean_inference_ms": 0.5785863177459076, "mean_action_processing_ms": 0.058846175312528434, "mean_env_wait_ms": 0.4912788506839003, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0}, "episode_reward_max": -9.899999999999999, "episode_reward_min": -673.2666666666697, "episode_reward_mean": -204.40964912280728, "episode_len_mean": 386.1578947368421, "episodes_this_iter": 3, "policy_reward_min": {"attacker": -670.1666666666697, "defender": -19.299999999999997}, "policy_reward_max": {"attacker": -10.299999999999997, "defender": 3.6000000000000005}, "policy_reward_mean": {"attacker": -198.38333333333355, "defender": -6.026315789473685}, "hist_stats": {"episode_reward": [-186.86666666666676, -201.73333333333355, -126.73333333333342, -190.63333333333333, -199.26666666666654, -154.26666666666696, -168.16666666666674, -152.5000000000002, -200.3333333333335, -164.50000000000006, -145.46666666666667, -119.16666666666663, -93.13333333333337, -141.8333333333334, -201.2666666666667, -204.33333333333317, -151.23333333333335, -175.76666666666677, -228.7333333333334, -199.20000000000005, -219.76666666666682, -226.19999999999976, -136.00000000000009, -317.6333333333334, -100.99999999999987, -9.899999999999999, -234.0, -186.36666666666693, -159.66666666666677, -178.23333333333355, -153.4, -293.73333333333323, -383.5000000000007, -346.26666666666785, -673.2666666666697, -234.000000000002, -200.10000000000014, -309.40000000000055], "episode_lengths": [283, 303, 315, 300, 328, 333, 292, 369, 314, 288, 273, 237, 151, 286, 351, 395, 286, 310, 352, 378, 304, 354, 300, 441, 337, 69, 339, 364, 288, 298, 357, 536, 826, 841, 1347, 705, 209, 615], "policy_attacker_reward": [-185.36666666666673, -184.63333333333352, -124.43333333333341, -180.03333333333336, -191.56666666666655, -143.86666666666696, -163.36666666666673, -146.2000000000002, -192.93333333333337, -160.60000000000002, -143.36666666666667, -120.76666666666664, -86.43333333333337, -137.03333333333333, -194.86666666666667, -191.83333333333312, -134.5333333333334, -168.06666666666678, -217.63333333333333, -195.7, -206.06666666666678, -215.8999999999997, -120.10000000000001, -315.3333333333334, -98.59999999999994, -10.299999999999997, -226.29999999999998, -188.46666666666678, -156.36666666666667, -177.5333333333335, -157.0, -274.43333333333317, -376.60000000000076, -340.66666666666777, -670.1666666666697, -233.200000000002, -201.2000000000001, -307.1000000000005], "policy_defender_reward": [-1.4999999999999998, -17.1, -2.3, -10.600000000000001, -7.699999999999999, -10.400000000000002, -4.800000000000001, -6.299999999999999, -7.400000000000009, -3.8999999999999995, -2.0999999999999996, 1.6000000000000005, -6.7, -4.800000000000001, -6.4, -12.5, -16.700000000000003, -7.7, -11.100000000000003, -3.5, -13.7, -10.300000000000002, -15.899999999999995, -2.2999999999999994, -2.3999999999999986, 0.4, -7.699999999999999, 2.1, -3.3000000000000016, -0.7000000000000001, 3.6000000000000005, -19.299999999999997, -6.900000000000001, -5.6000000000000005, -3.099999999999999, -0.7999999999999989, 1.0999999999999999, -2.3]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2865751244984955, "mean_inference_ms": 0.5785863177459076, "mean_action_processing_ms": 0.058846175312528434, "mean_env_wait_ms": 0.4912788506839003, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "num_healthy_workers": 3, "num_agent_steps_sampled": 15118, "num_agent_steps_trained": 37664, "num_env_steps_sampled": 15120, "num_env_steps_trained": 37664, "num_env_steps_sampled_this_iter": 1008, "num_env_steps_trained_this_iter": 2688, "timesteps_total": 15120, "num_steps_trained_this_iter": 2688, "agent_timesteps_total": 15118, "timers": {"training_iteration_time_ms": 24.118, "load_time_ms": 0.15, "load_throughput": 212807.56, "learn_time_ms": 3.565, "learn_throughput": 8976.273, "synch_weights_time_ms": 2.597}, "counters": {"num_env_steps_sampled": 15120, "num_env_steps_trained": 37664, "num_agent_steps_sampled": 15118, "num_agent_steps_trained": 37664, "last_target_update_ts": 15120, "num_target_updates": 29}, "done": false, "episodes_total": 38, "training_iteration": 15, "trial_id": "5f583_00000", "experiment_id": "d83cb2d89bc543feb18deca748a0082f", "date": "2022-09-11_15-48-17", "timestamp": 1662886097, "time_this_iter_s": 2.0577499866485596, "time_total_s": 30.557677030563354, "pid": 14740, "hostname": "XorgWorkstation", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "my_env", "env_config": {}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "num_workers": 3, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "ignore_worker_failures": false, "recreate_failed_workers": false, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 0.0005, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "my_env", "env_config": {}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "num_workers": 3, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "ignore_worker_failures": false, "recreate_failed_workers": false, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 0.0005, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": {"explore": false}, "off_policy_estimation_methods": {}, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": 1, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 1000, "logger_creator": null, "logger_config": null, "log_level": "INFO", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": -1, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": null, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "min_time_s_per_reporting": -1, "min_train_timesteps_per_reporting": -1, "min_sample_timesteps_per_reporting": -1, "input_evaluation": -1, "target_network_update_freq": 500, "replay_buffer_config": {"type": "<class 'ray.rllib.utils.replay_buffers.multi_agent_prioritized_replay_buffer.MultiAgentPrioritizedReplayBuffer'>", "prioritized_replay": -1, "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "worker_side_prioritization": false, "replay_mode": "independent"}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "input": "sampler", "multiagent": {"policies": {"attacker": "<ray.rllib.policy.policy.PolicySpec object at 0x00000295803061F0>", "defender": "<ray.rllib.policy.policy.PolicySpec object at 0x000002958037D190>"}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x00000295802F7700>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "tf", "num_cpus_for_driver": 1}, "off_policy_estimation_methods": {}, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": 1, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 1000, "logger_creator": null, "logger_config": null, "log_level": "INFO", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": -1, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": null, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "min_time_s_per_reporting": -1, "min_train_timesteps_per_reporting": -1, "min_sample_timesteps_per_reporting": -1, "input_evaluation": -1, "target_network_update_freq": 500, "replay_buffer_config": {"type": "<class 'ray.rllib.utils.replay_buffers.multi_agent_prioritized_replay_buffer.MultiAgentPrioritizedReplayBuffer'>", "prioritized_replay": -1, "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "worker_side_prioritization": false, "replay_mode": "independent"}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "input": "sampler", "multiagent": {"policies": {"attacker": "<ray.rllib.policy.policy.PolicySpec object at 0x000002958037D340>", "defender": "<ray.rllib.policy.policy.PolicySpec object at 0x00000295803B1CA0>"}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x00000295802F7700>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "tf", "num_cpus_for_driver": 1}, "time_since_restore": 30.557677030563354, "timesteps_since_restore": 0, "iterations_since_restore": 15, "warmup_time": 9.31046748161316, "perf": {"cpu_util_percent": 4.666666666666667, "ram_util_percent": 50.76666666666667}}
{"custom_metrics": {}, "episode_media": {}, "num_recreated_workers": 0, "info": {"learner": {"attacker": {"learner_stats": {"cur_lr": 0.0005000000237487257, "mean_q": -14.14293098449707, "min_q": -20.100900650024414, "max_q": -8.383853912353516, "mean_td_error": -0.4079357385635376, "model": {}}, "td_error": [-0.9099254608154297, -0.46796417236328125, -0.8211040496826172, -0.07538604736328125, 0.00799560546875, -0.2006816864013672, -0.04100608825683594, -1.5706958770751953, -0.26129627227783203, -0.5631446838378906, -0.5045785903930664, -0.27789306640625, -0.39091014862060547, -0.10484790802001953, -0.27014732360839844, -0.07538604736328125], "custom_metrics": {}, "num_agent_steps_trained": 16.0}, "defender": {"learner_stats": {"cur_lr": 0.0005000000237487257, "mean_q": 0.420678973197937, "min_q": -0.9572281837463379, "max_q": 2.7957205772399902, "mean_td_error": -0.01898871175944805, "model": {}}, "td_error": [0.10900366306304932, 0.1889709234237671, 0.6344069242477417, 0.08866962790489197, -0.004058778285980225, 0.6306291818618774, 0.005556568503379822, -2.767570972442627, -0.19250354170799255, 0.006734728813171387, -0.12521514296531677, -0.11092174053192139, -0.0155143141746521, 1.2706185579299927, -0.37640631198883057, 0.35378125309944153], "custom_metrics": {}, "num_agent_steps_trained": 16.0}}, "num_env_steps_sampled": 16128, "num_env_steps_trained": 40352, "num_agent_steps_sampled": 16126, "num_agent_steps_trained": 40352, "last_target_update_ts": 16128, "num_target_updates": 31}, "sampler_results": {"episode_reward_max": -9.899999999999999, "episode_reward_min": -673.2666666666697, "episode_reward_mean": -207.7769230769233, "episode_len_mean": 391.05128205128204, "episode_media": {}, "episodes_this_iter": 1, "policy_reward_min": {"attacker": -670.1666666666697, "defender": -20.0}, "policy_reward_max": {"attacker": -10.299999999999997, "defender": 3.6000000000000005}, "policy_reward_mean": {"attacker": -201.3923076923079, "defender": -6.384615384615385}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-186.86666666666676, -201.73333333333355, -126.73333333333342, -190.63333333333333, -199.26666666666654, -154.26666666666696, -168.16666666666674, -152.5000000000002, -200.3333333333335, -164.50000000000006, -145.46666666666667, -119.16666666666663, -93.13333333333337, -141.8333333333334, -201.2666666666667, -204.33333333333317, -151.23333333333335, -175.76666666666677, -228.7333333333334, -199.20000000000005, -219.76666666666682, -226.19999999999976, -136.00000000000009, -317.6333333333334, -100.99999999999987, -9.899999999999999, -234.0, -186.36666666666693, -159.66666666666677, -178.23333333333355, -153.4, -293.73333333333323, -383.5000000000007, -346.26666666666785, -673.2666666666697, -234.000000000002, -200.10000000000014, -309.40000000000055, -335.7333333333329], "episode_lengths": [283, 303, 315, 300, 328, 333, 292, 369, 314, 288, 273, 237, 151, 286, 351, 395, 286, 310, 352, 378, 304, 354, 300, 441, 337, 69, 339, 364, 288, 298, 357, 536, 826, 841, 1347, 705, 209, 615, 577], "policy_attacker_reward": [-185.36666666666673, -184.63333333333352, -124.43333333333341, -180.03333333333336, -191.56666666666655, -143.86666666666696, -163.36666666666673, -146.2000000000002, -192.93333333333337, -160.60000000000002, -143.36666666666667, -120.76666666666664, -86.43333333333337, -137.03333333333333, -194.86666666666667, -191.83333333333312, -134.5333333333334, -168.06666666666678, -217.63333333333333, -195.7, -206.06666666666678, -215.8999999999997, -120.10000000000001, -315.3333333333334, -98.59999999999994, -10.299999999999997, -226.29999999999998, -188.46666666666678, -156.36666666666667, -177.5333333333335, -157.0, -274.43333333333317, -376.60000000000076, -340.66666666666777, -670.1666666666697, -233.200000000002, -201.2000000000001, -307.1000000000005, -315.73333333333284], "policy_defender_reward": [-1.4999999999999998, -17.1, -2.3, -10.600000000000001, -7.699999999999999, -10.400000000000002, -4.800000000000001, -6.299999999999999, -7.400000000000009, -3.8999999999999995, -2.0999999999999996, 1.6000000000000005, -6.7, -4.800000000000001, -6.4, -12.5, -16.700000000000003, -7.7, -11.100000000000003, -3.5, -13.7, -10.300000000000002, -15.899999999999995, -2.2999999999999994, -2.3999999999999986, 0.4, -7.699999999999999, 2.1, -3.3000000000000016, -0.7000000000000001, 3.6000000000000005, -19.299999999999997, -6.900000000000001, -5.6000000000000005, -3.099999999999999, -0.7999999999999989, 1.0999999999999999, -2.3, -20.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.28619107641145614, "mean_inference_ms": 0.5773866464334844, "mean_action_processing_ms": 0.05883076597210477, "mean_env_wait_ms": 0.4908928964253309, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0}, "episode_reward_max": -9.899999999999999, "episode_reward_min": -673.2666666666697, "episode_reward_mean": -207.7769230769233, "episode_len_mean": 391.05128205128204, "episodes_this_iter": 1, "policy_reward_min": {"attacker": -670.1666666666697, "defender": -20.0}, "policy_reward_max": {"attacker": -10.299999999999997, "defender": 3.6000000000000005}, "policy_reward_mean": {"attacker": -201.3923076923079, "defender": -6.384615384615385}, "hist_stats": {"episode_reward": [-186.86666666666676, -201.73333333333355, -126.73333333333342, -190.63333333333333, -199.26666666666654, -154.26666666666696, -168.16666666666674, -152.5000000000002, -200.3333333333335, -164.50000000000006, -145.46666666666667, -119.16666666666663, -93.13333333333337, -141.8333333333334, -201.2666666666667, -204.33333333333317, -151.23333333333335, -175.76666666666677, -228.7333333333334, -199.20000000000005, -219.76666666666682, -226.19999999999976, -136.00000000000009, -317.6333333333334, -100.99999999999987, -9.899999999999999, -234.0, -186.36666666666693, -159.66666666666677, -178.23333333333355, -153.4, -293.73333333333323, -383.5000000000007, -346.26666666666785, -673.2666666666697, -234.000000000002, -200.10000000000014, -309.40000000000055, -335.7333333333329], "episode_lengths": [283, 303, 315, 300, 328, 333, 292, 369, 314, 288, 273, 237, 151, 286, 351, 395, 286, 310, 352, 378, 304, 354, 300, 441, 337, 69, 339, 364, 288, 298, 357, 536, 826, 841, 1347, 705, 209, 615, 577], "policy_attacker_reward": [-185.36666666666673, -184.63333333333352, -124.43333333333341, -180.03333333333336, -191.56666666666655, -143.86666666666696, -163.36666666666673, -146.2000000000002, -192.93333333333337, -160.60000000000002, -143.36666666666667, -120.76666666666664, -86.43333333333337, -137.03333333333333, -194.86666666666667, -191.83333333333312, -134.5333333333334, -168.06666666666678, -217.63333333333333, -195.7, -206.06666666666678, -215.8999999999997, -120.10000000000001, -315.3333333333334, -98.59999999999994, -10.299999999999997, -226.29999999999998, -188.46666666666678, -156.36666666666667, -177.5333333333335, -157.0, -274.43333333333317, -376.60000000000076, -340.66666666666777, -670.1666666666697, -233.200000000002, -201.2000000000001, -307.1000000000005, -315.73333333333284], "policy_defender_reward": [-1.4999999999999998, -17.1, -2.3, -10.600000000000001, -7.699999999999999, -10.400000000000002, -4.800000000000001, -6.299999999999999, -7.400000000000009, -3.8999999999999995, -2.0999999999999996, 1.6000000000000005, -6.7, -4.800000000000001, -6.4, -12.5, -16.700000000000003, -7.7, -11.100000000000003, -3.5, -13.7, -10.300000000000002, -15.899999999999995, -2.2999999999999994, -2.3999999999999986, 0.4, -7.699999999999999, 2.1, -3.3000000000000016, -0.7000000000000001, 3.6000000000000005, -19.299999999999997, -6.900000000000001, -5.6000000000000005, -3.099999999999999, -0.7999999999999989, 1.0999999999999999, -2.3, -20.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.28619107641145614, "mean_inference_ms": 0.5773866464334844, "mean_action_processing_ms": 0.05883076597210477, "mean_env_wait_ms": 0.4908928964253309, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "num_healthy_workers": 3, "num_agent_steps_sampled": 16126, "num_agent_steps_trained": 40352, "num_env_steps_sampled": 16128, "num_env_steps_trained": 40352, "num_env_steps_sampled_this_iter": 1008, "num_env_steps_trained_this_iter": 2688, "timesteps_total": 16128, "num_steps_trained_this_iter": 2688, "agent_timesteps_total": 16126, "timers": {"training_iteration_time_ms": 25.287, "load_time_ms": 0.1, "load_throughput": 320023.195, "learn_time_ms": 3.56, "learn_throughput": 8989.44, "synch_weights_time_ms": 2.156}, "counters": {"num_env_steps_sampled": 16128, "num_env_steps_trained": 40352, "num_agent_steps_sampled": 16126, "num_agent_steps_trained": 40352, "last_target_update_ts": 16128, "num_target_updates": 31}, "done": false, "episodes_total": 39, "training_iteration": 16, "trial_id": "5f583_00000", "experiment_id": "d83cb2d89bc543feb18deca748a0082f", "date": "2022-09-11_15-48-19", "timestamp": 1662886099, "time_this_iter_s": 2.0735442638397217, "time_total_s": 32.631221294403076, "pid": 14740, "hostname": "XorgWorkstation", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "my_env", "env_config": {}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "num_workers": 3, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "ignore_worker_failures": false, "recreate_failed_workers": false, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 0.0005, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "my_env", "env_config": {}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "num_workers": 3, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "ignore_worker_failures": false, "recreate_failed_workers": false, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 0.0005, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": {"explore": false}, "off_policy_estimation_methods": {}, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": 1, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 1000, "logger_creator": null, "logger_config": null, "log_level": "INFO", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": -1, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": null, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "min_time_s_per_reporting": -1, "min_train_timesteps_per_reporting": -1, "min_sample_timesteps_per_reporting": -1, "input_evaluation": -1, "target_network_update_freq": 500, "replay_buffer_config": {"type": "<class 'ray.rllib.utils.replay_buffers.multi_agent_prioritized_replay_buffer.MultiAgentPrioritizedReplayBuffer'>", "prioritized_replay": -1, "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "worker_side_prioritization": false, "replay_mode": "independent"}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "input": "sampler", "multiagent": {"policies": {"attacker": "<ray.rllib.policy.policy.PolicySpec object at 0x00000295803825B0>", "defender": "<ray.rllib.policy.policy.PolicySpec object at 0x00000295802FFD30>"}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x0000029580261700>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "tf", "num_cpus_for_driver": 1}, "off_policy_estimation_methods": {}, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": 1, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 1000, "logger_creator": null, "logger_config": null, "log_level": "INFO", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": -1, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": null, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "min_time_s_per_reporting": -1, "min_train_timesteps_per_reporting": -1, "min_sample_timesteps_per_reporting": -1, "input_evaluation": -1, "target_network_update_freq": 500, "replay_buffer_config": {"type": "<class 'ray.rllib.utils.replay_buffers.multi_agent_prioritized_replay_buffer.MultiAgentPrioritizedReplayBuffer'>", "prioritized_replay": -1, "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "worker_side_prioritization": false, "replay_mode": "independent"}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "input": "sampler", "multiagent": {"policies": {"attacker": "<ray.rllib.policy.policy.PolicySpec object at 0x00000295802FFE50>", "defender": "<ray.rllib.policy.policy.PolicySpec object at 0x00000295803B1790>"}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x0000029580261700>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "tf", "num_cpus_for_driver": 1}, "time_since_restore": 32.631221294403076, "timesteps_since_restore": 0, "iterations_since_restore": 16, "warmup_time": 9.31046748161316, "perf": {"cpu_util_percent": 4.866666666666667, "ram_util_percent": 50.73333333333334}}
{"custom_metrics": {}, "episode_media": {}, "num_recreated_workers": 0, "info": {"learner": {"attacker": {"learner_stats": {"cur_lr": 0.0005000000237487257, "mean_q": -16.176227569580078, "min_q": -20.911977767944336, "max_q": -8.908941268920898, "mean_td_error": 0.2641887664794922, "model": {}}, "td_error": [-0.247161865234375, -0.09490585327148438, -0.13218212127685547, -1.0398750305175781, -0.045459747314453125, 0.028757095336914062, 0.0509490966796875, 0.033577919006347656, 0.9400424957275391, 1.3573646545410156, -0.5438718795776367, -0.045459747314453125, 0.8055915832519531, 1.0829572677612305, 1.0429363250732422, 1.0337600708007812], "custom_metrics": {}, "num_agent_steps_trained": 16.0}, "defender": {"learner_stats": {"cur_lr": 0.0005000000237487257, "mean_q": 0.8854122161865234, "min_q": -0.30004748702049255, "max_q": 2.58853816986084, "mean_td_error": 0.2086622714996338, "model": {}}, "td_error": [0.22335176169872284, -0.5194059610366821, 0.13614952564239502, 0.27641043066978455, 0.07783842086791992, 0.10447520017623901, 0.19523712992668152, -0.12059074640274048, 0.8454431295394897, 0.21355605125427246, 0.022408723831176758, 0.5696239471435547, 0.024758577346801758, 0.37251198291778564, 0.2469756305217743, 0.6698525547981262], "custom_metrics": {}, "num_agent_steps_trained": 16.0}}, "num_env_steps_sampled": 17136, "num_env_steps_trained": 43040, "num_agent_steps_sampled": 17133, "num_agent_steps_trained": 43040, "last_target_update_ts": 17136, "num_target_updates": 33}, "sampler_results": {"episode_reward_max": -9.899999999999999, "episode_reward_min": -673.2666666666697, "episode_reward_mean": -207.7769230769233, "episode_len_mean": 391.05128205128204, "episode_media": {}, "episodes_this_iter": 0, "policy_reward_min": {"attacker": -670.1666666666697, "defender": -20.0}, "policy_reward_max": {"attacker": -10.299999999999997, "defender": 3.6000000000000005}, "policy_reward_mean": {"attacker": -201.3923076923079, "defender": -6.384615384615385}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-186.86666666666676, -201.73333333333355, -126.73333333333342, -190.63333333333333, -199.26666666666654, -154.26666666666696, -168.16666666666674, -152.5000000000002, -200.3333333333335, -164.50000000000006, -145.46666666666667, -119.16666666666663, -93.13333333333337, -141.8333333333334, -201.2666666666667, -204.33333333333317, -151.23333333333335, -175.76666666666677, -228.7333333333334, -199.20000000000005, -219.76666666666682, -226.19999999999976, -136.00000000000009, -317.6333333333334, -100.99999999999987, -9.899999999999999, -234.0, -186.36666666666693, -159.66666666666677, -178.23333333333355, -153.4, -293.73333333333323, -383.5000000000007, -346.26666666666785, -673.2666666666697, -234.000000000002, -200.10000000000014, -309.40000000000055, -335.7333333333329], "episode_lengths": [283, 303, 315, 300, 328, 333, 292, 369, 314, 288, 273, 237, 151, 286, 351, 395, 286, 310, 352, 378, 304, 354, 300, 441, 337, 69, 339, 364, 288, 298, 357, 536, 826, 841, 1347, 705, 209, 615, 577], "policy_attacker_reward": [-185.36666666666673, -184.63333333333352, -124.43333333333341, -180.03333333333336, -191.56666666666655, -143.86666666666696, -163.36666666666673, -146.2000000000002, -192.93333333333337, -160.60000000000002, -143.36666666666667, -120.76666666666664, -86.43333333333337, -137.03333333333333, -194.86666666666667, -191.83333333333312, -134.5333333333334, -168.06666666666678, -217.63333333333333, -195.7, -206.06666666666678, -215.8999999999997, -120.10000000000001, -315.3333333333334, -98.59999999999994, -10.299999999999997, -226.29999999999998, -188.46666666666678, -156.36666666666667, -177.5333333333335, -157.0, -274.43333333333317, -376.60000000000076, -340.66666666666777, -670.1666666666697, -233.200000000002, -201.2000000000001, -307.1000000000005, -315.73333333333284], "policy_defender_reward": [-1.4999999999999998, -17.1, -2.3, -10.600000000000001, -7.699999999999999, -10.400000000000002, -4.800000000000001, -6.299999999999999, -7.400000000000009, -3.8999999999999995, -2.0999999999999996, 1.6000000000000005, -6.7, -4.800000000000001, -6.4, -12.5, -16.700000000000003, -7.7, -11.100000000000003, -3.5, -13.7, -10.300000000000002, -15.899999999999995, -2.2999999999999994, -2.3999999999999986, 0.4, -7.699999999999999, 2.1, -3.3000000000000016, -0.7000000000000001, 3.6000000000000005, -19.299999999999997, -6.900000000000001, -5.6000000000000005, -3.099999999999999, -0.7999999999999989, 1.0999999999999999, -2.3, -20.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.28619107641145614, "mean_inference_ms": 0.5773866464334844, "mean_action_processing_ms": 0.05883076597210477, "mean_env_wait_ms": 0.4908928964253309, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0}, "episode_reward_max": -9.899999999999999, "episode_reward_min": -673.2666666666697, "episode_reward_mean": -207.7769230769233, "episode_len_mean": 391.05128205128204, "episodes_this_iter": 0, "policy_reward_min": {"attacker": -670.1666666666697, "defender": -20.0}, "policy_reward_max": {"attacker": -10.299999999999997, "defender": 3.6000000000000005}, "policy_reward_mean": {"attacker": -201.3923076923079, "defender": -6.384615384615385}, "hist_stats": {"episode_reward": [-186.86666666666676, -201.73333333333355, -126.73333333333342, -190.63333333333333, -199.26666666666654, -154.26666666666696, -168.16666666666674, -152.5000000000002, -200.3333333333335, -164.50000000000006, -145.46666666666667, -119.16666666666663, -93.13333333333337, -141.8333333333334, -201.2666666666667, -204.33333333333317, -151.23333333333335, -175.76666666666677, -228.7333333333334, -199.20000000000005, -219.76666666666682, -226.19999999999976, -136.00000000000009, -317.6333333333334, -100.99999999999987, -9.899999999999999, -234.0, -186.36666666666693, -159.66666666666677, -178.23333333333355, -153.4, -293.73333333333323, -383.5000000000007, -346.26666666666785, -673.2666666666697, -234.000000000002, -200.10000000000014, -309.40000000000055, -335.7333333333329], "episode_lengths": [283, 303, 315, 300, 328, 333, 292, 369, 314, 288, 273, 237, 151, 286, 351, 395, 286, 310, 352, 378, 304, 354, 300, 441, 337, 69, 339, 364, 288, 298, 357, 536, 826, 841, 1347, 705, 209, 615, 577], "policy_attacker_reward": [-185.36666666666673, -184.63333333333352, -124.43333333333341, -180.03333333333336, -191.56666666666655, -143.86666666666696, -163.36666666666673, -146.2000000000002, -192.93333333333337, -160.60000000000002, -143.36666666666667, -120.76666666666664, -86.43333333333337, -137.03333333333333, -194.86666666666667, -191.83333333333312, -134.5333333333334, -168.06666666666678, -217.63333333333333, -195.7, -206.06666666666678, -215.8999999999997, -120.10000000000001, -315.3333333333334, -98.59999999999994, -10.299999999999997, -226.29999999999998, -188.46666666666678, -156.36666666666667, -177.5333333333335, -157.0, -274.43333333333317, -376.60000000000076, -340.66666666666777, -670.1666666666697, -233.200000000002, -201.2000000000001, -307.1000000000005, -315.73333333333284], "policy_defender_reward": [-1.4999999999999998, -17.1, -2.3, -10.600000000000001, -7.699999999999999, -10.400000000000002, -4.800000000000001, -6.299999999999999, -7.400000000000009, -3.8999999999999995, -2.0999999999999996, 1.6000000000000005, -6.7, -4.800000000000001, -6.4, -12.5, -16.700000000000003, -7.7, -11.100000000000003, -3.5, -13.7, -10.300000000000002, -15.899999999999995, -2.2999999999999994, -2.3999999999999986, 0.4, -7.699999999999999, 2.1, -3.3000000000000016, -0.7000000000000001, 3.6000000000000005, -19.299999999999997, -6.900000000000001, -5.6000000000000005, -3.099999999999999, -0.7999999999999989, 1.0999999999999999, -2.3, -20.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.28619107641145614, "mean_inference_ms": 0.5773866464334844, "mean_action_processing_ms": 0.05883076597210477, "mean_env_wait_ms": 0.4908928964253309, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "num_healthy_workers": 3, "num_agent_steps_sampled": 17133, "num_agent_steps_trained": 43040, "num_env_steps_sampled": 17136, "num_env_steps_trained": 43040, "num_env_steps_sampled_this_iter": 1008, "num_env_steps_trained_this_iter": 2688, "timesteps_total": 17136, "num_steps_trained_this_iter": 2688, "agent_timesteps_total": 17133, "timers": {"training_iteration_time_ms": 24.374, "load_time_ms": 0.247, "load_throughput": 129779.277, "learn_time_ms": 3.179, "learn_throughput": 10065.298, "synch_weights_time_ms": 2.44}, "counters": {"num_env_steps_sampled": 17136, "num_env_steps_trained": 43040, "num_agent_steps_sampled": 17133, "num_agent_steps_trained": 43040, "last_target_update_ts": 17136, "num_target_updates": 33}, "done": false, "episodes_total": 39, "training_iteration": 17, "trial_id": "5f583_00000", "experiment_id": "d83cb2d89bc543feb18deca748a0082f", "date": "2022-09-11_15-48-21", "timestamp": 1662886101, "time_this_iter_s": 2.0682318210601807, "time_total_s": 34.69945311546326, "pid": 14740, "hostname": "XorgWorkstation", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "my_env", "env_config": {}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "num_workers": 3, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "ignore_worker_failures": false, "recreate_failed_workers": false, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 0.0005, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "my_env", "env_config": {}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "num_workers": 3, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "ignore_worker_failures": false, "recreate_failed_workers": false, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 0.0005, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": {"explore": false}, "off_policy_estimation_methods": {}, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": 1, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 1000, "logger_creator": null, "logger_config": null, "log_level": "INFO", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": -1, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": null, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "min_time_s_per_reporting": -1, "min_train_timesteps_per_reporting": -1, "min_sample_timesteps_per_reporting": -1, "input_evaluation": -1, "target_network_update_freq": 500, "replay_buffer_config": {"type": "<class 'ray.rllib.utils.replay_buffers.multi_agent_prioritized_replay_buffer.MultiAgentPrioritizedReplayBuffer'>", "prioritized_replay": -1, "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "worker_side_prioritization": false, "replay_mode": "independent"}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "input": "sampler", "multiagent": {"policies": {"attacker": "<ray.rllib.policy.policy.PolicySpec object at 0x00000295803824C0>", "defender": "<ray.rllib.policy.policy.PolicySpec object at 0x0000029580306460>"}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x00000295804088B0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "tf", "num_cpus_for_driver": 1}, "off_policy_estimation_methods": {}, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": 1, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 1000, "logger_creator": null, "logger_config": null, "log_level": "INFO", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": -1, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": null, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "min_time_s_per_reporting": -1, "min_train_timesteps_per_reporting": -1, "min_sample_timesteps_per_reporting": -1, "input_evaluation": -1, "target_network_update_freq": 500, "replay_buffer_config": {"type": "<class 'ray.rllib.utils.replay_buffers.multi_agent_prioritized_replay_buffer.MultiAgentPrioritizedReplayBuffer'>", "prioritized_replay": -1, "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "worker_side_prioritization": false, "replay_mode": "independent"}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "input": "sampler", "multiagent": {"policies": {"attacker": "<ray.rllib.policy.policy.PolicySpec object at 0x0000029580306730>", "defender": "<ray.rllib.policy.policy.PolicySpec object at 0x0000029580306FA0>"}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x00000295804088B0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "tf", "num_cpus_for_driver": 1}, "time_since_restore": 34.69945311546326, "timesteps_since_restore": 0, "iterations_since_restore": 17, "warmup_time": 9.31046748161316, "perf": {"cpu_util_percent": 5.133333333333334, "ram_util_percent": 50.73333333333333}}
{"custom_metrics": {}, "episode_media": {}, "num_recreated_workers": 0, "info": {"learner": {"attacker": {"learner_stats": {"cur_lr": 0.0005000000237487257, "mean_q": -17.28880500793457, "min_q": -22.195789337158203, "max_q": -8.983954429626465, "mean_td_error": -0.23383134603500366, "model": {}}, "td_error": [0.5832815170288086, -0.093658447265625, 0.14091014862060547, -0.093658447265625, -0.17466163635253906, -0.17466163635253906, -0.17466163635253906, 0.12264823913574219, 0.49584007263183594, 0.25351905822753906, -0.043578147888183594, -0.3988685607910156, -3.5258350372314453, 0.03483009338378906, -0.9714183807373047, 0.2786712646484375], "custom_metrics": {}, "num_agent_steps_trained": 16.0}, "defender": {"learner_stats": {"cur_lr": 0.0005000000237487257, "mean_q": 0.9602847695350647, "min_q": -0.17212066054344177, "max_q": 2.1100056171417236, "mean_td_error": 0.08096247166395187, "model": {}}, "td_error": [1.1049002408981323, -0.17577940225601196, -0.16113495826721191, 0.45124053955078125, -0.21690374612808228, 0.08627021312713623, 0.07055151462554932, -0.38806504011154175, -0.1807560920715332, 0.18248331546783447, 0.24341118335723877, 0.0699777603149414, 0.0022164583206176758, -0.038546204566955566, -0.5129448175430298, 0.758478581905365], "custom_metrics": {}, "num_agent_steps_trained": 16.0}}, "num_env_steps_sampled": 18144, "num_env_steps_trained": 45728, "num_agent_steps_sampled": 18141, "num_agent_steps_trained": 45728, "last_target_update_ts": 18144, "num_target_updates": 35}, "sampler_results": {"episode_reward_max": -9.899999999999999, "episode_reward_min": -673.2666666666697, "episode_reward_mean": -209.94500000000022, "episode_len_mean": 403.3, "episode_media": {}, "episodes_this_iter": 1, "policy_reward_min": {"attacker": -670.1666666666697, "defender": -20.0}, "policy_reward_max": {"attacker": -10.299999999999997, "defender": 3.6000000000000005}, "policy_reward_mean": {"attacker": -203.6800000000002, "defender": -6.265}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-186.86666666666676, -201.73333333333355, -126.73333333333342, -190.63333333333333, -199.26666666666654, -154.26666666666696, -168.16666666666674, -152.5000000000002, -200.3333333333335, -164.50000000000006, -145.46666666666667, -119.16666666666663, -93.13333333333337, -141.8333333333334, -201.2666666666667, -204.33333333333317, -151.23333333333335, -175.76666666666677, -228.7333333333334, -199.20000000000005, -219.76666666666682, -226.19999999999976, -136.00000000000009, -317.6333333333334, -100.99999999999987, -9.899999999999999, -234.0, -186.36666666666693, -159.66666666666677, -178.23333333333355, -153.4, -293.73333333333323, -383.5000000000007, -346.26666666666785, -673.2666666666697, -234.000000000002, -200.10000000000014, -309.40000000000055, -335.7333333333329, -294.4999999999996], "episode_lengths": [283, 303, 315, 300, 328, 333, 292, 369, 314, 288, 273, 237, 151, 286, 351, 395, 286, 310, 352, 378, 304, 354, 300, 441, 337, 69, 339, 364, 288, 298, 357, 536, 826, 841, 1347, 705, 209, 615, 577, 881], "policy_attacker_reward": [-185.36666666666673, -184.63333333333352, -124.43333333333341, -180.03333333333336, -191.56666666666655, -143.86666666666696, -163.36666666666673, -146.2000000000002, -192.93333333333337, -160.60000000000002, -143.36666666666667, -120.76666666666664, -86.43333333333337, -137.03333333333333, -194.86666666666667, -191.83333333333312, -134.5333333333334, -168.06666666666678, -217.63333333333333, -195.7, -206.06666666666678, -215.8999999999997, -120.10000000000001, -315.3333333333334, -98.59999999999994, -10.299999999999997, -226.29999999999998, -188.46666666666678, -156.36666666666667, -177.5333333333335, -157.0, -274.43333333333317, -376.60000000000076, -340.66666666666777, -670.1666666666697, -233.200000000002, -201.2000000000001, -307.1000000000005, -315.73333333333284, -292.8999999999996], "policy_defender_reward": [-1.4999999999999998, -17.1, -2.3, -10.600000000000001, -7.699999999999999, -10.400000000000002, -4.800000000000001, -6.299999999999999, -7.400000000000009, -3.8999999999999995, -2.0999999999999996, 1.6000000000000005, -6.7, -4.800000000000001, -6.4, -12.5, -16.700000000000003, -7.7, -11.100000000000003, -3.5, -13.7, -10.300000000000002, -15.899999999999995, -2.2999999999999994, -2.3999999999999986, 0.4, -7.699999999999999, 2.1, -3.3000000000000016, -0.7000000000000001, 3.6000000000000005, -19.299999999999997, -6.900000000000001, -5.6000000000000005, -3.099999999999999, -0.7999999999999989, 1.0999999999999999, -2.3, -20.0, -1.5999999999999996]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.28595075558219757, "mean_inference_ms": 0.576346947169084, "mean_action_processing_ms": 0.0587676941737467, "mean_env_wait_ms": 0.4906379769647506, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0}, "episode_reward_max": -9.899999999999999, "episode_reward_min": -673.2666666666697, "episode_reward_mean": -209.94500000000022, "episode_len_mean": 403.3, "episodes_this_iter": 1, "policy_reward_min": {"attacker": -670.1666666666697, "defender": -20.0}, "policy_reward_max": {"attacker": -10.299999999999997, "defender": 3.6000000000000005}, "policy_reward_mean": {"attacker": -203.6800000000002, "defender": -6.265}, "hist_stats": {"episode_reward": [-186.86666666666676, -201.73333333333355, -126.73333333333342, -190.63333333333333, -199.26666666666654, -154.26666666666696, -168.16666666666674, -152.5000000000002, -200.3333333333335, -164.50000000000006, -145.46666666666667, -119.16666666666663, -93.13333333333337, -141.8333333333334, -201.2666666666667, -204.33333333333317, -151.23333333333335, -175.76666666666677, -228.7333333333334, -199.20000000000005, -219.76666666666682, -226.19999999999976, -136.00000000000009, -317.6333333333334, -100.99999999999987, -9.899999999999999, -234.0, -186.36666666666693, -159.66666666666677, -178.23333333333355, -153.4, -293.73333333333323, -383.5000000000007, -346.26666666666785, -673.2666666666697, -234.000000000002, -200.10000000000014, -309.40000000000055, -335.7333333333329, -294.4999999999996], "episode_lengths": [283, 303, 315, 300, 328, 333, 292, 369, 314, 288, 273, 237, 151, 286, 351, 395, 286, 310, 352, 378, 304, 354, 300, 441, 337, 69, 339, 364, 288, 298, 357, 536, 826, 841, 1347, 705, 209, 615, 577, 881], "policy_attacker_reward": [-185.36666666666673, -184.63333333333352, -124.43333333333341, -180.03333333333336, -191.56666666666655, -143.86666666666696, -163.36666666666673, -146.2000000000002, -192.93333333333337, -160.60000000000002, -143.36666666666667, -120.76666666666664, -86.43333333333337, -137.03333333333333, -194.86666666666667, -191.83333333333312, -134.5333333333334, -168.06666666666678, -217.63333333333333, -195.7, -206.06666666666678, -215.8999999999997, -120.10000000000001, -315.3333333333334, -98.59999999999994, -10.299999999999997, -226.29999999999998, -188.46666666666678, -156.36666666666667, -177.5333333333335, -157.0, -274.43333333333317, -376.60000000000076, -340.66666666666777, -670.1666666666697, -233.200000000002, -201.2000000000001, -307.1000000000005, -315.73333333333284, -292.8999999999996], "policy_defender_reward": [-1.4999999999999998, -17.1, -2.3, -10.600000000000001, -7.699999999999999, -10.400000000000002, -4.800000000000001, -6.299999999999999, -7.400000000000009, -3.8999999999999995, -2.0999999999999996, 1.6000000000000005, -6.7, -4.800000000000001, -6.4, -12.5, -16.700000000000003, -7.7, -11.100000000000003, -3.5, -13.7, -10.300000000000002, -15.899999999999995, -2.2999999999999994, -2.3999999999999986, 0.4, -7.699999999999999, 2.1, -3.3000000000000016, -0.7000000000000001, 3.6000000000000005, -19.299999999999997, -6.900000000000001, -5.6000000000000005, -3.099999999999999, -0.7999999999999989, 1.0999999999999999, -2.3, -20.0, -1.5999999999999996]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.28595075558219757, "mean_inference_ms": 0.576346947169084, "mean_action_processing_ms": 0.0587676941737467, "mean_env_wait_ms": 0.4906379769647506, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "num_healthy_workers": 3, "num_agent_steps_sampled": 18141, "num_agent_steps_trained": 45728, "num_env_steps_sampled": 18144, "num_env_steps_trained": 45728, "num_env_steps_sampled_this_iter": 1008, "num_env_steps_trained_this_iter": 2688, "timesteps_total": 18144, "num_steps_trained_this_iter": 2688, "agent_timesteps_total": 18141, "timers": {"training_iteration_time_ms": 23.488, "load_time_ms": 0.1, "load_throughput": 319794.444, "learn_time_ms": 3.379, "learn_throughput": 9469.625, "synch_weights_time_ms": 2.142}, "counters": {"num_env_steps_sampled": 18144, "num_env_steps_trained": 45728, "num_agent_steps_sampled": 18141, "num_agent_steps_trained": 45728, "last_target_update_ts": 18144, "num_target_updates": 35}, "done": false, "episodes_total": 40, "training_iteration": 18, "trial_id": "5f583_00000", "experiment_id": "d83cb2d89bc543feb18deca748a0082f", "date": "2022-09-11_15-48-23", "timestamp": 1662886103, "time_this_iter_s": 2.063961982727051, "time_total_s": 36.76341509819031, "pid": 14740, "hostname": "XorgWorkstation", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "my_env", "env_config": {}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "num_workers": 3, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "ignore_worker_failures": false, "recreate_failed_workers": false, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 0.0005, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "my_env", "env_config": {}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "num_workers": 3, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "ignore_worker_failures": false, "recreate_failed_workers": false, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 0.0005, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": {"explore": false}, "off_policy_estimation_methods": {}, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": 1, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 1000, "logger_creator": null, "logger_config": null, "log_level": "INFO", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": -1, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": null, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "min_time_s_per_reporting": -1, "min_train_timesteps_per_reporting": -1, "min_sample_timesteps_per_reporting": -1, "input_evaluation": -1, "target_network_update_freq": 500, "replay_buffer_config": {"type": "<class 'ray.rllib.utils.replay_buffers.multi_agent_prioritized_replay_buffer.MultiAgentPrioritizedReplayBuffer'>", "prioritized_replay": -1, "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "worker_side_prioritization": false, "replay_mode": "independent"}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "input": "sampler", "multiagent": {"policies": {"attacker": "<ray.rllib.policy.policy.PolicySpec object at 0x000002958037C760>", "defender": "<ray.rllib.policy.policy.PolicySpec object at 0x00000295803B2A60>"}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x0000029580408940>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "tf", "num_cpus_for_driver": 1}, "off_policy_estimation_methods": {}, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": 1, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 1000, "logger_creator": null, "logger_config": null, "log_level": "INFO", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": -1, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": null, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "min_time_s_per_reporting": -1, "min_train_timesteps_per_reporting": -1, "min_sample_timesteps_per_reporting": -1, "input_evaluation": -1, "target_network_update_freq": 500, "replay_buffer_config": {"type": "<class 'ray.rllib.utils.replay_buffers.multi_agent_prioritized_replay_buffer.MultiAgentPrioritizedReplayBuffer'>", "prioritized_replay": -1, "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "worker_side_prioritization": false, "replay_mode": "independent"}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "input": "sampler", "multiagent": {"policies": {"attacker": "<ray.rllib.policy.policy.PolicySpec object at 0x00000295803B2A90>", "defender": "<ray.rllib.policy.policy.PolicySpec object at 0x00000295803066A0>"}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x0000029580408940>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "tf", "num_cpus_for_driver": 1}, "time_since_restore": 36.76341509819031, "timesteps_since_restore": 0, "iterations_since_restore": 18, "warmup_time": 9.31046748161316, "perf": {"cpu_util_percent": 4.7, "ram_util_percent": 50.833333333333336}}
{"custom_metrics": {}, "episode_media": {}, "num_recreated_workers": 0, "info": {"learner": {"attacker": {"learner_stats": {"cur_lr": 0.0005000000237487257, "mean_q": -16.688220977783203, "min_q": -26.792219161987305, "max_q": -7.990938663482666, "mean_td_error": -0.3588918447494507, "model": {}}, "td_error": [0.5130233764648438, 0.2609291076660156, -0.4065284729003906, -2.1538257598876953, -0.3607902526855469, -0.7007274627685547, -0.6163539886474609, -0.6163539886474609, -0.26293182373046875, -0.37583351135253906, -0.7783470153808594, 0.9454498291015625, -0.18090534210205078, -0.39842987060546875, -0.26598167419433594, -0.3446626663208008], "custom_metrics": {}, "num_agent_steps_trained": 16.0}, "defender": {"learner_stats": {"cur_lr": 0.0005000000237487257, "mean_q": 1.0923210382461548, "min_q": -0.09607911109924316, "max_q": 2.5568861961364746, "mean_td_error": -0.0656822919845581, "model": {}}, "td_error": [-0.06479483842849731, 0.014014720916748047, -0.10946309566497803, 0.19306281208992004, -0.1099170446395874, -0.1868886947631836, 0.028749197721481323, -0.29795312881469727, -0.07153955101966858, -0.06665679067373276, -0.07089042663574219, 0.6771425008773804, -0.11536943912506104, 0.11716198921203613, -0.45579028129577637, -0.5317845940589905], "custom_metrics": {}, "num_agent_steps_trained": 16.0}}, "num_env_steps_sampled": 19152, "num_env_steps_trained": 48416, "num_agent_steps_sampled": 19149, "num_agent_steps_trained": 48416, "last_target_update_ts": 19152, "num_target_updates": 37}, "sampler_results": {"episode_reward_max": -9.899999999999999, "episode_reward_min": -673.2666666666697, "episode_reward_mean": -223.36111111111126, "episode_len_mean": 434.0, "episode_media": {}, "episodes_this_iter": 2, "policy_reward_min": {"attacker": -670.1666666666697, "defender": -21.2}, "policy_reward_max": {"attacker": -10.299999999999997, "defender": 3.6000000000000005}, "policy_reward_mean": {"attacker": -216.4492063492065, "defender": -6.911904761904762}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-186.86666666666676, -201.73333333333355, -126.73333333333342, -190.63333333333333, -199.26666666666654, -154.26666666666696, -168.16666666666674, -152.5000000000002, -200.3333333333335, -164.50000000000006, -145.46666666666667, -119.16666666666663, -93.13333333333337, -141.8333333333334, -201.2666666666667, -204.33333333333317, -151.23333333333335, -175.76666666666677, -228.7333333333334, -199.20000000000005, -219.76666666666682, -226.19999999999976, -136.00000000000009, -317.6333333333334, -100.99999999999987, -9.899999999999999, -234.0, -186.36666666666693, -159.66666666666677, -178.23333333333355, -153.4, -293.73333333333323, -383.5000000000007, -346.26666666666785, -673.2666666666697, -234.000000000002, -200.10000000000014, -309.40000000000055, -335.7333333333329, -294.4999999999996, -509.4000000000008, -473.96666666666306], "episode_lengths": [283, 303, 315, 300, 328, 333, 292, 369, 314, 288, 273, 237, 151, 286, 351, 395, 286, 310, 352, 378, 304, 354, 300, 441, 337, 69, 339, 364, 288, 298, 357, 536, 826, 841, 1347, 705, 209, 615, 577, 881, 1059, 1037], "policy_attacker_reward": [-185.36666666666673, -184.63333333333352, -124.43333333333341, -180.03333333333336, -191.56666666666655, -143.86666666666696, -163.36666666666673, -146.2000000000002, -192.93333333333337, -160.60000000000002, -143.36666666666667, -120.76666666666664, -86.43333333333337, -137.03333333333333, -194.86666666666667, -191.83333333333312, -134.5333333333334, -168.06666666666678, -217.63333333333333, -195.7, -206.06666666666678, -215.8999999999997, -120.10000000000001, -315.3333333333334, -98.59999999999994, -10.299999999999997, -226.29999999999998, -188.46666666666678, -156.36666666666667, -177.5333333333335, -157.0, -274.43333333333317, -376.60000000000076, -340.66666666666777, -670.1666666666697, -233.200000000002, -201.2000000000001, -307.1000000000005, -315.73333333333284, -292.8999999999996, -488.20000000000084, -455.4666666666627], "policy_defender_reward": [-1.4999999999999998, -17.1, -2.3, -10.600000000000001, -7.699999999999999, -10.400000000000002, -4.800000000000001, -6.299999999999999, -7.400000000000009, -3.8999999999999995, -2.0999999999999996, 1.6000000000000005, -6.7, -4.800000000000001, -6.4, -12.5, -16.700000000000003, -7.7, -11.100000000000003, -3.5, -13.7, -10.300000000000002, -15.899999999999995, -2.2999999999999994, -2.3999999999999986, 0.4, -7.699999999999999, 2.1, -3.3000000000000016, -0.7000000000000001, 3.6000000000000005, -19.299999999999997, -6.900000000000001, -5.6000000000000005, -3.099999999999999, -0.7999999999999989, 1.0999999999999999, -2.3, -20.0, -1.5999999999999996, -21.2, -18.5]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.28537099634826424, "mean_inference_ms": 0.5738547045282274, "mean_action_processing_ms": 0.05864174416544393, "mean_env_wait_ms": 0.49016675396476267, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0}, "episode_reward_max": -9.899999999999999, "episode_reward_min": -673.2666666666697, "episode_reward_mean": -223.36111111111126, "episode_len_mean": 434.0, "episodes_this_iter": 2, "policy_reward_min": {"attacker": -670.1666666666697, "defender": -21.2}, "policy_reward_max": {"attacker": -10.299999999999997, "defender": 3.6000000000000005}, "policy_reward_mean": {"attacker": -216.4492063492065, "defender": -6.911904761904762}, "hist_stats": {"episode_reward": [-186.86666666666676, -201.73333333333355, -126.73333333333342, -190.63333333333333, -199.26666666666654, -154.26666666666696, -168.16666666666674, -152.5000000000002, -200.3333333333335, -164.50000000000006, -145.46666666666667, -119.16666666666663, -93.13333333333337, -141.8333333333334, -201.2666666666667, -204.33333333333317, -151.23333333333335, -175.76666666666677, -228.7333333333334, -199.20000000000005, -219.76666666666682, -226.19999999999976, -136.00000000000009, -317.6333333333334, -100.99999999999987, -9.899999999999999, -234.0, -186.36666666666693, -159.66666666666677, -178.23333333333355, -153.4, -293.73333333333323, -383.5000000000007, -346.26666666666785, -673.2666666666697, -234.000000000002, -200.10000000000014, -309.40000000000055, -335.7333333333329, -294.4999999999996, -509.4000000000008, -473.96666666666306], "episode_lengths": [283, 303, 315, 300, 328, 333, 292, 369, 314, 288, 273, 237, 151, 286, 351, 395, 286, 310, 352, 378, 304, 354, 300, 441, 337, 69, 339, 364, 288, 298, 357, 536, 826, 841, 1347, 705, 209, 615, 577, 881, 1059, 1037], "policy_attacker_reward": [-185.36666666666673, -184.63333333333352, -124.43333333333341, -180.03333333333336, -191.56666666666655, -143.86666666666696, -163.36666666666673, -146.2000000000002, -192.93333333333337, -160.60000000000002, -143.36666666666667, -120.76666666666664, -86.43333333333337, -137.03333333333333, -194.86666666666667, -191.83333333333312, -134.5333333333334, -168.06666666666678, -217.63333333333333, -195.7, -206.06666666666678, -215.8999999999997, -120.10000000000001, -315.3333333333334, -98.59999999999994, -10.299999999999997, -226.29999999999998, -188.46666666666678, -156.36666666666667, -177.5333333333335, -157.0, -274.43333333333317, -376.60000000000076, -340.66666666666777, -670.1666666666697, -233.200000000002, -201.2000000000001, -307.1000000000005, -315.73333333333284, -292.8999999999996, -488.20000000000084, -455.4666666666627], "policy_defender_reward": [-1.4999999999999998, -17.1, -2.3, -10.600000000000001, -7.699999999999999, -10.400000000000002, -4.800000000000001, -6.299999999999999, -7.400000000000009, -3.8999999999999995, -2.0999999999999996, 1.6000000000000005, -6.7, -4.800000000000001, -6.4, -12.5, -16.700000000000003, -7.7, -11.100000000000003, -3.5, -13.7, -10.300000000000002, -15.899999999999995, -2.2999999999999994, -2.3999999999999986, 0.4, -7.699999999999999, 2.1, -3.3000000000000016, -0.7000000000000001, 3.6000000000000005, -19.299999999999997, -6.900000000000001, -5.6000000000000005, -3.099999999999999, -0.7999999999999989, 1.0999999999999999, -2.3, -20.0, -1.5999999999999996, -21.2, -18.5]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.28537099634826424, "mean_inference_ms": 0.5738547045282274, "mean_action_processing_ms": 0.05864174416544393, "mean_env_wait_ms": 0.49016675396476267, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "num_healthy_workers": 3, "num_agent_steps_sampled": 19149, "num_agent_steps_trained": 48416, "num_env_steps_sampled": 19152, "num_env_steps_trained": 48416, "num_env_steps_sampled_this_iter": 1008, "num_env_steps_trained_this_iter": 2688, "timesteps_total": 19152, "num_steps_trained_this_iter": 2688, "agent_timesteps_total": 19149, "timers": {"training_iteration_time_ms": 24.505, "load_time_ms": 0.2, "load_throughput": 160202.588, "learn_time_ms": 3.408, "learn_throughput": 9388.613, "synch_weights_time_ms": 2.271}, "counters": {"num_env_steps_sampled": 19152, "num_env_steps_trained": 48416, "num_agent_steps_sampled": 19149, "num_agent_steps_trained": 48416, "last_target_update_ts": 19152, "num_target_updates": 37}, "done": false, "episodes_total": 42, "training_iteration": 19, "trial_id": "5f583_00000", "experiment_id": "d83cb2d89bc543feb18deca748a0082f", "date": "2022-09-11_15-48-25", "timestamp": 1662886105, "time_this_iter_s": 2.0775909423828125, "time_total_s": 38.84100604057312, "pid": 14740, "hostname": "XorgWorkstation", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "my_env", "env_config": {}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "num_workers": 3, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "ignore_worker_failures": false, "recreate_failed_workers": false, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 0.0005, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "my_env", "env_config": {}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "num_workers": 3, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "ignore_worker_failures": false, "recreate_failed_workers": false, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 0.0005, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": {"explore": false}, "off_policy_estimation_methods": {}, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": 1, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 1000, "logger_creator": null, "logger_config": null, "log_level": "INFO", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": -1, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": null, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "min_time_s_per_reporting": -1, "min_train_timesteps_per_reporting": -1, "min_sample_timesteps_per_reporting": -1, "input_evaluation": -1, "target_network_update_freq": 500, "replay_buffer_config": {"type": "<class 'ray.rllib.utils.replay_buffers.multi_agent_prioritized_replay_buffer.MultiAgentPrioritizedReplayBuffer'>", "prioritized_replay": -1, "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "worker_side_prioritization": false, "replay_mode": "independent"}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "input": "sampler", "multiagent": {"policies": {"attacker": "<ray.rllib.policy.policy.PolicySpec object at 0x00000295802FEFD0>", "defender": "<ray.rllib.policy.policy.PolicySpec object at 0x0000029580382640>"}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x0000029580261700>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "tf", "num_cpus_for_driver": 1}, "off_policy_estimation_methods": {}, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": 1, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 1000, "logger_creator": null, "logger_config": null, "log_level": "INFO", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": -1, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": null, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "min_time_s_per_reporting": -1, "min_train_timesteps_per_reporting": -1, "min_sample_timesteps_per_reporting": -1, "input_evaluation": -1, "target_network_update_freq": 500, "replay_buffer_config": {"type": "<class 'ray.rllib.utils.replay_buffers.multi_agent_prioritized_replay_buffer.MultiAgentPrioritizedReplayBuffer'>", "prioritized_replay": -1, "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "worker_side_prioritization": false, "replay_mode": "independent"}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "input": "sampler", "multiagent": {"policies": {"attacker": "<ray.rllib.policy.policy.PolicySpec object at 0x0000029580382370>", "defender": "<ray.rllib.policy.policy.PolicySpec object at 0x00000295803B16A0>"}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x0000029580261700>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "tf", "num_cpus_for_driver": 1}, "time_since_restore": 38.84100604057312, "timesteps_since_restore": 0, "iterations_since_restore": 19, "warmup_time": 9.31046748161316, "perf": {"cpu_util_percent": 4.966666666666666, "ram_util_percent": 50.76666666666667}}
{"custom_metrics": {}, "episode_media": {}, "num_recreated_workers": 0, "info": {"learner": {"attacker": {"learner_stats": {"cur_lr": 0.0005000000237487257, "mean_q": -17.111927032470703, "min_q": -22.262598037719727, "max_q": -10.769275665283203, "mean_td_error": -0.4801795482635498, "model": {}}, "td_error": [-0.030986785888671875, 2.0368528366088867, -0.3696460723876953, 0.048198699951171875, -0.3632183074951172, -0.12259292602539062, 0.013286590576171875, 0.1786327362060547, -0.11500930786132812, -5.083369255065918, -0.11500930786132812, -0.030986785888671875, 0.36403465270996094, -0.3089790344238281, -3.0241308212280273, -0.7599496841430664], "custom_metrics": {}, "num_agent_steps_trained": 16.0}, "defender": {"learner_stats": {"cur_lr": 0.0005000000237487257, "mean_q": 1.2332649230957031, "min_q": -0.35233789682388306, "max_q": 3.03802752494812, "mean_td_error": -0.15193799138069153, "model": {}}, "td_error": [-0.5715733766555786, -0.3254917860031128, 0.18674087524414062, -0.10016846656799316, -0.0044525861740112305, -0.08494257926940918, -0.07750248908996582, -0.07750248908996582, -0.5853540897369385, -0.01753997802734375, -0.2579801678657532, -0.32079172134399414, 0.40672528743743896, -0.48255252838134766, -0.15227094292640686, 0.03364920616149902], "custom_metrics": {}, "num_agent_steps_trained": 16.0}}, "num_env_steps_sampled": 20160, "num_env_steps_trained": 51104, "num_agent_steps_sampled": 20157, "num_agent_steps_trained": 51104, "last_target_update_ts": 20160, "num_target_updates": 39}, "sampler_results": {"episode_reward_max": -9.899999999999999, "episode_reward_min": -673.2666666666697, "episode_reward_mean": -221.68914728682182, "episode_len_mean": 434.0, "episode_media": {}, "episodes_this_iter": 1, "policy_reward_min": {"attacker": -670.1666666666697, "defender": -21.2}, "policy_reward_max": {"attacker": -10.299999999999997, "defender": 3.6000000000000005}, "policy_reward_mean": {"attacker": -214.92403100775206, "defender": -6.765116279069768}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-186.86666666666676, -201.73333333333355, -126.73333333333342, -190.63333333333333, -199.26666666666654, -154.26666666666696, -168.16666666666674, -152.5000000000002, -200.3333333333335, -164.50000000000006, -145.46666666666667, -119.16666666666663, -93.13333333333337, -141.8333333333334, -201.2666666666667, -204.33333333333317, -151.23333333333335, -175.76666666666677, -228.7333333333334, -199.20000000000005, -219.76666666666682, -226.19999999999976, -136.00000000000009, -317.6333333333334, -100.99999999999987, -9.899999999999999, -234.0, -186.36666666666693, -159.66666666666677, -178.23333333333355, -153.4, -293.73333333333323, -383.5000000000007, -346.26666666666785, -673.2666666666697, -234.000000000002, -200.10000000000014, -309.40000000000055, -335.7333333333329, -294.4999999999996, -509.4000000000008, -473.96666666666306, -151.4666666666661], "episode_lengths": [283, 303, 315, 300, 328, 333, 292, 369, 314, 288, 273, 237, 151, 286, 351, 395, 286, 310, 352, 378, 304, 354, 300, 441, 337, 69, 339, 364, 288, 298, 357, 536, 826, 841, 1347, 705, 209, 615, 577, 881, 1059, 1037, 434], "policy_attacker_reward": [-185.36666666666673, -184.63333333333352, -124.43333333333341, -180.03333333333336, -191.56666666666655, -143.86666666666696, -163.36666666666673, -146.2000000000002, -192.93333333333337, -160.60000000000002, -143.36666666666667, -120.76666666666664, -86.43333333333337, -137.03333333333333, -194.86666666666667, -191.83333333333312, -134.5333333333334, -168.06666666666678, -217.63333333333333, -195.7, -206.06666666666678, -215.8999999999997, -120.10000000000001, -315.3333333333334, -98.59999999999994, -10.299999999999997, -226.29999999999998, -188.46666666666678, -156.36666666666667, -177.5333333333335, -157.0, -274.43333333333317, -376.60000000000076, -340.66666666666777, -670.1666666666697, -233.200000000002, -201.2000000000001, -307.1000000000005, -315.73333333333284, -292.8999999999996, -488.20000000000084, -455.4666666666627, -150.86666666666608], "policy_defender_reward": [-1.4999999999999998, -17.1, -2.3, -10.600000000000001, -7.699999999999999, -10.400000000000002, -4.800000000000001, -6.299999999999999, -7.400000000000009, -3.8999999999999995, -2.0999999999999996, 1.6000000000000005, -6.7, -4.800000000000001, -6.4, -12.5, -16.700000000000003, -7.7, -11.100000000000003, -3.5, -13.7, -10.300000000000002, -15.899999999999995, -2.2999999999999994, -2.3999999999999986, 0.4, -7.699999999999999, 2.1, -3.3000000000000016, -0.7000000000000001, 3.6000000000000005, -19.299999999999997, -6.900000000000001, -5.6000000000000005, -3.099999999999999, -0.7999999999999989, 1.0999999999999999, -2.3, -20.0, -1.5999999999999996, -21.2, -18.5, -0.6]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.285115426037267, "mean_inference_ms": 0.5724980380313596, "mean_action_processing_ms": 0.058566041763031644, "mean_env_wait_ms": 0.4900582538476213, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0}, "episode_reward_max": -9.899999999999999, "episode_reward_min": -673.2666666666697, "episode_reward_mean": -221.68914728682182, "episode_len_mean": 434.0, "episodes_this_iter": 1, "policy_reward_min": {"attacker": -670.1666666666697, "defender": -21.2}, "policy_reward_max": {"attacker": -10.299999999999997, "defender": 3.6000000000000005}, "policy_reward_mean": {"attacker": -214.92403100775206, "defender": -6.765116279069768}, "hist_stats": {"episode_reward": [-186.86666666666676, -201.73333333333355, -126.73333333333342, -190.63333333333333, -199.26666666666654, -154.26666666666696, -168.16666666666674, -152.5000000000002, -200.3333333333335, -164.50000000000006, -145.46666666666667, -119.16666666666663, -93.13333333333337, -141.8333333333334, -201.2666666666667, -204.33333333333317, -151.23333333333335, -175.76666666666677, -228.7333333333334, -199.20000000000005, -219.76666666666682, -226.19999999999976, -136.00000000000009, -317.6333333333334, -100.99999999999987, -9.899999999999999, -234.0, -186.36666666666693, -159.66666666666677, -178.23333333333355, -153.4, -293.73333333333323, -383.5000000000007, -346.26666666666785, -673.2666666666697, -234.000000000002, -200.10000000000014, -309.40000000000055, -335.7333333333329, -294.4999999999996, -509.4000000000008, -473.96666666666306, -151.4666666666661], "episode_lengths": [283, 303, 315, 300, 328, 333, 292, 369, 314, 288, 273, 237, 151, 286, 351, 395, 286, 310, 352, 378, 304, 354, 300, 441, 337, 69, 339, 364, 288, 298, 357, 536, 826, 841, 1347, 705, 209, 615, 577, 881, 1059, 1037, 434], "policy_attacker_reward": [-185.36666666666673, -184.63333333333352, -124.43333333333341, -180.03333333333336, -191.56666666666655, -143.86666666666696, -163.36666666666673, -146.2000000000002, -192.93333333333337, -160.60000000000002, -143.36666666666667, -120.76666666666664, -86.43333333333337, -137.03333333333333, -194.86666666666667, -191.83333333333312, -134.5333333333334, -168.06666666666678, -217.63333333333333, -195.7, -206.06666666666678, -215.8999999999997, -120.10000000000001, -315.3333333333334, -98.59999999999994, -10.299999999999997, -226.29999999999998, -188.46666666666678, -156.36666666666667, -177.5333333333335, -157.0, -274.43333333333317, -376.60000000000076, -340.66666666666777, -670.1666666666697, -233.200000000002, -201.2000000000001, -307.1000000000005, -315.73333333333284, -292.8999999999996, -488.20000000000084, -455.4666666666627, -150.86666666666608], "policy_defender_reward": [-1.4999999999999998, -17.1, -2.3, -10.600000000000001, -7.699999999999999, -10.400000000000002, -4.800000000000001, -6.299999999999999, -7.400000000000009, -3.8999999999999995, -2.0999999999999996, 1.6000000000000005, -6.7, -4.800000000000001, -6.4, -12.5, -16.700000000000003, -7.7, -11.100000000000003, -3.5, -13.7, -10.300000000000002, -15.899999999999995, -2.2999999999999994, -2.3999999999999986, 0.4, -7.699999999999999, 2.1, -3.3000000000000016, -0.7000000000000001, 3.6000000000000005, -19.299999999999997, -6.900000000000001, -5.6000000000000005, -3.099999999999999, -0.7999999999999989, 1.0999999999999999, -2.3, -20.0, -1.5999999999999996, -21.2, -18.5, -0.6]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.285115426037267, "mean_inference_ms": 0.5724980380313596, "mean_action_processing_ms": 0.058566041763031644, "mean_env_wait_ms": 0.4900582538476213, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "num_healthy_workers": 3, "num_agent_steps_sampled": 20157, "num_agent_steps_trained": 51104, "num_env_steps_sampled": 20160, "num_env_steps_trained": 51104, "num_env_steps_sampled_this_iter": 1008, "num_env_steps_trained_this_iter": 2688, "timesteps_total": 20160, "num_steps_trained_this_iter": 2688, "agent_timesteps_total": 20157, "timers": {"training_iteration_time_ms": 23.717, "load_time_ms": 0.1, "load_throughput": 319186.036, "learn_time_ms": 3.254, "learn_throughput": 9832.801, "synch_weights_time_ms": 2.157}, "counters": {"num_env_steps_sampled": 20160, "num_env_steps_trained": 51104, "num_agent_steps_sampled": 20157, "num_agent_steps_trained": 51104, "last_target_update_ts": 20160, "num_target_updates": 39}, "done": false, "episodes_total": 43, "training_iteration": 20, "trial_id": "5f583_00000", "experiment_id": "d83cb2d89bc543feb18deca748a0082f", "date": "2022-09-11_15-48-27", "timestamp": 1662886107, "time_this_iter_s": 2.0308175086975098, "time_total_s": 40.87182354927063, "pid": 14740, "hostname": "XorgWorkstation", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "my_env", "env_config": {}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "num_workers": 3, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "ignore_worker_failures": false, "recreate_failed_workers": false, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 0.0005, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "my_env", "env_config": {}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "num_workers": 3, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "ignore_worker_failures": false, "recreate_failed_workers": false, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 0.0005, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": {"explore": false}, "off_policy_estimation_methods": {}, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": 1, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 1000, "logger_creator": null, "logger_config": null, "log_level": "INFO", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": -1, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": null, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "min_time_s_per_reporting": -1, "min_train_timesteps_per_reporting": -1, "min_sample_timesteps_per_reporting": -1, "input_evaluation": -1, "target_network_update_freq": 500, "replay_buffer_config": {"type": "<class 'ray.rllib.utils.replay_buffers.multi_agent_prioritized_replay_buffer.MultiAgentPrioritizedReplayBuffer'>", "prioritized_replay": -1, "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "worker_side_prioritization": false, "replay_mode": "independent"}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "input": "sampler", "multiagent": {"policies": {"attacker": "<ray.rllib.policy.policy.PolicySpec object at 0x000002958037DE80>", "defender": "<ray.rllib.policy.policy.PolicySpec object at 0x00000295803B2D30>"}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x00000295804088B0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "tf", "num_cpus_for_driver": 1}, "off_policy_estimation_methods": {}, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": 1, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 1000, "logger_creator": null, "logger_config": null, "log_level": "INFO", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": -1, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": null, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "min_time_s_per_reporting": -1, "min_train_timesteps_per_reporting": -1, "min_sample_timesteps_per_reporting": -1, "input_evaluation": -1, "target_network_update_freq": 500, "replay_buffer_config": {"type": "<class 'ray.rllib.utils.replay_buffers.multi_agent_prioritized_replay_buffer.MultiAgentPrioritizedReplayBuffer'>", "prioritized_replay": -1, "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "worker_side_prioritization": false, "replay_mode": "independent"}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "input": "sampler", "multiagent": {"policies": {"attacker": "<ray.rllib.policy.policy.PolicySpec object at 0x00000295803B2520>", "defender": "<ray.rllib.policy.policy.PolicySpec object at 0x00000295803B25E0>"}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x00000295804088B0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "tf", "num_cpus_for_driver": 1}, "time_since_restore": 40.87182354927063, "timesteps_since_restore": 0, "iterations_since_restore": 20, "warmup_time": 9.31046748161316, "perf": {"cpu_util_percent": 4.633333333333334, "ram_util_percent": 50.86666666666667}}
{"custom_metrics": {}, "episode_media": {}, "num_recreated_workers": 0, "info": {"learner": {"attacker": {"learner_stats": {"cur_lr": 0.0005000000237487257, "mean_q": -17.28588104248047, "min_q": -25.0378475189209, "max_q": -7.884411334991455, "mean_td_error": 0.3128869831562042, "model": {}}, "td_error": [0.004221916198730469, 0.8625345230102539, 0.6357831954956055, 0.0018091201782226562, 1.0118560791015625, 0.8184084892272949, 0.52081298828125, -0.16512107849121094, 0.5158271789550781, 0.1281290054321289, 0.10169410705566406, 1.1147270202636719, -0.1622781753540039, 0.11471748352050781, 0.0018091201782226562, -0.49873924255371094], "custom_metrics": {}, "num_agent_steps_trained": 16.0}, "defender": {"learner_stats": {"cur_lr": 0.0005000000237487257, "mean_q": 1.773086667060852, "min_q": 0.10054295510053635, "max_q": 7.377348899841309, "mean_td_error": 0.015965022146701813, "model": {}}, "td_error": [-0.06515622138977051, 0.05599510669708252, -0.0316852331161499, 0.05599510669708252, -0.5658354759216309, -0.29079365730285645, -0.09157321602106094, 0.21494388580322266, -0.06515622138977051, 1.3971048593521118, -0.48259735107421875, -0.1481044888496399, -0.10154640674591064, 0.1507178544998169, 0.1671367883682251, 0.05599510669708252], "custom_metrics": {}, "num_agent_steps_trained": 16.0}}, "num_env_steps_sampled": 21168, "num_env_steps_trained": 53792, "num_agent_steps_sampled": 21165, "num_agent_steps_trained": 53792, "last_target_update_ts": 21168, "num_target_updates": 41}, "sampler_results": {"episode_reward_max": -9.899999999999999, "episode_reward_min": -673.2666666666697, "episode_reward_mean": -221.68914728682182, "episode_len_mean": 434.0, "episode_media": {}, "episodes_this_iter": 0, "policy_reward_min": {"attacker": -670.1666666666697, "defender": -21.2}, "policy_reward_max": {"attacker": -10.299999999999997, "defender": 3.6000000000000005}, "policy_reward_mean": {"attacker": -214.92403100775206, "defender": -6.765116279069768}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-186.86666666666676, -201.73333333333355, -126.73333333333342, -190.63333333333333, -199.26666666666654, -154.26666666666696, -168.16666666666674, -152.5000000000002, -200.3333333333335, -164.50000000000006, -145.46666666666667, -119.16666666666663, -93.13333333333337, -141.8333333333334, -201.2666666666667, -204.33333333333317, -151.23333333333335, -175.76666666666677, -228.7333333333334, -199.20000000000005, -219.76666666666682, -226.19999999999976, -136.00000000000009, -317.6333333333334, -100.99999999999987, -9.899999999999999, -234.0, -186.36666666666693, -159.66666666666677, -178.23333333333355, -153.4, -293.73333333333323, -383.5000000000007, -346.26666666666785, -673.2666666666697, -234.000000000002, -200.10000000000014, -309.40000000000055, -335.7333333333329, -294.4999999999996, -509.4000000000008, -473.96666666666306, -151.4666666666661], "episode_lengths": [283, 303, 315, 300, 328, 333, 292, 369, 314, 288, 273, 237, 151, 286, 351, 395, 286, 310, 352, 378, 304, 354, 300, 441, 337, 69, 339, 364, 288, 298, 357, 536, 826, 841, 1347, 705, 209, 615, 577, 881, 1059, 1037, 434], "policy_attacker_reward": [-185.36666666666673, -184.63333333333352, -124.43333333333341, -180.03333333333336, -191.56666666666655, -143.86666666666696, -163.36666666666673, -146.2000000000002, -192.93333333333337, -160.60000000000002, -143.36666666666667, -120.76666666666664, -86.43333333333337, -137.03333333333333, -194.86666666666667, -191.83333333333312, -134.5333333333334, -168.06666666666678, -217.63333333333333, -195.7, -206.06666666666678, -215.8999999999997, -120.10000000000001, -315.3333333333334, -98.59999999999994, -10.299999999999997, -226.29999999999998, -188.46666666666678, -156.36666666666667, -177.5333333333335, -157.0, -274.43333333333317, -376.60000000000076, -340.66666666666777, -670.1666666666697, -233.200000000002, -201.2000000000001, -307.1000000000005, -315.73333333333284, -292.8999999999996, -488.20000000000084, -455.4666666666627, -150.86666666666608], "policy_defender_reward": [-1.4999999999999998, -17.1, -2.3, -10.600000000000001, -7.699999999999999, -10.400000000000002, -4.800000000000001, -6.299999999999999, -7.400000000000009, -3.8999999999999995, -2.0999999999999996, 1.6000000000000005, -6.7, -4.800000000000001, -6.4, -12.5, -16.700000000000003, -7.7, -11.100000000000003, -3.5, -13.7, -10.300000000000002, -15.899999999999995, -2.2999999999999994, -2.3999999999999986, 0.4, -7.699999999999999, 2.1, -3.3000000000000016, -0.7000000000000001, 3.6000000000000005, -19.299999999999997, -6.900000000000001, -5.6000000000000005, -3.099999999999999, -0.7999999999999989, 1.0999999999999999, -2.3, -20.0, -1.5999999999999996, -21.2, -18.5, -0.6]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.285115426037267, "mean_inference_ms": 0.5724980380313596, "mean_action_processing_ms": 0.058566041763031644, "mean_env_wait_ms": 0.4900582538476213, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0}, "episode_reward_max": -9.899999999999999, "episode_reward_min": -673.2666666666697, "episode_reward_mean": -221.68914728682182, "episode_len_mean": 434.0, "episodes_this_iter": 0, "policy_reward_min": {"attacker": -670.1666666666697, "defender": -21.2}, "policy_reward_max": {"attacker": -10.299999999999997, "defender": 3.6000000000000005}, "policy_reward_mean": {"attacker": -214.92403100775206, "defender": -6.765116279069768}, "hist_stats": {"episode_reward": [-186.86666666666676, -201.73333333333355, -126.73333333333342, -190.63333333333333, -199.26666666666654, -154.26666666666696, -168.16666666666674, -152.5000000000002, -200.3333333333335, -164.50000000000006, -145.46666666666667, -119.16666666666663, -93.13333333333337, -141.8333333333334, -201.2666666666667, -204.33333333333317, -151.23333333333335, -175.76666666666677, -228.7333333333334, -199.20000000000005, -219.76666666666682, -226.19999999999976, -136.00000000000009, -317.6333333333334, -100.99999999999987, -9.899999999999999, -234.0, -186.36666666666693, -159.66666666666677, -178.23333333333355, -153.4, -293.73333333333323, -383.5000000000007, -346.26666666666785, -673.2666666666697, -234.000000000002, -200.10000000000014, -309.40000000000055, -335.7333333333329, -294.4999999999996, -509.4000000000008, -473.96666666666306, -151.4666666666661], "episode_lengths": [283, 303, 315, 300, 328, 333, 292, 369, 314, 288, 273, 237, 151, 286, 351, 395, 286, 310, 352, 378, 304, 354, 300, 441, 337, 69, 339, 364, 288, 298, 357, 536, 826, 841, 1347, 705, 209, 615, 577, 881, 1059, 1037, 434], "policy_attacker_reward": [-185.36666666666673, -184.63333333333352, -124.43333333333341, -180.03333333333336, -191.56666666666655, -143.86666666666696, -163.36666666666673, -146.2000000000002, -192.93333333333337, -160.60000000000002, -143.36666666666667, -120.76666666666664, -86.43333333333337, -137.03333333333333, -194.86666666666667, -191.83333333333312, -134.5333333333334, -168.06666666666678, -217.63333333333333, -195.7, -206.06666666666678, -215.8999999999997, -120.10000000000001, -315.3333333333334, -98.59999999999994, -10.299999999999997, -226.29999999999998, -188.46666666666678, -156.36666666666667, -177.5333333333335, -157.0, -274.43333333333317, -376.60000000000076, -340.66666666666777, -670.1666666666697, -233.200000000002, -201.2000000000001, -307.1000000000005, -315.73333333333284, -292.8999999999996, -488.20000000000084, -455.4666666666627, -150.86666666666608], "policy_defender_reward": [-1.4999999999999998, -17.1, -2.3, -10.600000000000001, -7.699999999999999, -10.400000000000002, -4.800000000000001, -6.299999999999999, -7.400000000000009, -3.8999999999999995, -2.0999999999999996, 1.6000000000000005, -6.7, -4.800000000000001, -6.4, -12.5, -16.700000000000003, -7.7, -11.100000000000003, -3.5, -13.7, -10.300000000000002, -15.899999999999995, -2.2999999999999994, -2.3999999999999986, 0.4, -7.699999999999999, 2.1, -3.3000000000000016, -0.7000000000000001, 3.6000000000000005, -19.299999999999997, -6.900000000000001, -5.6000000000000005, -3.099999999999999, -0.7999999999999989, 1.0999999999999999, -2.3, -20.0, -1.5999999999999996, -21.2, -18.5, -0.6]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.285115426037267, "mean_inference_ms": 0.5724980380313596, "mean_action_processing_ms": 0.058566041763031644, "mean_env_wait_ms": 0.4900582538476213, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "num_healthy_workers": 3, "num_agent_steps_sampled": 21165, "num_agent_steps_trained": 53792, "num_env_steps_sampled": 21168, "num_env_steps_trained": 53792, "num_env_steps_sampled_this_iter": 1008, "num_env_steps_trained_this_iter": 2688, "timesteps_total": 21168, "num_steps_trained_this_iter": 2688, "agent_timesteps_total": 21165, "timers": {"training_iteration_time_ms": 24.224, "load_time_ms": 0.1, "load_throughput": 319566.019, "learn_time_ms": 3.507, "learn_throughput": 9124.499, "synch_weights_time_ms": 2.607}, "counters": {"num_env_steps_sampled": 21168, "num_env_steps_trained": 53792, "num_agent_steps_sampled": 21165, "num_agent_steps_trained": 53792, "last_target_update_ts": 21168, "num_target_updates": 41}, "done": false, "episodes_total": 43, "training_iteration": 21, "trial_id": "5f583_00000", "experiment_id": "d83cb2d89bc543feb18deca748a0082f", "date": "2022-09-11_15-48-30", "timestamp": 1662886110, "time_this_iter_s": 2.2387115955352783, "time_total_s": 43.11053514480591, "pid": 14740, "hostname": "XorgWorkstation", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "my_env", "env_config": {}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "num_workers": 3, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "ignore_worker_failures": false, "recreate_failed_workers": false, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 0.0005, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "my_env", "env_config": {}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "num_workers": 3, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "ignore_worker_failures": false, "recreate_failed_workers": false, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 0.0005, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": {"explore": false}, "off_policy_estimation_methods": {}, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": 1, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 1000, "logger_creator": null, "logger_config": null, "log_level": "INFO", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": -1, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": null, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "min_time_s_per_reporting": -1, "min_train_timesteps_per_reporting": -1, "min_sample_timesteps_per_reporting": -1, "input_evaluation": -1, "target_network_update_freq": 500, "replay_buffer_config": {"type": "<class 'ray.rllib.utils.replay_buffers.multi_agent_prioritized_replay_buffer.MultiAgentPrioritizedReplayBuffer'>", "prioritized_replay": -1, "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "worker_side_prioritization": false, "replay_mode": "independent"}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "input": "sampler", "multiagent": {"policies": {"attacker": "<ray.rllib.policy.policy.PolicySpec object at 0x0000029580382910>", "defender": "<ray.rllib.policy.policy.PolicySpec object at 0x00000295802FFF40>"}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x00000295802F7160>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "tf", "num_cpus_for_driver": 1}, "off_policy_estimation_methods": {}, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": 1, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 1000, "logger_creator": null, "logger_config": null, "log_level": "INFO", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": -1, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": null, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "min_time_s_per_reporting": -1, "min_train_timesteps_per_reporting": -1, "min_sample_timesteps_per_reporting": -1, "input_evaluation": -1, "target_network_update_freq": 500, "replay_buffer_config": {"type": "<class 'ray.rllib.utils.replay_buffers.multi_agent_prioritized_replay_buffer.MultiAgentPrioritizedReplayBuffer'>", "prioritized_replay": -1, "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "worker_side_prioritization": false, "replay_mode": "independent"}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "input": "sampler", "multiagent": {"policies": {"attacker": "<ray.rllib.policy.policy.PolicySpec object at 0x000002958037D640>", "defender": "<ray.rllib.policy.policy.PolicySpec object at 0x000002958037C640>"}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x00000295802F7160>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "tf", "num_cpus_for_driver": 1}, "time_since_restore": 43.11053514480591, "timesteps_since_restore": 0, "iterations_since_restore": 21, "warmup_time": 9.31046748161316, "perf": {"cpu_util_percent": 4.533333333333333, "ram_util_percent": 50.76666666666667}}
{"custom_metrics": {}, "episode_media": {}, "num_recreated_workers": 0, "info": {"learner": {"attacker": {"learner_stats": {"cur_lr": 0.0005000000237487257, "mean_q": -19.433958053588867, "min_q": -26.273468017578125, "max_q": -3.049710512161255, "mean_td_error": 0.042423561215400696, "model": {}}, "td_error": [0.28568458557128906, -0.7827777862548828, -0.26999855041503906, 0.1410503387451172, -0.3197650909423828, -1.9082908630371094, 1.2990550994873047, 0.1376049518585205, 0.2706298828125, 0.02695465087890625, 0.1779766082763672, 0.3242073059082031, 0.4942760467529297, 0.8833503723144531, 0.18881797790527344, -0.26999855041503906], "custom_metrics": {}, "num_agent_steps_trained": 16.0}, "defender": {"learner_stats": {"cur_lr": 0.0005000000237487257, "mean_q": 0.889992892742157, "min_q": -1.1568708419799805, "max_q": 2.1232123374938965, "mean_td_error": -0.1881723701953888, "model": {}}, "td_error": [-0.043910980224609375, -0.2229304313659668, -0.043910980224609375, -0.0782170295715332, -0.27953672409057617, 0.0703853964805603, -0.5186810493469238, -0.14323806762695312, -0.18601202964782715, -0.9500872492790222, -0.047336578369140625, 0.15438830852508545, -0.013688802719116211, -0.26290416717529297, -0.12766659259796143, -0.31741106510162354], "custom_metrics": {}, "num_agent_steps_trained": 16.0}}, "num_env_steps_sampled": 22176, "num_env_steps_trained": 56480, "num_agent_steps_sampled": 22173, "num_agent_steps_trained": 56480, "last_target_update_ts": 22176, "num_target_updates": 43}, "sampler_results": {"episode_reward_max": -9.899999999999999, "episode_reward_min": -673.2666666666697, "episode_reward_mean": -234.9442028985508, "episode_len_mean": 474.0869565217391, "episode_media": {}, "episodes_this_iter": 3, "policy_reward_min": {"attacker": -670.1666666666697, "defender": -21.2}, "policy_reward_max": {"attacker": -10.299999999999997, "defender": 3.6000000000000005}, "policy_reward_mean": {"attacker": -228.4615942028986, "defender": -6.482608695652174}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-186.86666666666676, -201.73333333333355, -126.73333333333342, -190.63333333333333, -199.26666666666654, -154.26666666666696, -168.16666666666674, -152.5000000000002, -200.3333333333335, -164.50000000000006, -145.46666666666667, -119.16666666666663, -93.13333333333337, -141.8333333333334, -201.2666666666667, -204.33333333333317, -151.23333333333335, -175.76666666666677, -228.7333333333334, -199.20000000000005, -219.76666666666682, -226.19999999999976, -136.00000000000009, -317.6333333333334, -100.99999999999987, -9.899999999999999, -234.0, -186.36666666666693, -159.66666666666677, -178.23333333333355, -153.4, -293.73333333333323, -383.5000000000007, -346.26666666666785, -673.2666666666697, -234.000000000002, -200.10000000000014, -309.40000000000055, -335.7333333333329, -294.4999999999996, -509.4000000000008, -473.96666666666306, -151.4666666666661, -433.16666666666345, -592.0000000000007, -249.63333333333304], "episode_lengths": [283, 303, 315, 300, 328, 333, 292, 369, 314, 288, 273, 237, 151, 286, 351, 395, 286, 310, 352, 378, 304, 354, 300, 441, 337, 69, 339, 364, 288, 298, 357, 536, 826, 841, 1347, 705, 209, 615, 577, 881, 1059, 1037, 434, 1363, 1090, 693], "policy_attacker_reward": [-185.36666666666673, -184.63333333333352, -124.43333333333341, -180.03333333333336, -191.56666666666655, -143.86666666666696, -163.36666666666673, -146.2000000000002, -192.93333333333337, -160.60000000000002, -143.36666666666667, -120.76666666666664, -86.43333333333337, -137.03333333333333, -194.86666666666667, -191.83333333333312, -134.5333333333334, -168.06666666666678, -217.63333333333333, -195.7, -206.06666666666678, -215.8999999999997, -120.10000000000001, -315.3333333333334, -98.59999999999994, -10.299999999999997, -226.29999999999998, -188.46666666666678, -156.36666666666667, -177.5333333333335, -157.0, -274.43333333333317, -376.60000000000076, -340.66666666666777, -670.1666666666697, -233.200000000002, -201.2000000000001, -307.1000000000005, -315.73333333333284, -292.8999999999996, -488.20000000000084, -455.4666666666627, -150.86666666666608, -429.76666666666364, -594.6000000000007, -243.13333333333298], "policy_defender_reward": [-1.4999999999999998, -17.1, -2.3, -10.600000000000001, -7.699999999999999, -10.400000000000002, -4.800000000000001, -6.299999999999999, -7.400000000000009, -3.8999999999999995, -2.0999999999999996, 1.6000000000000005, -6.7, -4.800000000000001, -6.4, -12.5, -16.700000000000003, -7.7, -11.100000000000003, -3.5, -13.7, -10.300000000000002, -15.899999999999995, -2.2999999999999994, -2.3999999999999986, 0.4, -7.699999999999999, 2.1, -3.3000000000000016, -0.7000000000000001, 3.6000000000000005, -19.299999999999997, -6.900000000000001, -5.6000000000000005, -3.099999999999999, -0.7999999999999989, 1.0999999999999999, -2.3, -20.0, -1.5999999999999996, -21.2, -18.5, -0.6, -3.3999999999999995, 2.6000000000000005, -6.5]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2843086679671113, "mean_inference_ms": 0.5694871079194439, "mean_action_processing_ms": 0.05843266702015342, "mean_env_wait_ms": 0.48979326006706936, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0}, "episode_reward_max": -9.899999999999999, "episode_reward_min": -673.2666666666697, "episode_reward_mean": -234.9442028985508, "episode_len_mean": 474.0869565217391, "episodes_this_iter": 3, "policy_reward_min": {"attacker": -670.1666666666697, "defender": -21.2}, "policy_reward_max": {"attacker": -10.299999999999997, "defender": 3.6000000000000005}, "policy_reward_mean": {"attacker": -228.4615942028986, "defender": -6.482608695652174}, "hist_stats": {"episode_reward": [-186.86666666666676, -201.73333333333355, -126.73333333333342, -190.63333333333333, -199.26666666666654, -154.26666666666696, -168.16666666666674, -152.5000000000002, -200.3333333333335, -164.50000000000006, -145.46666666666667, -119.16666666666663, -93.13333333333337, -141.8333333333334, -201.2666666666667, -204.33333333333317, -151.23333333333335, -175.76666666666677, -228.7333333333334, -199.20000000000005, -219.76666666666682, -226.19999999999976, -136.00000000000009, -317.6333333333334, -100.99999999999987, -9.899999999999999, -234.0, -186.36666666666693, -159.66666666666677, -178.23333333333355, -153.4, -293.73333333333323, -383.5000000000007, -346.26666666666785, -673.2666666666697, -234.000000000002, -200.10000000000014, -309.40000000000055, -335.7333333333329, -294.4999999999996, -509.4000000000008, -473.96666666666306, -151.4666666666661, -433.16666666666345, -592.0000000000007, -249.63333333333304], "episode_lengths": [283, 303, 315, 300, 328, 333, 292, 369, 314, 288, 273, 237, 151, 286, 351, 395, 286, 310, 352, 378, 304, 354, 300, 441, 337, 69, 339, 364, 288, 298, 357, 536, 826, 841, 1347, 705, 209, 615, 577, 881, 1059, 1037, 434, 1363, 1090, 693], "policy_attacker_reward": [-185.36666666666673, -184.63333333333352, -124.43333333333341, -180.03333333333336, -191.56666666666655, -143.86666666666696, -163.36666666666673, -146.2000000000002, -192.93333333333337, -160.60000000000002, -143.36666666666667, -120.76666666666664, -86.43333333333337, -137.03333333333333, -194.86666666666667, -191.83333333333312, -134.5333333333334, -168.06666666666678, -217.63333333333333, -195.7, -206.06666666666678, -215.8999999999997, -120.10000000000001, -315.3333333333334, -98.59999999999994, -10.299999999999997, -226.29999999999998, -188.46666666666678, -156.36666666666667, -177.5333333333335, -157.0, -274.43333333333317, -376.60000000000076, -340.66666666666777, -670.1666666666697, -233.200000000002, -201.2000000000001, -307.1000000000005, -315.73333333333284, -292.8999999999996, -488.20000000000084, -455.4666666666627, -150.86666666666608, -429.76666666666364, -594.6000000000007, -243.13333333333298], "policy_defender_reward": [-1.4999999999999998, -17.1, -2.3, -10.600000000000001, -7.699999999999999, -10.400000000000002, -4.800000000000001, -6.299999999999999, -7.400000000000009, -3.8999999999999995, -2.0999999999999996, 1.6000000000000005, -6.7, -4.800000000000001, -6.4, -12.5, -16.700000000000003, -7.7, -11.100000000000003, -3.5, -13.7, -10.300000000000002, -15.899999999999995, -2.2999999999999994, -2.3999999999999986, 0.4, -7.699999999999999, 2.1, -3.3000000000000016, -0.7000000000000001, 3.6000000000000005, -19.299999999999997, -6.900000000000001, -5.6000000000000005, -3.099999999999999, -0.7999999999999989, 1.0999999999999999, -2.3, -20.0, -1.5999999999999996, -21.2, -18.5, -0.6, -3.3999999999999995, 2.6000000000000005, -6.5]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2843086679671113, "mean_inference_ms": 0.5694871079194439, "mean_action_processing_ms": 0.05843266702015342, "mean_env_wait_ms": 0.48979326006706936, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "num_healthy_workers": 3, "num_agent_steps_sampled": 22173, "num_agent_steps_trained": 56480, "num_env_steps_sampled": 22176, "num_env_steps_trained": 56480, "num_env_steps_sampled_this_iter": 1008, "num_env_steps_trained_this_iter": 2688, "timesteps_total": 22176, "num_steps_trained_this_iter": 2688, "agent_timesteps_total": 22173, "timers": {"training_iteration_time_ms": 29.275, "load_time_ms": 0.1, "load_throughput": 320328.706, "learn_time_ms": 3.706, "learn_throughput": 8634.03, "synch_weights_time_ms": 2.345}, "counters": {"num_env_steps_sampled": 22176, "num_env_steps_trained": 56480, "num_agent_steps_sampled": 22173, "num_agent_steps_trained": 56480, "last_target_update_ts": 22176, "num_target_updates": 43}, "done": false, "episodes_total": 46, "training_iteration": 22, "trial_id": "5f583_00000", "experiment_id": "d83cb2d89bc543feb18deca748a0082f", "date": "2022-09-11_15-48-32", "timestamp": 1662886112, "time_this_iter_s": 2.1263816356658936, "time_total_s": 45.2369167804718, "pid": 14740, "hostname": "XorgWorkstation", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "my_env", "env_config": {}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "num_workers": 3, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "ignore_worker_failures": false, "recreate_failed_workers": false, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 0.0005, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "my_env", "env_config": {}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "num_workers": 3, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "ignore_worker_failures": false, "recreate_failed_workers": false, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 0.0005, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": {"explore": false}, "off_policy_estimation_methods": {}, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": 1, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 1000, "logger_creator": null, "logger_config": null, "log_level": "INFO", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": -1, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": null, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "min_time_s_per_reporting": -1, "min_train_timesteps_per_reporting": -1, "min_sample_timesteps_per_reporting": -1, "input_evaluation": -1, "target_network_update_freq": 500, "replay_buffer_config": {"type": "<class 'ray.rllib.utils.replay_buffers.multi_agent_prioritized_replay_buffer.MultiAgentPrioritizedReplayBuffer'>", "prioritized_replay": -1, "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "worker_side_prioritization": false, "replay_mode": "independent"}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "input": "sampler", "multiagent": {"policies": {"attacker": "<ray.rllib.policy.policy.PolicySpec object at 0x00000295803B24F0>", "defender": "<ray.rllib.policy.policy.PolicySpec object at 0x00000295803B2FD0>"}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x00000295803BDA60>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "tf", "num_cpus_for_driver": 1}, "off_policy_estimation_methods": {}, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": 1, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 1000, "logger_creator": null, "logger_config": null, "log_level": "INFO", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": -1, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": null, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "min_time_s_per_reporting": -1, "min_train_timesteps_per_reporting": -1, "min_sample_timesteps_per_reporting": -1, "input_evaluation": -1, "target_network_update_freq": 500, "replay_buffer_config": {"type": "<class 'ray.rllib.utils.replay_buffers.multi_agent_prioritized_replay_buffer.MultiAgentPrioritizedReplayBuffer'>", "prioritized_replay": -1, "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "worker_side_prioritization": false, "replay_mode": "independent"}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "input": "sampler", "multiagent": {"policies": {"attacker": "<ray.rllib.policy.policy.PolicySpec object at 0x00000295803B2970>", "defender": "<ray.rllib.policy.policy.PolicySpec object at 0x00000295803B1A30>"}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x00000295803BDA60>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "tf", "num_cpus_for_driver": 1}, "time_since_restore": 45.2369167804718, "timesteps_since_restore": 0, "iterations_since_restore": 22, "warmup_time": 9.31046748161316, "perf": {"cpu_util_percent": 5.7, "ram_util_percent": 50.833333333333336}}
{"custom_metrics": {}, "episode_media": {}, "num_recreated_workers": 0, "info": {"learner": {"attacker": {"learner_stats": {"cur_lr": 0.0005000000237487257, "mean_q": -18.896820068359375, "min_q": -30.483217239379883, "max_q": -9.926273345947266, "mean_td_error": -1.4031970500946045, "model": {}}, "td_error": [-0.7480697631835938, -0.2522697448730469, 1.5889873504638672, -1.4372367858886719, -0.2695808410644531, -4.679256439208984, 0.4148139953613281, -0.4138813018798828, 0.32329368591308594, -0.162445068359375, -0.26449012756347656, -0.2420368194580078, -0.1827259063720703, -0.7158718109130859, -15.465067863464355, 0.05468559265136719], "custom_metrics": {}, "num_agent_steps_trained": 16.0}, "defender": {"learner_stats": {"cur_lr": 0.0005000000237487257, "mean_q": 1.0792173147201538, "min_q": -0.5437555313110352, "max_q": 3.829340696334839, "mean_td_error": 0.05040702223777771, "model": {}}, "td_error": [-0.6719248294830322, 0.046464622020721436, 0.2777550220489502, 0.09782478213310242, 0.1250932216644287, -0.0024643540382385254, -0.19179987907409668, -0.19942569732666016, 0.18061098456382751, 0.09782478213310242, -0.11844274401664734, 0.036849260330200195, 0.055777907371520996, 0.18961137533187866, 0.04118608683347702, 0.8415718078613281], "custom_metrics": {}, "num_agent_steps_trained": 16.0}}, "num_env_steps_sampled": 23184, "num_env_steps_trained": 59168, "num_agent_steps_sampled": 23181, "num_agent_steps_trained": 59168, "last_target_update_ts": 23184, "num_target_updates": 45}, "sampler_results": {"episode_reward_max": -9.899999999999999, "episode_reward_min": -673.2666666666697, "episode_reward_mean": -234.9442028985508, "episode_len_mean": 474.0869565217391, "episode_media": {}, "episodes_this_iter": 0, "policy_reward_min": {"attacker": -670.1666666666697, "defender": -21.2}, "policy_reward_max": {"attacker": -10.299999999999997, "defender": 3.6000000000000005}, "policy_reward_mean": {"attacker": -228.4615942028986, "defender": -6.482608695652174}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-186.86666666666676, -201.73333333333355, -126.73333333333342, -190.63333333333333, -199.26666666666654, -154.26666666666696, -168.16666666666674, -152.5000000000002, -200.3333333333335, -164.50000000000006, -145.46666666666667, -119.16666666666663, -93.13333333333337, -141.8333333333334, -201.2666666666667, -204.33333333333317, -151.23333333333335, -175.76666666666677, -228.7333333333334, -199.20000000000005, -219.76666666666682, -226.19999999999976, -136.00000000000009, -317.6333333333334, -100.99999999999987, -9.899999999999999, -234.0, -186.36666666666693, -159.66666666666677, -178.23333333333355, -153.4, -293.73333333333323, -383.5000000000007, -346.26666666666785, -673.2666666666697, -234.000000000002, -200.10000000000014, -309.40000000000055, -335.7333333333329, -294.4999999999996, -509.4000000000008, -473.96666666666306, -151.4666666666661, -433.16666666666345, -592.0000000000007, -249.63333333333304], "episode_lengths": [283, 303, 315, 300, 328, 333, 292, 369, 314, 288, 273, 237, 151, 286, 351, 395, 286, 310, 352, 378, 304, 354, 300, 441, 337, 69, 339, 364, 288, 298, 357, 536, 826, 841, 1347, 705, 209, 615, 577, 881, 1059, 1037, 434, 1363, 1090, 693], "policy_attacker_reward": [-185.36666666666673, -184.63333333333352, -124.43333333333341, -180.03333333333336, -191.56666666666655, -143.86666666666696, -163.36666666666673, -146.2000000000002, -192.93333333333337, -160.60000000000002, -143.36666666666667, -120.76666666666664, -86.43333333333337, -137.03333333333333, -194.86666666666667, -191.83333333333312, -134.5333333333334, -168.06666666666678, -217.63333333333333, -195.7, -206.06666666666678, -215.8999999999997, -120.10000000000001, -315.3333333333334, -98.59999999999994, -10.299999999999997, -226.29999999999998, -188.46666666666678, -156.36666666666667, -177.5333333333335, -157.0, -274.43333333333317, -376.60000000000076, -340.66666666666777, -670.1666666666697, -233.200000000002, -201.2000000000001, -307.1000000000005, -315.73333333333284, -292.8999999999996, -488.20000000000084, -455.4666666666627, -150.86666666666608, -429.76666666666364, -594.6000000000007, -243.13333333333298], "policy_defender_reward": [-1.4999999999999998, -17.1, -2.3, -10.600000000000001, -7.699999999999999, -10.400000000000002, -4.800000000000001, -6.299999999999999, -7.400000000000009, -3.8999999999999995, -2.0999999999999996, 1.6000000000000005, -6.7, -4.800000000000001, -6.4, -12.5, -16.700000000000003, -7.7, -11.100000000000003, -3.5, -13.7, -10.300000000000002, -15.899999999999995, -2.2999999999999994, -2.3999999999999986, 0.4, -7.699999999999999, 2.1, -3.3000000000000016, -0.7000000000000001, 3.6000000000000005, -19.299999999999997, -6.900000000000001, -5.6000000000000005, -3.099999999999999, -0.7999999999999989, 1.0999999999999999, -2.3, -20.0, -1.5999999999999996, -21.2, -18.5, -0.6, -3.3999999999999995, 2.6000000000000005, -6.5]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2843086679671113, "mean_inference_ms": 0.5694871079194439, "mean_action_processing_ms": 0.05843266702015342, "mean_env_wait_ms": 0.48979326006706936, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0}, "episode_reward_max": -9.899999999999999, "episode_reward_min": -673.2666666666697, "episode_reward_mean": -234.9442028985508, "episode_len_mean": 474.0869565217391, "episodes_this_iter": 0, "policy_reward_min": {"attacker": -670.1666666666697, "defender": -21.2}, "policy_reward_max": {"attacker": -10.299999999999997, "defender": 3.6000000000000005}, "policy_reward_mean": {"attacker": -228.4615942028986, "defender": -6.482608695652174}, "hist_stats": {"episode_reward": [-186.86666666666676, -201.73333333333355, -126.73333333333342, -190.63333333333333, -199.26666666666654, -154.26666666666696, -168.16666666666674, -152.5000000000002, -200.3333333333335, -164.50000000000006, -145.46666666666667, -119.16666666666663, -93.13333333333337, -141.8333333333334, -201.2666666666667, -204.33333333333317, -151.23333333333335, -175.76666666666677, -228.7333333333334, -199.20000000000005, -219.76666666666682, -226.19999999999976, -136.00000000000009, -317.6333333333334, -100.99999999999987, -9.899999999999999, -234.0, -186.36666666666693, -159.66666666666677, -178.23333333333355, -153.4, -293.73333333333323, -383.5000000000007, -346.26666666666785, -673.2666666666697, -234.000000000002, -200.10000000000014, -309.40000000000055, -335.7333333333329, -294.4999999999996, -509.4000000000008, -473.96666666666306, -151.4666666666661, -433.16666666666345, -592.0000000000007, -249.63333333333304], "episode_lengths": [283, 303, 315, 300, 328, 333, 292, 369, 314, 288, 273, 237, 151, 286, 351, 395, 286, 310, 352, 378, 304, 354, 300, 441, 337, 69, 339, 364, 288, 298, 357, 536, 826, 841, 1347, 705, 209, 615, 577, 881, 1059, 1037, 434, 1363, 1090, 693], "policy_attacker_reward": [-185.36666666666673, -184.63333333333352, -124.43333333333341, -180.03333333333336, -191.56666666666655, -143.86666666666696, -163.36666666666673, -146.2000000000002, -192.93333333333337, -160.60000000000002, -143.36666666666667, -120.76666666666664, -86.43333333333337, -137.03333333333333, -194.86666666666667, -191.83333333333312, -134.5333333333334, -168.06666666666678, -217.63333333333333, -195.7, -206.06666666666678, -215.8999999999997, -120.10000000000001, -315.3333333333334, -98.59999999999994, -10.299999999999997, -226.29999999999998, -188.46666666666678, -156.36666666666667, -177.5333333333335, -157.0, -274.43333333333317, -376.60000000000076, -340.66666666666777, -670.1666666666697, -233.200000000002, -201.2000000000001, -307.1000000000005, -315.73333333333284, -292.8999999999996, -488.20000000000084, -455.4666666666627, -150.86666666666608, -429.76666666666364, -594.6000000000007, -243.13333333333298], "policy_defender_reward": [-1.4999999999999998, -17.1, -2.3, -10.600000000000001, -7.699999999999999, -10.400000000000002, -4.800000000000001, -6.299999999999999, -7.400000000000009, -3.8999999999999995, -2.0999999999999996, 1.6000000000000005, -6.7, -4.800000000000001, -6.4, -12.5, -16.700000000000003, -7.7, -11.100000000000003, -3.5, -13.7, -10.300000000000002, -15.899999999999995, -2.2999999999999994, -2.3999999999999986, 0.4, -7.699999999999999, 2.1, -3.3000000000000016, -0.7000000000000001, 3.6000000000000005, -19.299999999999997, -6.900000000000001, -5.6000000000000005, -3.099999999999999, -0.7999999999999989, 1.0999999999999999, -2.3, -20.0, -1.5999999999999996, -21.2, -18.5, -0.6, -3.3999999999999995, 2.6000000000000005, -6.5]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2843086679671113, "mean_inference_ms": 0.5694871079194439, "mean_action_processing_ms": 0.05843266702015342, "mean_env_wait_ms": 0.48979326006706936, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "num_healthy_workers": 3, "num_agent_steps_sampled": 23181, "num_agent_steps_trained": 59168, "num_env_steps_sampled": 23184, "num_env_steps_trained": 59168, "num_env_steps_sampled_this_iter": 1008, "num_env_steps_trained_this_iter": 2688, "timesteps_total": 23184, "num_steps_trained_this_iter": 2688, "agent_timesteps_total": 23181, "timers": {"training_iteration_time_ms": 24.407, "load_time_ms": 0.301, "load_throughput": 106294.233, "learn_time_ms": 3.131, "learn_throughput": 10219.961, "synch_weights_time_ms": 2.353}, "counters": {"num_env_steps_sampled": 23184, "num_env_steps_trained": 59168, "num_agent_steps_sampled": 23181, "num_agent_steps_trained": 59168, "last_target_update_ts": 23184, "num_target_updates": 45}, "done": false, "episodes_total": 46, "training_iteration": 23, "trial_id": "5f583_00000", "experiment_id": "d83cb2d89bc543feb18deca748a0082f", "date": "2022-09-11_15-48-34", "timestamp": 1662886114, "time_this_iter_s": 2.04823637008667, "time_total_s": 47.28515315055847, "pid": 14740, "hostname": "XorgWorkstation", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "my_env", "env_config": {}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "num_workers": 3, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "ignore_worker_failures": false, "recreate_failed_workers": false, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 0.0005, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "my_env", "env_config": {}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "num_workers": 3, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "ignore_worker_failures": false, "recreate_failed_workers": false, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 0.0005, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": {"explore": false}, "off_policy_estimation_methods": {}, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": 1, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 1000, "logger_creator": null, "logger_config": null, "log_level": "INFO", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": -1, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": null, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "min_time_s_per_reporting": -1, "min_train_timesteps_per_reporting": -1, "min_sample_timesteps_per_reporting": -1, "input_evaluation": -1, "target_network_update_freq": 500, "replay_buffer_config": {"type": "<class 'ray.rllib.utils.replay_buffers.multi_agent_prioritized_replay_buffer.MultiAgentPrioritizedReplayBuffer'>", "prioritized_replay": -1, "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "worker_side_prioritization": false, "replay_mode": "independent"}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "input": "sampler", "multiagent": {"policies": {"attacker": "<ray.rllib.policy.policy.PolicySpec object at 0x00000295803060D0>", "defender": "<ray.rllib.policy.policy.PolicySpec object at 0x0000029580382070>"}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x000002958029D280>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "tf", "num_cpus_for_driver": 1}, "off_policy_estimation_methods": {}, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": 1, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 1000, "logger_creator": null, "logger_config": null, "log_level": "INFO", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": -1, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": null, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "min_time_s_per_reporting": -1, "min_train_timesteps_per_reporting": -1, "min_sample_timesteps_per_reporting": -1, "input_evaluation": -1, "target_network_update_freq": 500, "replay_buffer_config": {"type": "<class 'ray.rllib.utils.replay_buffers.multi_agent_prioritized_replay_buffer.MultiAgentPrioritizedReplayBuffer'>", "prioritized_replay": -1, "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "worker_side_prioritization": false, "replay_mode": "independent"}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "input": "sampler", "multiagent": {"policies": {"attacker": "<ray.rllib.policy.policy.PolicySpec object at 0x0000029580382D90>", "defender": "<ray.rllib.policy.policy.PolicySpec object at 0x00000295803B2DF0>"}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x000002958029D280>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "tf", "num_cpus_for_driver": 1}, "time_since_restore": 47.28515315055847, "timesteps_since_restore": 0, "iterations_since_restore": 23, "warmup_time": 9.31046748161316, "perf": {"cpu_util_percent": 5.7, "ram_util_percent": 50.86666666666667}}
